Here is the system detailed explanation. Create the application only on the basis of this file. if you need anything please do ask the user don't assume anything. And cross check everything you build and continue to iterate till u reach the expected output.



# 1. Project Overview

## Project Name

Execution Aware RAG Code Explainer

## Objective

Build a local web based system that:

* Accepts a public GitHub repository URL or Python code snippet
* Parses the repository using Tree sitter
* Builds full execution graph including:

  * Call graph
  * Dependency graph
  * Control flow graph
  * Variable flow graph
* Stores semantic embeddings in Milvus
* Stores structural relationships in SQLite graph schema
* Retrieves external documentation, Stack Overflow, GitHub issues
* Uses Ollama local LLM and embedding model
* Generates execution aware explanations
* Displays execution flow diagrams in React Flow

---

# 2. Critical Engineering Constraints

The AI agent MUST follow these rules strictly.

## NOTHING MUST BE HARDCODED

The following must NEVER be hardcoded:

* Model name
* Embedding model
* Milvus collection name
* Repository size limits
* Context length
* Chunk size
* Batch size
* Graph depth
* Timeout values
* GitHub clone location
* SQLite schema assumptions
* Maximum number of files
* Maximum graph nodes

All must be configurable via config file.

---

## ALL OPERATIONS MUST BE SAFE

System must NOT assume:

* Repository is small
* Graph fits in memory
* Model responds instantly
* Embeddings complete instantly

All operations must support:

* Streaming
* Pagination
* Batching
* Timeouts
* Retry logic

---

# 3. System Architecture

## High Level Architecture

```
Frontend (React)
    ↓
FastAPI Backend
    ↓
├── Repository Cloner
├── Tree sitter Parser
├── Graph Builder (SQLite)
├── Embedding Generator (Ollama)
├── Vector Storage (Milvus)
├── External Knowledge Indexer
├── Hybrid Retriever
└── LLM Explanation Engine
```

---

# 4. Technology Stack

## Backend

FastAPI
Python 3.11+

Libraries:

* tree sitter
* pymilvus
* sqlite3
* requests
* gitpython
* ollama python client
* networkx

---

## Vector Database

Milvus

Stores:

* Code embeddings
* Documentation embeddings
* Stack Overflow embeddings
* GitHub issues embeddings

---

## Graph Database

SQLite

Stores:

* Call graph
* Dependency graph
* Variable graph

---

## LLM and Embedding

Ollama

Configurable models:

* embedding_model configurable
* llm_model configurable

Must NOT hardcode model name.

---

## Frontend

React

Graph visualization:

React Flow

---

# 5. Input Specification

## Input Type 1: GitHub Repository URL

Example:

```
https://github.com/user/repo
```

Frontend sends:

```
POST /index_repo
{
  "repo_url": "...",
  "branch": "optional"
}
```

---

## Input Type 2: Code Snippet

```
POST /explain_snippet
{
  "code": "...",
  "language": "python"
}
```

---

# 6. Output Specification

System must return:

## Explanation Output

```
{
  "summary": "...",
  "execution_flow": "...",
  "dependencies": "...",
  "variables": "...",
  "improvements": "...",
  "confidence_score": 0.95
}
```

---

## Graph Output

Nodes:

```
{
  "id": "function_name",
  "type": "function",
  "file": "path"
}
```

Edges:

```
{
  "source": "caller",
  "target": "callee",
  "type": "calls"
}
```

---

# 7. Milvus Schema

Collection name must be configurable.

Schema:

```
id: string
embedding: float vector
content: string
file_path: string
function_name: string
type: string
metadata: json
```

Vector dimension must be dynamically determined from embedding model.

Must NOT hardcode dimension.

---

# 8. SQLite Graph Schema

Tables:

## nodes

```
id TEXT PRIMARY KEY
type TEXT
name TEXT
file_path TEXT
line_start INTEGER
line_end INTEGER
metadata TEXT
```

## edges

```
id TEXT PRIMARY KEY
source TEXT
target TEXT
type TEXT
metadata TEXT
```

## variables

```
id TEXT PRIMARY KEY
name TEXT
scope TEXT
file_path TEXT
metadata TEXT
```

---

# 9. Repository Indexing Flow

## Step 1 Clone Repository

Use GitPython.

Must handle:

* Clone failure
* Network timeout
* Invalid URL

Must NOT assume success.

---

## Step 2 Parse Code using Tree sitter

Extract:

* Functions
* Classes
* Calls
* Variables
* Imports

Must parse file by file.

Must NOT load entire repo into memory.

---

## Step 3 Build Graph

Store relationships in SQLite.

Must batch insert.

Must NOT assume graph fits in RAM.

---

## Step 4 Generate Embeddings

For each code chunk:

Call Ollama embedding API.

Must batch.

Must retry on failure.

Must NOT assume embedding always succeeds.

---

## Step 5 Store Embeddings in Milvus

Insert in batches.

Must NOT assume unlimited memory.

---

## Step 6 Index External Knowledge

Fetch documentation.

Store in Milvus.

Must be offline indexed.

Must NOT fetch during explanation.

---

# 10. Query Flow

User selects function.

System performs:

Step 1 Graph retrieval

Fetch:

* callers
* callees
* dependencies

Step 2 Vector retrieval

Search Milvus.

Step 3 Combine context

Step 4 Send to LLM

Step 5 Generate explanation

---

# 11. FastAPI Endpoints

## Index Repository

```
POST /index_repo
```

## Explain Function

```
POST /explain_function
```

## Explain Snippet

```
POST /explain_snippet
```

## Get Execution Graph

```
GET /graph/{function}
```

---

# 12. Frontend Specification

React pages:

## Page 1 Repository Input

Input field:

GitHub URL

Button:

Index Repository

---

## Page 2 Function Explorer

Displays:

File tree
Functions list

---

## Page 3 Explanation Viewer

Displays:

Explanation text
Execution flow
Dependency list

---

## Page 4 Graph Viewer

Uses React Flow

Displays:

Execution graph
Dependency graph

---

# 13. Configuration File Specification

config.yaml

```
ollama:
  llm_model: configurable
  embedding_model: configurable

milvus:
  host: configurable
  port: configurable
  collection: configurable

sqlite:
  path: configurable

indexing:
  batch_size: configurable
  chunk_size: configurable

github:
  clone_dir: configurable
```

---

# 14. Failure Handling Requirements

Agent must implement:

Retry logic
Timeout handling
Memory safe batching
Partial indexing recovery
Crash recovery

System must NEVER crash due to:

Large repository
Slow model
Slow embedding
Large graph

---

# 15. Folder Structure

```
project/
├── backend/
│   ├── api/
│   ├── parser/
│   ├── graph/
│   ├── embeddings/
│   ├── retriever/
│   ├── llm/
│   ├── config/
│   └── main.py
│
├── frontend/
│   ├── src/
│   └── components/
│
├── data/
│   ├── milvus/
│   ├── sqlite/
│   └── repos/
│
└── config.yaml
```

---

# 16. Expected Outcome

Final system must:

Accept GitHub repo
Index repository safely
Build execution graph
Store embeddings
Retrieve structural plus semantic context
Generate execution aware explanation
Display execution graph visually

Must work reliably for enterprise scale repos.

Must not crash during presentation.

---

# 17. Explicit Safety Rules for AI Agent

Agent MUST NOT:

Hardcode limits
Hardcode model names
Assume repository size
Assume graph size
Assume embedding dimension
Assume memory availability

Agent MUST:

Use config driven architecture
Use batching
Use streaming
Use retries
Use safe database operations
record_id,source_type,domain,library,title,content,code_signature,tags,url,author,date_published,votes_or_stars,relevance_label,difficulty_level
7d43e928-ded2-47a5-9f7c-8c3d0735eeb9,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","vectorization, broadcasting, nan, dtype, reshape",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,15-02-2024,4496,high,intermediate
3673803f-652e-453d-9306-4cc0e5d843f3,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"http, oauth, rest-api, authentication, httpx, retry",https://stackoverflow.com/questions/1604451,user_885136,22-12-2022,640,high,advanced
9c43ce7d-5d4b-49e5-9871-9a4534720acf,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"lock, gather, executor",https://stackoverflow.com/questions/3646552,user_469469,02-06-2023,1532,low,advanced
1c570767-2f5a-4811-8e17-2b02a4e47fe1,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"pathlib, glob, os",https://stackoverflow.com/questions/2737893,user_994539,31-12-2020,2311,low,advanced
3e001a2d-92fd-46cd-9eff-99f83d184f13,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"os, glob, pipe, stdout",https://github.com/cpython/cpython/issues/7712,contributor_8802,31-12-2018,414,high,beginner
76550b3c-af44-4633-8d08-caaaf3112550,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"timeout, authentication, websocket, http",https://stackoverflow.com/questions/8896868,user_243238,22-11-2022,1547,high,beginner
8331d943-8dba-47bf-84d7-494573ce6263,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"nan, dataframe, pivot, reshape, loc, iloc",https://stackoverflow.com/questions/6438436,user_522340,21-11-2022,13,high,beginner
2f6c144b-4b68-497a-81d8-3693d23adec9,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"response, flask, routing",https://github.com/django/django/issues/3243,contributor_6988,06-12-2024,69,low,advanced
815d4d45-d6f0-4007-be22-be4473e63abb,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"pivot, vectorization, array, iloc, reshape",https://stackoverflow.com/questions/6438436,user_522340,23-08-2022,1,low,intermediate
727d2380-38e8-40b6-a1f2-68eabfc40714,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"template, blueprint, django, request, flask, response",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,22-07-2019,317,medium,advanced
5e99f4fc-3b6c-442d-988d-713cef14ec86,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"blueprint, pydantic, middleware, routing, template",https://stackoverflow.com/questions/8930103,user_264801,12-04-2022,2211,high,beginner
70efaa98-679f-4c61-85dd-b28180d9b2b1,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"relationship, sqlalchemy, query",https://stackoverflow.com/questions/7358113,user_12260,19-07-2021,220,high,intermediate
71d7fcf6-a1b8-4d47-8f2d-cf08afb11ffd,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"middleware, flask, orm, rest",https://stackoverflow.com/questions/8930103,user_264801,16-08-2018,2219,high,advanced
bce33477-efd6-4bad-8e32-e19873369ae7,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"race-condition, asyncio, lock, await, executor, gather",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,04-11-2018,4144,high,beginner
d6a203e6-350c-4f5b-9d9d-e77809b60d4f,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"dependency-injection, pydantic, orm, flask, response",https://github.com/django/django/issues/8618,contributor_8921,19-06-2024,21,high,advanced
bb78d29a-67d1-4c70-8284-a41cdac5a5d7,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"pathlib, subprocess, stderr",https://docs.os.org/en/stable/os/environ.html,Official Docs,02-11-2018,2265,high,beginner
b37ff177-3fcf-46b4-b4a1-8167020de213,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"executor, gather, event-loop, lock",https://github.com/cpython/cpython/issues/6647,contributor_4097,27-08-2020,258,high,advanced
28660e2a-97c8-49af-8330-126727b30782,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"rest, flask, orm, request",https://docs.flask.org/en/stable/@app/route.html,Official Docs,02-04-2019,2987,medium,intermediate
f54fd18c-4a3d-477c-a02e-e8d212bf5743,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"loc, numpy, dtype, broadcasting, vectorization",https://stackoverflow.com/questions/4860684,user_627024,26-03-2023,1409,high,beginner
7adee526-0bee-42e6-ba48-41c9013fe864,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"aiohttp, timeout, authentication",https://stackoverflow.com/questions/3592974,user_980733,21-12-2019,1651,medium,beginner
938c0230-0b42-405a-9c08-7ed7f39070c2,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"asyncio, await, race-condition, deadlock",https://github.com/cpython/cpython/issues/6647,contributor_4097,20-02-2024,245,medium,advanced
7d46c0e4-01d5-4074-9b90-a9ce3f436367,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","orm, connection-pool, relationship, sqlalchemy, alembic",https://stackoverflow.com/questions/1247595,user_107793,01-04-2021,431,high,intermediate
d7bbe627-ef23-41cf-b23b-6c83ae0aede0,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"sqlite, orm, session, sqlalchemy, connection-pool, migration",https://github.com/alembic/alembic/issues/7344,contributor_3601,02-03-2019,214,medium,advanced
27026465-be3c-4c99-8c42-bad7fc0e8480,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"groupby, pivot, loc",https://stackoverflow.com/questions/2321324,user_99814,03-05-2022,231,medium,intermediate
073cc390-ab10-4164-a434-b2c4ea60856e,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"broadcasting, reshape, vectorization, array",https://stackoverflow.com/questions/2321324,user_99814,14-06-2023,247,medium,beginner
8882d998-f299-4cd3-b9d9-51575dbfa4bd,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","os, shutil, stdout, tempfile, glob",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,10-10-2024,413,medium,advanced
4ca6a5fb-b202-4cb0-96a0-654cf14a352c,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"oauth, rest-api, retry",https://github.com/requests/requests/issues/4019,contributor_4599,07-12-2023,253,high,beginner
e8e66a94-ca00-49d3-88b9-b22698e1fbe1,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"task, deadlock, asyncio, lock",https://stackoverflow.com/questions/3195773,user_714318,30-07-2024,1109,high,advanced
20fd9494-66a5-4d0d-8c1b-444763d0dcf9,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"flask, orm, fastapi, rest, dependency-injection",https://github.com/flask/flask/issues/2141,contributor_5020,01-06-2021,193,medium,intermediate
2e2c2f28-b2f9-4ab9-979c-318e11ce3f68,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"rest, response, fastapi, request, routing",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,02-12-2022,2432,high,intermediate
6b3f609a-791b-478c-8a5d-18d43764379a,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"timeout, rate-limiting, requests, oauth, aiohttp",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,05-09-2023,4182,high,intermediate
78a8b902-923f-4862-abb2-8a82cc210861,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"dependency-injection, routing, flask, middleware",https://stackoverflow.com/questions/7754864,user_773587,12-02-2023,388,medium,intermediate
f2a60b88-b89d-4565-b952-8bba93d1775c,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","shutil, stdin, pathlib, stdout",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,25-03-2024,429,low,intermediate
796e34e4-0c37-4c9b-81d7-07f4ed854136,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"env-variable, file-io, glob, stdin, os",https://github.com/cpython/cpython/issues/2707,contributor_7877,05-12-2022,489,medium,advanced
532002f5-f670-499f-9d07-bd87872efc96,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"foreign-key, orm, session",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,28-01-2018,278,high,beginner
dcbd8a8a-af77-43a5-95d8-e58b4edcf8a1,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rest-api, timeout, headers",https://stackoverflow.com/questions/1669324,user_952590,28-09-2019,1532,medium,intermediate
590db587-625e-4687-8dad-3d3cd0d74ec6,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"dependency-injection, response, rest, orm, routing",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,06-05-2022,2432,medium,advanced
d8488e6a-6fb6-423b-8ab5-4e8f1ee958b9,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","stderr, process, shutil, pipe, subprocess, pathlib",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,24-01-2022,440,high,intermediate
06d5f02d-053f-41ed-8eba-1b5369eef175,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"process, os, stdin, subprocess, stderr",https://docs.os.org/en/stable/os/environ.html,Official Docs,17-03-2024,2235,medium,intermediate
01b4bcae-84ce-4ae5-8c8d-1a2f09d27ea9,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"connection-pool, transaction, migration, session",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,24-04-2023,2067,medium,beginner
a0b25496-990e-41fc-bc7a-bb0d8f9f73c4,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"orm, connection-pool, postgresql, session",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,14-12-2019,256,low,intermediate
e84459ce-ae65-4f4c-8f51-67ff4a055b71,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"tempfile, pathlib, shutil, file-io, env-variable, process",https://docs.os.org/en/stable/os/environ.html,Official Docs,13-03-2019,2230,medium,beginner
5be5fd63-6768-4cf6-937b-21ddf2d2f293,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"dependency-injection, rest, template",https://stackoverflow.com/questions/8930103,user_264801,18-04-2022,2246,high,beginner
c3d049cd-d7cf-4cd3-9c9a-9943ef41c12f,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"stdout, process, glob, stderr, env-variable",https://github.com/cpython/cpython/issues/2707,contributor_7877,18-01-2024,464,high,intermediate
c1a92ff2-0cde-4dc1-93fd-b439e43111ee,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"event-loop, await, race-condition, executor, threading",https://github.com/cpython/cpython/issues/6647,contributor_4097,24-07-2019,256,high,beginner
a039419f-ae49-4c3a-8e64-118b9c9b1a52,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"request, middleware, template, fastapi, flask",https://stackoverflow.com/questions/8077999,user_202401,03-05-2023,1847,high,advanced
90a9e36a-50b8-4f26-a908-6ea347a7625a,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"request, routing, template",https://stackoverflow.com/questions/1527021,user_911393,11-03-2020,929,low,advanced
62128db7-5d89-4644-ad92-8a78068e1234,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"numpy, broadcasting, array, nan, vectorization",https://stackoverflow.com/questions/2321324,user_99814,09-12-2022,229,medium,advanced
d4855603-15e0-43bb-a2da-5d9ad6879db4,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"nan, dataframe, numpy, loc, groupby, array",https://stackoverflow.com/questions/2321324,user_99814,14-12-2020,251,medium,intermediate
9533f064-e714-485b-bc0d-3f869243fc41,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"file-io, process, shutil, pathlib, env-variable",https://stackoverflow.com/questions/2737893,user_994539,07-05-2018,2301,high,beginner
e931b945-3f7e-471e-a107-52cf67d12ad1,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"threading, deadlock, await",https://stackoverflow.com/questions/2140194,user_718011,29-08-2024,264,low,advanced
c65271fc-4f64-45b4-823f-bd2477df0ea6,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"os, pathlib, env-variable",https://stackoverflow.com/questions/2737893,user_994539,14-11-2021,2254,high,advanced
ad3fb0e8-ae80-4ef2-a33d-ada1cb2dbdd9,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"websocket, timeout, requests, json, authentication",https://stackoverflow.com/questions/1604451,user_885136,02-02-2019,647,medium,advanced
e39aef2c-afe2-4617-9f56-27b972268fc8,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"race-condition, gather, await, executor",https://stackoverflow.com/questions/3646552,user_469469,08-11-2022,1546,medium,advanced
2d651606-6f39-4586-91ae-f5b2482b6d50,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"postgresql, migration, sqlalchemy, session, query, connection-pool",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,16-02-2020,3026,high,beginner
9e932dd2-25db-4f20-982b-5fe53a6e0122,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"json, rest-api, oauth, aiohttp, requests, retry",https://github.com/httpx/httpx/issues/8949,contributor_1420,23-03-2024,460,high,beginner
e9294156-651d-499c-8fd7-2755235b3547,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"query, alembic, migration, relationship, sqlite, session",https://stackoverflow.com/questions/9436429,user_974047,16-11-2024,2393,high,intermediate
ff31d71a-33ea-4414-a3e7-cc243cc6bc28,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","foreign-key, orm, postgresql, sqlite, transaction, session",https://stackoverflow.com/questions/5977931,user_238275,13-07-2022,650,high,beginner
e58ded68-d9ab-4139-b3df-f8bdc2641fe3,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"websocket, retry, headers, timeout",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,01-05-2019,81,medium,intermediate
c66b9658-792d-46dd-8609-8dd6b79bb0b3,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"alembic, orm, postgresql, migration, foreign-key",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,09-02-2022,2047,medium,advanced
ba498d78-b3cf-4a85-9bbb-6931e684a788,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"flask, request, pydantic, dependency-injection, response",https://stackoverflow.com/questions/8077999,user_202401,17-10-2021,1860,high,advanced
7851db22-a1fc-4ac6-be68-ff7c0ac40cf0,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"stdin, env-variable, subprocess, process, stderr, pathlib",https://github.com/cpython/cpython/issues/7712,contributor_8802,12-08-2018,429,low,advanced
bd7ca042-1abd-4433-9f22-d3c02159c2d9,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"fastapi, response, template, flask, dependency-injection",https://stackoverflow.com/questions/8077999,user_202401,09-05-2022,1845,high,advanced
da966da5-21ba-414b-b0b2-9fe51dda51fb,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"lock, async, executor, event-loop",https://stackoverflow.com/questions/2229110,user_573750,20-06-2018,2334,high,advanced
077ed16e-3b01-4f2a-8526-872bfcb00d4b,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"connection-pool, sqlalchemy, session, postgresql, relationship, migration",https://github.com/alembic/alembic/issues/7344,contributor_3601,21-12-2019,213,low,intermediate
b89328e3-36a5-43c6-a16e-636ea3d4db62,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","loc, array, vectorization, nan",https://stackoverflow.com/questions/5446912,user_563306,04-11-2019,2277,high,beginner
2f45f53f-a0e4-44a5-94b9-5594dbe2c5e9,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"groupby, pandas, vectorization",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,06-01-2020,815,high,beginner
fc07bf70-3462-483d-a37a-2771e3db3f18,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"gather, lock, task, threading, coroutine",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,22-09-2020,4816,high,beginner
12a2917e-5816-41b3-8df1-66bd0877da5a,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"orm, django, blueprint, fastapi, routing, dependency-injection",https://github.com/django/django/issues/8618,contributor_8921,02-06-2021,1,medium,intermediate
81620b22-0123-4f64-8732-c62f90827e6a,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"middleware, fastapi, response, routing, orm, request",https://stackoverflow.com/questions/8077999,user_202401,08-11-2023,1848,medium,beginner
7403b976-871c-4016-9cc1-3a2225329bbe,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"rest-api, headers, aiohttp",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,18-07-2022,76,low,advanced
704075e7-573c-42a3-a066-64b8a190f256,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"rate-limiting, http, websocket, timeout, requests, authentication",https://stackoverflow.com/questions/1604451,user_885136,17-02-2022,634,medium,beginner
d1d42f99-aa5c-46f3-b266-a76c63d7a08f,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"pivot, dataframe, merge, vectorization, loc",https://stackoverflow.com/questions/2321324,user_99814,06-12-2022,242,medium,intermediate
bb236202-9931-4c82-a481-dea14bbedead,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"headers, http, httpx, timeout, json, retry",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,17-09-2021,63,medium,beginner
4326d01d-2f75-40de-849d-ac222b20bd6a,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"foreign-key, sqlalchemy, query, session, postgresql",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,19-03-2023,2057,high,advanced
47fc6444-b233-45ba-a392-d581a74fd352,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","rest, orm, blueprint, request",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,05-04-2021,2879,high,beginner
e1bb0026-2f96-4c86-b9c8-0a2b65fab017,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"await, lock, threading, deadlock, semaphore, event-loop",https://github.com/cpython/cpython/issues/6647,contributor_4097,21-11-2022,237,low,beginner
d10fe05b-ceaf-4040-bda9-4089576c7cf1,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"pivot, broadcasting, groupby, vectorization, reshape, iloc",https://stackoverflow.com/questions/6438436,user_522340,12-01-2022,1,medium,advanced
885d4710-a6f7-4d22-ab63-12c33e767977,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"merge, nan, pivot, vectorization, broadcasting",https://stackoverflow.com/questions/4860684,user_627024,08-08-2021,1406,low,beginner
4ea0d6fc-cf89-4a94-adb3-713e98b104a6,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"requests, aiohttp, timeout",https://github.com/httpx/httpx/issues/8949,contributor_1420,10-04-2021,467,high,advanced
35766141-70ed-4cb8-bfff-736f8ed7f5b0,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","alembic, orm, connection-pool, sqlalchemy",https://stackoverflow.com/questions/1247595,user_107793,09-07-2023,393,medium,beginner
f48e34fa-a29b-4c76-914e-2a031ab96e12,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"pandas, pivot, dtype",https://stackoverflow.com/questions/6438436,user_522340,29-12-2022,5,high,beginner
169c9468-e055-4213-90b1-f68385df366a,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"json, timeout, rest-api",https://github.com/requests/requests/issues/3605,contributor_1152,03-09-2022,373,medium,intermediate
dd9a7f69-5a7d-4c30-8231-edb0d1afac3b,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"middleware, request, orm, routing",https://stackoverflow.com/questions/8106470,user_441071,11-09-2021,1773,high,intermediate
0afbce9d-6fc4-4a71-9a5a-a854dd9127fc,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","pandas, pivot, dtype, iloc, array, loc",https://stackoverflow.com/questions/5446912,user_563306,26-02-2024,2286,high,intermediate
7eaec7ff-ab39-4507-9f69-f4a05c8a424b,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rest-api, aiohttp, http, oauth, json, requests",https://stackoverflow.com/questions/1669324,user_952590,02-11-2019,1509,high,beginner
852b858f-2b1c-4c0d-a175-cbff2887eb05,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"fastapi, template, routing",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,02-05-2024,2420,low,beginner
d557af26-28a3-45ce-99aa-888711a2fbab,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"websocket, http, json",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,14-09-2020,63,medium,advanced
4d534a57-0a5f-4299-87f3-afcc4d968e0d,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"flask, fastapi, dependency-injection, request, blueprint, routing",https://github.com/django/django/issues/3243,contributor_6988,17-02-2022,79,high,beginner
736c8f5f-cc91-465c-a6fd-19ad85bb92f6,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"subprocess, process, stdout, stdin, pipe",https://stackoverflow.com/questions/2737893,user_994539,03-09-2022,2262,medium,advanced
ceaf93aa-f3cd-47d7-9f4b-8c342986c9ac,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"coroutine, lock, semaphore, gather",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,03-04-2020,4811,high,advanced
0628a03d-c4fd-45b2-9404-1bd4637ff1c0,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"blueprint, fastapi, template",https://stackoverflow.com/questions/8930103,user_264801,03-12-2020,2225,medium,intermediate
9796a1a1-3399-4c54-a137-ada1edc7126a,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"dependency-injection, fastapi, blueprint, template, pydantic",https://github.com/django/django/issues/3243,contributor_6988,02-07-2024,59,high,advanced
f5edd406-63ab-46c6-a4b3-890fe25e5b47,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"transaction, query, sqlalchemy, relationship, orm, postgresql",https://stackoverflow.com/questions/9436429,user_974047,10-08-2020,2430,high,beginner
dc5cc6b1-788e-4235-8c5d-618d86bfde6b,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"pathlib, process, stderr, os",https://docs.os.org/en/stable/os/environ.html,Official Docs,10-10-2020,2252,high,intermediate
fd80ac7b-665f-43e8-87cd-a1869dcacf39,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"request, routing, fastapi, orm",https://github.com/django/django/issues/3243,contributor_6988,05-07-2022,60,low,beginner
99162d2a-cb22-40ec-a3df-297e998e5089,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"reshape, dataframe, iloc, groupby",https://stackoverflow.com/questions/6438436,user_522340,09-12-2018,1,medium,beginner
3ad14c68-c949-489c-85fd-012b94d986f7,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"pipe, stdin, stderr, stdout, glob",https://stackoverflow.com/questions/2737893,user_994539,12-05-2018,2310,high,beginner
23a3985d-0aa7-403c-8719-94d7425f62f0,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"process, stdout, pipe",https://stackoverflow.com/questions/5394880,user_179430,16-10-2024,559,high,beginner
59854682-75a5-4dd2-955d-787dc7e25a69,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"orm, foreign-key, transaction, sqlalchemy",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,10-06-2018,3016,high,advanced
97c394f6-9858-481b-a6f6-a441455615ad,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","httpx, websocket, retry, requests, json",https://stackoverflow.com/questions/7907400,user_851204,19-05-2020,1385,medium,intermediate
06b833dd-3caa-4888-b204-a5c98da8e197,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"migration, foreign-key, orm",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,12-09-2023,2031,medium,intermediate
7b6b1c36-5784-4a0e-82b3-e8a55bb5bca2,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","json, http, oauth, httpx, timeout",https://stackoverflow.com/questions/7907400,user_851204,15-08-2020,1370,medium,beginner
756717ac-2fc0-4378-b5bf-053a4567dc93,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rate-limiting, authentication, oauth, headers, http, rest-api",https://stackoverflow.com/questions/1669324,user_952590,20-04-2020,1529,medium,advanced
1a3aac30-7d9b-4f29-a7fc-f936bafd3c77,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"semaphore, task, asyncio",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,05-04-2019,4831,medium,beginner
373e98bd-124b-41ba-9e51-de34299523f2,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"race-condition, semaphore, task, deadlock, async",https://github.com/cpython/cpython/issues/4111,contributor_7884,21-04-2020,56,high,intermediate
2c03853d-ea98-4404-b40e-b8605d05842d,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"pydantic, blueprint, fastapi, rest, django",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,23-05-2018,2394,medium,beginner
ac757187-869b-4ad2-934c-e1b930f427d5,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"query, foreign-key, orm, migration, alembic",https://stackoverflow.com/questions/7358113,user_12260,03-10-2022,251,high,advanced
86f74c08-2727-487e-ba4b-bbdba43c06f9,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"django, dependency-injection, routing, middleware, flask",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,21-12-2019,2431,high,advanced
36228d3c-aafb-4b32-8e21-7809e224524d,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"orm, connection-pool, relationship, session, postgresql",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,28-02-2018,2036,high,advanced
e0017c5a-9f51-4480-b8a8-da78c65eaf44,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"rest, response, request",https://github.com/flask/flask/issues/2141,contributor_5020,23-11-2021,186,medium,intermediate
a6f576e7-1645-4401-bfa4-8ffefabf8f24,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","await, executor, async, threading, semaphore",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,18-09-2021,525,high,beginner
ea287a7f-4fdf-4e4b-a7d4-5f7dd91cbd9e,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"template, middleware, orm, flask",https://stackoverflow.com/questions/8077999,user_202401,09-12-2021,1820,high,advanced
9e4f793f-0466-453e-9ae6-acad6841146b,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"postgresql, foreign-key, relationship, session, alembic, transaction",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,15-01-2023,3048,high,intermediate
dfbca5b7-a7d7-4de9-ad31-a414aa846590,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"deadlock, race-condition, task, coroutine, threading, asyncio",https://stackoverflow.com/questions/2140194,user_718011,23-12-2021,281,high,beginner
4268d402-d595-4a2b-88c3-8a79837db961,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"glob, shutil, os, stdin, tempfile",https://stackoverflow.com/questions/5394880,user_179430,15-12-2022,545,high,advanced
e466f864-ebc9-44a4-bd2a-7fb8b9d53cff,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"timeout, httpx, json, oauth, requests, http",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,07-06-2020,83,medium,advanced
190031d5-d9b8-4f97-a998-a17770886846,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"middleware, flask, orm, request, rest",https://stackoverflow.com/questions/8077999,user_202401,08-07-2020,1837,high,beginner
cf6b3fc2-f8f0-43b8-9bb9-a7e27a6b5148,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"groupby, broadcasting, array, reshape, dtype, numpy",https://stackoverflow.com/questions/6229731,user_428373,17-06-2024,808,medium,beginner
e648d739-b396-41c4-8636-eaba5192bc28,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"rest, response, dependency-injection",https://stackoverflow.com/questions/7754864,user_773587,26-02-2018,422,low,beginner
2ffb96a9-c072-46e3-8a7f-7713cadad658,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"deadlock, race-condition, threading, gather, asyncio",https://github.com/cpython/cpython/issues/5591,contributor_1630,10-05-2022,336,high,beginner
1f2c1c67-f5d9-4742-bbc4-c13e21d26917,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"alembic, foreign-key, sqlite, query, connection-pool, orm",https://stackoverflow.com/questions/9436429,user_974047,25-01-2018,2432,high,intermediate
6366c6a4-931a-441f-af06-0043acb5b0c6,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"gather, deadlock, executor, asyncio, coroutine, async",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,23-11-2020,4168,medium,beginner
9b4471ef-315d-44f1-98f6-91d6d1bb019f,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"json, timeout, oauth, rate-limiting, requests",https://stackoverflow.com/questions/3592974,user_980733,01-02-2024,1673,high,intermediate
c3d59b69-3ac4-4d62-b37f-3d4d789ce8c0,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"headers, http, retry, authentication",https://github.com/httpx/httpx/issues/8949,contributor_1420,26-04-2019,479,low,intermediate
95d9a3f6-bfc1-442a-93d2-4f3ff912c385,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"shutil, pathlib, file-io, tempfile, stdin, glob",https://stackoverflow.com/questions/2737893,user_994539,25-06-2020,2298,high,beginner
4f762aba-b1a9-455f-8cf0-c7872ab3860d,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"routing, django, blueprint, dependency-injection, template",https://stackoverflow.com/questions/8077999,user_202401,13-10-2020,1872,medium,beginner
aa0e0913-874d-47cb-9209-46f352cfe2ee,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"middleware, rest, django, blueprint",https://stackoverflow.com/questions/8106470,user_441071,24-01-2020,1793,medium,advanced
cff7d83b-5bf3-4f59-bba9-fc78e5696f9a,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"foreign-key, alembic, migration, sqlalchemy, sqlite, orm",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,07-10-2024,2059,low,beginner
ec3caf73-5c41-497f-a34e-3723e9453d4a,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"flask, routing, django",https://github.com/django/django/issues/8618,contributor_8921,02-04-2022,1,medium,intermediate
e7047478-24d0-4d4c-a8c8-19f6cd3e7b00,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"transaction, session, foreign-key, sqlalchemy",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,26-06-2024,303,medium,beginner
b5da7911-7536-4146-9b30-5e0b9616c2dd,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"threading, semaphore, lock, deadlock, await",https://stackoverflow.com/questions/2229110,user_573750,03-07-2024,2308,high,beginner
277e8c3f-988b-4f46-82b3-cd6ef8299ec6,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"dtype, pivot, nan, broadcasting, merge",https://github.com/pandas/pandas/issues/4449,contributor_726,05-04-2024,493,high,advanced
115785be-d045-4427-a02f-9d064ee878ed,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","broadcasting, dtype, nan, loc, pivot, vectorization",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,05-12-2019,1889,medium,intermediate
5dbbb342-6dab-43c9-b221-99695d41d321,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"dtype, nan, reshape, groupby, pandas",https://stackoverflow.com/questions/6229731,user_428373,19-07-2021,855,medium,advanced
4453bf1e-b374-4576-a807-279809854651,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","pandas, reshape, pivot, dataframe",https://stackoverflow.com/questions/5446912,user_563306,20-11-2018,2256,high,advanced
6d16a39f-dafb-4eab-b47d-f192e0345aae,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","aiohttp, retry, headers",https://stackoverflow.com/questions/7907400,user_851204,18-01-2024,1348,low,advanced
ad34200c-726f-4f54-a61f-43076df4c24d,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"rate-limiting, timeout, headers, json, websocket",https://github.com/requests/requests/issues/4019,contributor_4599,25-04-2019,274,low,advanced
79ef6666-6342-4b08-91d0-5defb62354df,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"dtype, groupby, dataframe, numpy, pivot, pandas",https://stackoverflow.com/questions/2321324,user_99814,19-10-2022,229,low,beginner
f26a2848-1c39-4b7d-9aca-8b7d02b20f5b,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"gather, async, race-condition, coroutine",https://stackoverflow.com/questions/3646552,user_469469,02-06-2024,1516,medium,intermediate
6d808b52-996c-45ca-8365-fbb5860ff999,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","os, file-io, env-variable, pathlib",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,04-04-2019,457,medium,beginner
69611d5e-9db3-4c4c-9458-e95467c651b1,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"sqlite, transaction, orm, session",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,29-12-2022,2055,high,intermediate
064a6425-60d2-4601-a6d5-4593b85c98b0,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"event-loop, coroutine, await",https://stackoverflow.com/questions/3195773,user_714318,13-03-2019,1068,high,intermediate
6f875f67-f282-4f9f-8d90-7f43df5dbb4c,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"iloc, loc, dataframe, merge, pivot",https://github.com/pandas/pandas/issues/8446,contributor_6648,08-07-2021,361,high,intermediate
01225355-e23c-4540-89e6-519b33741d75,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"stdin, pathlib, process, pipe, glob",https://github.com/cpython/cpython/issues/2707,contributor_7877,11-05-2020,453,high,intermediate
fa0c957f-9abd-4ffd-b77b-e4e702b4928d,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"headers, aiohttp, rest-api",https://github.com/requests/requests/issues/4019,contributor_4599,29-05-2023,273,high,intermediate
704996b6-0321-4a46-8285-0c5951468e00,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"gather, coroutine, lock, async, deadlock, threading",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,15-10-2022,4125,high,advanced
8b1a95ce-ac98-48b9-a2a9-55c7581b3138,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","rate-limiting, requests, oauth, retry",https://stackoverflow.com/questions/7907400,user_851204,24-01-2021,1349,high,intermediate
9d3a026a-373e-4a1f-a91a-fe6c137d618f,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"task, event-loop, asyncio",https://stackoverflow.com/questions/2375453,user_449589,03-07-2023,2445,high,intermediate
295fa90c-4f66-4d4e-9c50-e808dae01306,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"coroutine, lock, event-loop",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,30-07-2019,4838,low,intermediate
c65c6afc-83ff-4623-b00c-9fac8e31a0f1,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"process, os, stdout, shutil, file-io",https://github.com/cpython/cpython/issues/2707,contributor_7877,12-04-2022,458,low,intermediate
84fb110e-9949-4176-b151-64620b1e095f,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"threading, race-condition, asyncio, gather, coroutine, executor",https://stackoverflow.com/questions/2140194,user_718011,24-11-2018,289,high,advanced
534f606f-2269-49e8-afb9-7243984f59a1,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"orm, template, dependency-injection, middleware, fastapi, django",https://stackoverflow.com/questions/8930103,user_264801,24-11-2018,2226,medium,beginner
d2e3eda8-aa7c-423e-8f8a-63c21646b432,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"template, pydantic, rest",https://stackoverflow.com/questions/7754864,user_773587,21-10-2021,413,medium,beginner
0755c5a7-5037-435c-8bcc-11202b01108b,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","postgresql, migration, query, sqlite, session",https://stackoverflow.com/questions/1247595,user_107793,09-08-2024,406,high,advanced
27fb96c6-5970-4a02-b2c0-749ec350a5aa,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"loc, nan, broadcasting",https://stackoverflow.com/questions/2321324,user_99814,28-11-2020,275,high,intermediate
36139519-9a25-463e-a350-8dec574bb57e,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"groupby, iloc, nan, array",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,02-06-2021,1326,high,beginner
f55ab10b-eba4-410c-8cba-0cc9f7ef7eeb,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"stdin, tempfile, os",https://stackoverflow.com/questions/5394880,user_179430,01-05-2023,547,medium,intermediate
10b36a39-8ca1-4486-88ab-4279d3bf1565,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"subprocess, env-variable, stdin",https://stackoverflow.com/questions/5213115,user_959314,09-06-2018,2106,medium,advanced
bc232e1d-968d-4a96-8463-e872cfcd38df,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"retry, authentication, aiohttp, http, websocket",https://github.com/requests/requests/issues/3605,contributor_1152,01-02-2019,361,medium,intermediate
70b879bc-7a9e-430c-903a-bb00f882914e,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","sqlalchemy, connection-pool, relationship, postgresql, migration",https://stackoverflow.com/questions/5977931,user_238275,27-09-2022,650,low,advanced
1fa2e98e-142d-4a7a-b502-02e7732c58e9,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"postgresql, sqlite, foreign-key",https://stackoverflow.com/questions/7358113,user_12260,08-07-2018,224,medium,intermediate
20f56d6c-8507-4378-9406-e776e30bb00b,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"executor, await, task, gather, semaphore",https://github.com/cpython/cpython/issues/6647,contributor_4097,03-03-2019,238,medium,beginner
0d3823d0-f083-412a-accd-2c0533995d30,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"pydantic, flask, request, routing",https://stackoverflow.com/questions/8077999,user_202401,25-03-2020,1864,low,advanced
57c3a341-0848-42bb-bcb3-54e0b38cb6ed,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"django, response, rest",https://stackoverflow.com/questions/7754864,user_773587,30-11-2022,416,medium,advanced
1616156a-e195-4ee5-b937-62ee88d9e4e6,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","dataframe, broadcasting, reshape, loc, nan, pivot",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,11-10-2021,4540,high,advanced
01770363-bca2-41c6-a35f-2ee605776015,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"lock, threading, gather",https://github.com/cpython/cpython/issues/6647,contributor_4097,08-09-2021,229,medium,intermediate
5a540e47-67a5-495a-b401-4600a0653e0e,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","nan, reshape, pandas, broadcasting, numpy, pivot",https://stackoverflow.com/questions/5446912,user_563306,29-05-2019,2244,low,beginner
633bddff-7e7f-4fd3-934e-039c4fe7a5c9,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"rate-limiting, timeout, aiohttp, websocket",https://stackoverflow.com/questions/3592974,user_980733,17-03-2023,1675,high,intermediate
109edd02-f4ce-42bd-bccd-7f43657878d6,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"merge, vectorization, pivot, dtype, reshape, dataframe",https://stackoverflow.com/questions/6229731,user_428373,20-08-2019,849,medium,beginner
260743f4-8779-4fde-aecd-a6c912c296fc,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"vectorization, numpy, broadcasting, array",https://github.com/pandas/pandas/issues/8446,contributor_6648,22-05-2018,321,high,advanced
0e6f7fb5-8690-4db5-8d66-2ee8ad6e149a,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"aiohttp, httpx, authentication, retry, headers, websocket",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,27-11-2019,4210,low,intermediate
aa10f4e3-139b-4b68-8d33-5eee1ae0a379,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"threading, gather, race-condition",https://stackoverflow.com/questions/2375453,user_449589,17-11-2021,2418,high,beginner
abaa3a98-d860-460d-8b87-d9456df87783,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","executor, threading, deadlock, await, asyncio, semaphore",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,20-10-2023,526,low,beginner
841e5e8c-5993-46dc-81c4-7a234d5b3c64,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"dependency-injection, response, pydantic, blueprint, routing, orm",https://stackoverflow.com/questions/8077999,user_202401,12-08-2024,1831,high,advanced
5b873dcb-fcb2-4bb9-9f01-baf211dc81f8,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"broadcasting, merge, pandas, array",https://stackoverflow.com/questions/2321324,user_99814,10-12-2018,265,high,beginner
1f331420-41c0-4fd2-9f4a-172ca5637429,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"httpx, timeout, rest-api, http, aiohttp",https://stackoverflow.com/questions/1604451,user_885136,07-01-2019,613,low,advanced
ad1697ef-ff08-4b93-9b51-c94cf0bc60af,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"event-loop, lock, gather",https://github.com/cpython/cpython/issues/5591,contributor_1630,22-05-2021,326,low,intermediate
32d687d3-3358-4a56-942a-35760e1cebe2,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"relationship, transaction, alembic, migration, session",https://stackoverflow.com/questions/9436429,user_974047,30-03-2023,2410,high,advanced
e4d184cc-fc0e-4d6d-a7c1-b448c9dfe451,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"stdin, subprocess, file-io, env-variable",https://stackoverflow.com/questions/2737893,user_994539,11-11-2021,2300,high,advanced
2fc08a05-fb9b-4bcd-8849-75e8f5ee52ef,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"rest, django, blueprint, template, fastapi, flask",https://github.com/flask/flask/issues/2141,contributor_5020,22-08-2019,143,high,beginner
85e1ef11-f0c8-408c-b38c-e2de84d60f22,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"rest, template, blueprint, orm",https://stackoverflow.com/questions/8077999,user_202401,12-05-2021,1847,high,beginner
86add8fd-0283-43a4-98e8-c9c6b65a73b2,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"executor, task, semaphore, asyncio, lock",https://github.com/cpython/cpython/issues/5591,contributor_1630,05-04-2018,358,medium,advanced
adf195be-9453-4e7f-843e-fa8473ba647c,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"broadcasting, vectorization, iloc, pivot, numpy",https://stackoverflow.com/questions/6229731,user_428373,02-10-2018,808,medium,intermediate
d5d1bcc7-8f43-42ad-ac18-f6724b4f22e0,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","dataframe, pandas, iloc, reshape, dtype, vectorization",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,31-12-2018,1906,low,beginner
422705f6-854d-4870-b129-c5828faf6ba2,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"file-io, process, pipe, stdout, stderr",https://stackoverflow.com/questions/5213115,user_959314,24-10-2024,2068,high,advanced
5a3dc02d-b349-4144-b07d-448f4c29b454,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"requests, aiohttp, rest-api",https://stackoverflow.com/questions/1669324,user_952590,03-09-2019,1531,medium,intermediate
d0d8cdc3-c5ea-419a-b084-3e2568109e15,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"rest, orm, pydantic, blueprint",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,21-04-2022,2393,high,beginner
5e7bf536-5ada-45f1-b889-6495abcc22b9,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"gather, semaphore, event-loop, executor, coroutine",https://stackoverflow.com/questions/2229110,user_573750,22-12-2021,2329,medium,advanced
c5796659-1d45-4058-8543-be5c5524f349,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"alembic, query, session, orm",https://github.com/alembic/alembic/issues/7344,contributor_3601,21-07-2024,248,medium,intermediate
d622515a-72bc-4c20-8fb2-5e78ca492104,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"response, request, blueprint, middleware, routing, template",https://github.com/django/django/issues/3243,contributor_6988,05-06-2021,85,medium,advanced
624a866d-7f0c-4a6c-baa8-16e557e4d6d6,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"pandas, reshape, loc",https://github.com/pandas/pandas/issues/3264,contributor_6628,26-07-2018,46,medium,intermediate
37a56d46-1011-4796-b288-4a0005b2850a,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"gather, race-condition, lock",https://github.com/cpython/cpython/issues/4111,contributor_7884,08-06-2020,3,high,beginner
cba34db0-69b0-4746-a74d-da4f661a1a9c,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"dtype, groupby, vectorization, loc",https://stackoverflow.com/questions/2321324,user_99814,17-05-2022,256,high,advanced
e7d8bb8b-90db-4295-9e4f-dd4fdde8d023,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"response, template, flask, rest",https://stackoverflow.com/questions/8930103,user_264801,09-11-2019,2191,medium,intermediate
01b31f53-78e6-4439-9dfa-ac45e99aa8c6,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"broadcasting, loc, reshape",https://github.com/pandas/pandas/issues/8446,contributor_6648,05-11-2018,360,low,beginner
987a397b-86c9-4044-ba92-058e3dbc4985,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"tempfile, env-variable, os, stderr, subprocess, pathlib",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,01-11-2021,3198,medium,intermediate
e5f96a2d-d30e-444f-bcb5-9e5426d9a6ff,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rest-api, websocket, oauth",https://stackoverflow.com/questions/1669324,user_952590,01-06-2018,1485,high,beginner
759fbcf5-c0a0-4952-963a-dce9773c899d,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"os, subprocess, stdin",https://stackoverflow.com/questions/2737893,user_994539,11-06-2023,2301,low,intermediate
9a94e037-cbd9-4e33-ac0c-94f0ec72bb76,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"groupby, pivot, merge, nan, pandas, broadcasting",https://github.com/pandas/pandas/issues/8446,contributor_6648,30-05-2020,330,low,intermediate
ad0ef856-8018-4e11-8110-074050bf98bc,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"race-condition, lock, deadlock, await, coroutine",https://stackoverflow.com/questions/2140194,user_718011,12-07-2018,282,medium,advanced
767628da-e024-45cc-ac69-2c24085a9593,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"lock, executor, race-condition, await, semaphore, asyncio",https://github.com/cpython/cpython/issues/5591,contributor_1630,10-08-2022,316,medium,intermediate
57579c67-ac1a-4d94-8bad-6e138581d0ea,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"session, connection-pool, orm, sqlalchemy",https://github.com/alembic/alembic/issues/7344,contributor_3601,18-05-2023,251,medium,advanced
7d869120-37e9-4db5-8c2e-58b866b2df17,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"async, executor, threading, semaphore, deadlock, gather",https://stackoverflow.com/questions/3646552,user_469469,11-06-2018,1517,high,advanced
0336c308-7214-4661-a594-f94d47416a22,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"stderr, file-io, subprocess, pathlib",https://github.com/cpython/cpython/issues/2707,contributor_7877,10-01-2021,494,high,intermediate
214f91b6-77a2-4245-a75c-1fa3125f2e44,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"dataframe, reshape, groupby, dtype, pivot, numpy",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,07-02-2023,816,low,beginner
98c75e08-c89d-4ee9-ab43-7f65280fe3b5,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"executor, deadlock, event-loop, lock",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,13-01-2024,4143,medium,beginner
62a04145-367a-4408-b28e-cafe26d0f43e,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"broadcasting, array, dtype, merge, pivot",https://stackoverflow.com/questions/6438436,user_522340,04-06-2019,26,high,beginner
c4ca29b3-090b-473f-95f0-cf8afbc26ac7,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"dtype, groupby, broadcasting, vectorization, pivot",https://github.com/pandas/pandas/issues/8446,contributor_6648,29-03-2024,320,high,intermediate
825cdb0e-9281-4303-b060-4089665950d2,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"transaction, alembic, relationship",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,31-12-2020,3036,high,beginner
6fa7497c-f8df-4e8a-850e-f8588a42fdb6,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"rest-api, oauth, httpx, timeout, rate-limiting",https://github.com/httpx/httpx/issues/8949,contributor_1420,13-03-2022,467,medium,advanced
03ee52ef-ac0a-4da3-bbc1-97667ac549af,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"lock, await, race-condition, asyncio, executor, event-loop",https://github.com/cpython/cpython/issues/6647,contributor_4097,28-12-2022,277,medium,intermediate
fabe47be-aa5d-4e27-bd0e-9aa9e75ee381,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"aiohttp, json, httpx, rest-api, authentication, requests",https://github.com/requests/requests/issues/3605,contributor_1152,17-03-2022,376,low,advanced
156a4c2f-7191-4546-a8fa-3be0e4a3a545,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","numpy, nan, vectorization",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,16-05-2021,1878,high,beginner
683ea517-a7ab-4115-8d46-cde07a1fe04d,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"threading, race-condition, asyncio, executor, event-loop, lock",https://github.com/cpython/cpython/issues/4111,contributor_7884,17-12-2019,27,medium,beginner
9d05eea0-9b49-4559-bdfc-dce07a9b6eba,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"sqlalchemy, orm, connection-pool, alembic, migration, relationship",https://stackoverflow.com/questions/7358113,user_12260,07-11-2019,236,medium,beginner
cb953775-b89f-4ba4-bc1d-df5b934f14fc,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","numpy, iloc, dtype",https://stackoverflow.com/questions/5446912,user_563306,03-11-2023,2283,high,advanced
1742731b-3f46-478d-ab4f-ae3c305b9acb,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"transaction, postgresql, sqlalchemy, orm, session",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,02-09-2023,2029,high,intermediate
2ea78e60-1220-4cd7-b487-afefdf7ca380,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","loc, vectorization, nan, pivot, array, iloc",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,10-08-2022,4507,medium,advanced
5389eeae-d33c-491a-abf9-fcce4ba63127,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"django, request, template",https://stackoverflow.com/questions/7754864,user_773587,15-05-2023,416,medium,intermediate
94771d31-9e79-4164-8395-8bb680b614f1,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"middleware, template, django, flask, rest, routing",https://stackoverflow.com/questions/8077999,user_202401,15-06-2021,1836,medium,advanced
e95dfdbb-6fbe-4930-a370-903674241474,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"env-variable, stdout, stdin",https://github.com/cpython/cpython/issues/2707,contributor_7877,11-03-2019,487,high,intermediate
374bc038-fef6-44c6-bc45-88eee2a13e45,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"headers, rate-limiting, timeout, oauth, aiohttp, httpx",https://github.com/httpx/httpx/issues/8949,contributor_1420,19-04-2024,464,medium,advanced
f374a546-3254-4dc2-823a-a2ec682b66c2,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"requests, rate-limiting, authentication, http, timeout",https://stackoverflow.com/questions/1669324,user_952590,10-02-2019,1526,medium,intermediate
e9852464-bc6a-4ca0-b858-25060d90f5a1,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"transaction, foreign-key, query, migration",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,03-03-2021,3015,medium,beginner
5fee7364-2e4f-41dc-a57a-24bc67392792,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"middleware, fastapi, orm, rest, blueprint, pydantic",https://stackoverflow.com/questions/1527021,user_911393,12-06-2024,935,high,advanced
2ddeb9fb-f5d9-45d5-9107-83e1b0b63183,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"tempfile, shutil, file-io, pipe, stdin",https://github.com/cpython/cpython/issues/7712,contributor_8802,05-01-2019,420,medium,intermediate
ea9dfe1a-1a32-45f7-9819-59737cb95777,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"template, routing, rest",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,04-02-2023,2446,medium,beginner
511d02f8-d5fe-48f2-8476-1c7692ff5c04,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"rate-limiting, rest-api, retry, aiohttp",https://stackoverflow.com/questions/3592974,user_980733,05-04-2024,1655,high,intermediate
e28ac6c8-42d3-49a7-93ab-84e0d1cc7542,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"coroutine, semaphore, executor",https://stackoverflow.com/questions/3195773,user_714318,06-06-2019,1113,low,beginner
705cb82f-fc84-4563-b52c-ffd25a2bf85a,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"iloc, numpy, nan, pandas",https://stackoverflow.com/questions/6438436,user_522340,25-06-2022,4,high,advanced
c9600e52-05d8-420f-8167-bff0e41d21bf,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"websocket, aiohttp, timeout, retry",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,15-12-2018,4203,high,advanced
9864d55e-8695-4ca2-a268-c4bab601b7e1,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"lock, gather, await",https://stackoverflow.com/questions/3195773,user_714318,28-12-2020,1118,medium,beginner
e55dab4c-c680-4d5f-85fa-18de7bf48abe,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"lock, async, semaphore",https://stackoverflow.com/questions/2375453,user_449589,04-08-2018,2426,medium,beginner
70d80e68-b2c8-4d30-bb2a-d1dcb9a2c0b9,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"postgresql, query, transaction, migration, connection-pool",https://github.com/alembic/alembic/issues/7344,contributor_3601,25-08-2018,216,medium,beginner
411e198a-8dd7-4c68-94b2-bd3225c6cf62,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"flask, dependency-injection, orm, rest, pydantic, routing",https://stackoverflow.com/questions/7754864,user_773587,27-03-2024,435,medium,advanced
9d095a36-20f2-482a-ab01-f694dbfad5a9,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"dataframe, array, vectorization, merge, numpy, pandas",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,27-12-2020,1342,high,intermediate
e8f9c554-f2ce-47d6-a024-b3242f05119f,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"headers, requests, authentication, oauth, retry, http",https://stackoverflow.com/questions/1604451,user_885136,29-04-2019,637,medium,beginner
fc4019f2-0b39-4271-b476-34da16810337,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"executor, coroutine, await",https://github.com/cpython/cpython/issues/5591,contributor_1630,03-01-2024,332,high,beginner
1bac8e53-e9ad-4be4-bafb-b1a9b2056cd0,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"threading, race-condition, event-loop, await, lock, semaphore",https://stackoverflow.com/questions/3195773,user_714318,26-04-2024,1067,medium,advanced
bd59a931-8e1c-421e-a943-67c7f4fd5336,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"transaction, query, orm, connection-pool, sqlite",https://stackoverflow.com/questions/9436429,user_974047,05-11-2022,2423,medium,beginner
22e08b61-6acd-4a77-bcbd-824f992f64ba,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","flask, request, pydantic, fastapi",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,20-03-2020,2894,high,advanced
bc5a6dea-cac6-4529-84bc-870f70f224e0,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"migration, sqlalchemy, connection-pool, orm",https://stackoverflow.com/questions/7358113,user_12260,13-03-2022,245,medium,intermediate
88c4a0fe-a7a2-4ff3-938a-8d53e7cb4a59,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"flask, template, request, orm",https://github.com/flask/flask/issues/2141,contributor_5020,08-09-2024,165,medium,intermediate
4156e63e-ab72-43b4-915d-eb247feb915a,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"executor, gather, event-loop, lock, deadlock",https://github.com/cpython/cpython/issues/5591,contributor_1630,17-08-2022,331,medium,intermediate
9d7184dc-b8a2-44ef-98ca-8a1f7885a0fe,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"race-condition, deadlock, semaphore, threading",https://stackoverflow.com/questions/3646552,user_469469,07-05-2021,1507,medium,intermediate
5f13b38c-0ba7-424f-965b-b2655a06da20,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","postgresql, transaction, foreign-key, sqlalchemy, orm",https://stackoverflow.com/questions/5977931,user_238275,28-03-2019,647,medium,beginner
e79be205-d183-489e-84a7-91d82d603373,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"json, httpx, authentication, rest-api, oauth, aiohttp",https://github.com/httpx/httpx/issues/8949,contributor_1420,25-10-2018,455,low,advanced
c77dc5cb-51a0-43a6-967c-868aa70b1294,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"dtype, broadcasting, groupby, pandas, numpy",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,20-03-2023,1334,high,beginner
7a5ef0f3-c74d-474e-b6cc-112e9df1f65e,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"request, rest, pydantic, template",https://stackoverflow.com/questions/8077999,user_202401,07-06-2023,1846,high,beginner
06f81827-d5ad-4f29-bd5a-5034e9f6b382,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"postgresql, transaction, connection-pool",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,17-08-2021,2073,low,advanced
3aacf486-04d0-4c0b-92ca-979e7714ac78,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"response, pydantic, request, flask, routing",https://stackoverflow.com/questions/8930103,user_264801,10-03-2023,2197,high,beginner
5e2dc0aa-91ed-4417-8b9d-8137cc628179,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"rest, middleware, orm, response, pydantic",https://docs.flask.org/en/stable/@app/route.html,Official Docs,26-10-2019,3003,high,beginner
b6d3296b-1303-4260-876b-674d53853829,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"subprocess, stdin, pathlib, os, process, stdout",https://docs.os.org/en/stable/os/environ.html,Official Docs,11-08-2020,2208,high,beginner
43ea60f0-f9a0-42cf-b788-23b42815a790,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"pipe, pathlib, glob, subprocess",https://stackoverflow.com/questions/2737893,user_994539,15-05-2018,2262,high,intermediate
6cfbba59-7e33-4e1e-8b77-442824f206bf,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"dependency-injection, pydantic, middleware, routing",https://docs.flask.org/en/stable/@app/route.html,Official Docs,01-06-2018,3016,high,intermediate
acec6be5-0d0a-4d39-8ea5-f279f6b68d44,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"aiohttp, websocket, requests, json, headers",https://stackoverflow.com/questions/3592974,user_980733,09-08-2024,1696,high,beginner
7c0891fd-adf6-4983-8c48-55f101c00355,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"stderr, env-variable, pathlib, stdout, subprocess",https://stackoverflow.com/questions/2737893,user_994539,26-06-2022,2287,medium,beginner
279a9d23-2f32-4627-ab29-86d473c5e0b0,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"aiohttp, json, retry, http",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,31-05-2018,58,high,beginner
cfdb6bb1-0871-4c87-bd99-7ecbd55bab63,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"alembic, session, query",https://github.com/alembic/alembic/issues/7344,contributor_3601,01-11-2018,261,high,advanced
b073ca24-a0a4-46d8-a7d8-5cf7a7505c2c,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"websocket, rate-limiting, httpx",https://stackoverflow.com/questions/8896868,user_243238,20-02-2022,1575,high,intermediate
cbb557a6-70c0-43dc-bef1-3dc71f3dbb1a,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"blueprint, routing, dependency-injection, orm",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,04-09-2019,340,high,intermediate
4aaea669-bfa0-4c75-a209-101d6fa8aee0,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"shutil, os, stdout, process",https://docs.os.org/en/stable/os/environ.html,Official Docs,18-01-2022,2216,high,intermediate
fed15f29-2177-4945-87a9-11291564d8a3,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"postgresql, query, migration, relationship",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,14-05-2023,3055,low,advanced
4eb2050e-2c96-4785-9430-134f37f20096,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"request, pydantic, routing, blueprint",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,14-09-2018,321,medium,beginner
458cd673-428f-4dc6-b0b8-dd3b39105575,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"pydantic, blueprint, dependency-injection, rest, django",https://stackoverflow.com/questions/7754864,user_773587,11-08-2023,385,high,beginner
c8cc9c2e-3628-4ff3-b930-0e47758f4203,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"rate-limiting, websocket, oauth, headers",https://github.com/httpx/httpx/issues/8949,contributor_1420,21-10-2022,442,high,beginner
c4651ff8-a452-480f-a04c-6a442bfcbe3b,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"json, timeout, requests, httpx, oauth",https://stackoverflow.com/questions/1669324,user_952590,31-01-2022,1491,high,beginner
e0192a36-17e0-434e-baee-2cfd583be8d8,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"django, fastapi, dependency-injection, template, request",https://stackoverflow.com/questions/7754864,user_773587,08-08-2023,432,low,beginner
1f218e1e-8265-45d7-8686-65ef21834920,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"nan, reshape, array, groupby, pivot",https://github.com/pandas/pandas/issues/8446,contributor_6648,23-07-2019,304,high,advanced
ee539032-6b5f-4bc8-b855-9027d8755f9e,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","groupby, iloc, pandas",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,07-12-2024,1852,medium,advanced
718073f4-6070-460d-a5f2-e5e3a516c107,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","query, migration, sqlite, alembic, sqlalchemy",https://stackoverflow.com/questions/5977931,user_238275,08-02-2019,665,medium,advanced
e2ae6609-491e-4f80-a546-e5fb2ceab2d4,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"task, semaphore, event-loop, executor, threading, asyncio",https://stackoverflow.com/questions/2140194,user_718011,17-06-2021,291,high,beginner
eced8047-9c83-4e9a-bfab-9582e999abdb,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"pipe, stdin, shutil, tempfile, stdout, process",https://github.com/cpython/cpython/issues/7712,contributor_8802,17-12-2023,425,low,intermediate
e4bc9e33-6ba9-4f1f-a695-a2b9f155756d,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"shutil, file-io, subprocess",https://github.com/cpython/cpython/issues/2707,contributor_7877,25-06-2019,464,high,intermediate
d5f5ddd3-3b15-402a-9770-efb76535ba6d,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"aiohttp, headers, websocket, requests, rest-api",https://stackoverflow.com/questions/1669324,user_952590,05-01-2022,1503,high,beginner
42d59678-6ff2-4404-ad30-37f2be598cf8,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"fastapi, pydantic, response",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,27-01-2019,325,medium,intermediate
42424893-77bb-4439-9673-0d67624e098f,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"oauth, httpx, http, timeout, headers",https://stackoverflow.com/questions/8896868,user_243238,28-06-2018,1561,high,beginner
dc23103f-6f43-4bd7-bc5e-ce093950df21,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"await, threading, async, event-loop",https://stackoverflow.com/questions/3646552,user_469469,04-02-2024,1523,high,advanced
cdc6a135-0597-4ada-b086-20f6671f6f33,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"deadlock, task, event-loop, asyncio, gather",https://stackoverflow.com/questions/2229110,user_573750,27-03-2020,2332,low,intermediate
85e50969-d5b9-476c-9787-0c7f212c07c1,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"aiohttp, retry, json, requests, oauth, websocket",https://stackoverflow.com/questions/3592974,user_980733,15-10-2020,1674,medium,intermediate
7bca433f-f049-4882-ba3a-50824c7186a5,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"aiohttp, http, websocket",https://github.com/requests/requests/issues/4019,contributor_4599,01-05-2020,263,high,beginner
6179cd88-c9c4-465e-9c78-dfc9022c1733,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"dtype, broadcasting, loc, numpy",https://stackoverflow.com/questions/6438436,user_522340,17-02-2020,1,high,intermediate
fe4f322d-34b5-4a9f-b5f5-320ff224da5b,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"executor, deadlock, task",https://stackoverflow.com/questions/2375453,user_449589,15-10-2024,2442,medium,beginner
d08ad5e7-f37f-4ae4-aeca-a57045f967e9,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"oauth, rate-limiting, http, authentication",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,04-10-2018,4202,medium,advanced
ac86da7d-032c-4659-a993-936393d7a1fb,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"middleware, template, request, flask, dependency-injection, routing",https://github.com/django/django/issues/3243,contributor_6988,12-08-2018,84,high,advanced
00a88d9b-a279-4266-bbc8-2b7fee44c520,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","sqlite, postgresql, alembic, relationship",https://stackoverflow.com/questions/1247595,user_107793,08-03-2023,395,medium,intermediate
cb195781-c89e-4758-b0d2-c09aa58de832,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","orm, connection-pool, foreign-key",https://stackoverflow.com/questions/1247595,user_107793,26-08-2020,411,medium,beginner
444ce7b8-8744-4618-a7a8-bb8e4364b093,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"broadcasting, nan, pandas, merge, pivot",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,06-03-2023,847,high,advanced
e7b2ab3c-9465-43bd-92d7-876a7105435e,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"subprocess, process, shutil, stdin, glob, pathlib",https://stackoverflow.com/questions/5727085,user_644210,10-01-2022,633,medium,beginner
fa434176-1d15-427c-8ef3-0123ddb010eb,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"coroutine, race-condition, async, deadlock",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,28-04-2023,4845,high,advanced
c88ebec2-aca1-4f0c-8042-16ab319f5919,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"broadcasting, nan, dtype",https://github.com/pandas/pandas/issues/3264,contributor_6628,15-02-2022,39,high,intermediate
9a01aa2a-df53-4c95-8a32-e2ff817c0a7b,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"task, async, await",https://stackoverflow.com/questions/2140194,user_718011,21-08-2020,290,medium,intermediate
2fe4282b-79f6-4b37-b369-99b5dffdf2b9,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","middleware, dependency-injection, orm",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,07-06-2023,2838,medium,intermediate
92b380dd-981d-4ff6-b418-3647c920e09f,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"fastapi, middleware, response, dependency-injection",https://stackoverflow.com/questions/8930103,user_264801,20-10-2023,2236,low,beginner
82087894-6123-475b-ab74-3dbe23b79e85,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"oauth, timeout, http, json, rate-limiting",https://stackoverflow.com/questions/1604451,user_885136,15-01-2022,645,low,beginner
24af0c29-4b87-4e7a-8d94-be34d8b0d0ef,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"rate-limiting, requests, authentication",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,15-09-2020,4231,medium,intermediate
6c306988-1a9a-4676-b268-8318dd16553a,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"threading, gather, lock, async, deadlock",https://github.com/cpython/cpython/issues/4111,contributor_7884,25-09-2019,2,medium,intermediate
54571af3-9310-427d-a215-c27d2099d459,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"fastapi, response, blueprint, flask, rest",https://stackoverflow.com/questions/1527021,user_911393,23-12-2023,944,high,advanced
53b35be1-0e26-4c89-9dea-6c4d70a6db7f,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"postgresql, sqlalchemy, transaction, migration",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,11-03-2023,3031,high,beginner
f1968080-5de3-46ef-b639-1eea3e1f5452,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"routing, dependency-injection, orm",https://stackoverflow.com/questions/1527021,user_911393,25-10-2022,937,high,beginner
f30039ac-3ca2-4839-8205-f7bc8c633283,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"orm, flask, dependency-injection, fastapi, routing",https://docs.flask.org/en/stable/@app/route.html,Official Docs,10-08-2023,3036,medium,intermediate
7c16f7e6-4ffd-4328-b54c-16d8f97de9c6,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"semaphore, gather, coroutine, async, threading",https://github.com/cpython/cpython/issues/5591,contributor_1630,21-07-2019,356,high,advanced
79a6428f-8934-4c5e-b012-323b80e3c5a8,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"os, subprocess, pathlib, shutil, tempfile",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,03-08-2024,3229,high,beginner
568d4954-8ec7-4bd3-b016-6abbac622124,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"relationship, query, foreign-key, connection-pool, transaction",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,29-04-2023,265,medium,advanced
0ad78bc6-5f2e-4bf8-a486-1e85d3d79333,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","postgresql, query, sqlite, transaction",https://stackoverflow.com/questions/1247595,user_107793,02-02-2023,433,medium,advanced
2f8414d9-fd05-4fb6-9be3-092f5ce8471c,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"httpx, rest-api, timeout, aiohttp",https://stackoverflow.com/questions/1669324,user_952590,17-09-2020,1500,low,advanced
5fb585c8-8767-4435-883b-109d86c1de36,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"template, rest, flask, response, middleware, routing",https://stackoverflow.com/questions/7754864,user_773587,14-11-2024,433,high,beginner
b1fd4cd3-2fe1-4bd6-aba9-9f75660e56df,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","dtype, merge, dataframe, pandas, nan, reshape",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,21-10-2018,1889,high,beginner
a18b5fc5-efbd-4147-956c-134902546ef0,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"file-io, stdout, os, process, stdin, glob",https://stackoverflow.com/questions/5727085,user_644210,09-11-2024,675,low,advanced
270f8a98-0192-455b-871f-c22a4c886dce,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"json, retry, requests, timeout, http, authentication",https://stackoverflow.com/questions/1669324,user_952590,05-01-2019,1512,medium,advanced
dae90fbd-954e-4f2f-94bb-7ba09b6eda19,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"connection-pool, postgresql, foreign-key, alembic, relationship",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,07-09-2019,3020,high,beginner
8b924b76-7f31-4452-9df7-e4fbbdb750f3,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","rest-api, json, headers, timeout",https://stackoverflow.com/questions/7907400,user_851204,20-02-2019,1355,medium,advanced
7ed4ecde-1e44-4e8c-928c-33670a8e3e69,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"lock, executor, await",https://stackoverflow.com/questions/2375453,user_449589,01-07-2019,2455,high,intermediate
7ba69af9-baf0-413b-9161-ca339f401265,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"retry, rest-api, httpx, requests",https://stackoverflow.com/questions/3592974,user_980733,22-07-2021,1666,high,beginner
6c78cabb-77a0-42e4-a67f-83bb37abe274,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"semaphore, asyncio, threading, executor, async",https://stackoverflow.com/questions/2375453,user_449589,19-09-2023,2449,medium,intermediate
b4eca5bd-3474-4d7e-b22b-461308606d62,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"relationship, postgresql, migration, sqlite",https://stackoverflow.com/questions/7358113,user_12260,06-09-2021,259,high,advanced
c5767e47-76e8-4fca-8daa-645c20028b49,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"alembic, relationship, postgresql, migration",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,11-01-2022,262,low,intermediate
baf6a521-3d2b-49fd-8c32-2f37d35d69fd,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","vectorization, broadcasting, iloc",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,04-04-2020,1892,high,intermediate
05d38304-7d0c-400b-9b13-8d4cab200bbd,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"rate-limiting, json, requests",https://stackoverflow.com/questions/1604451,user_885136,08-01-2022,607,high,beginner
9e652b1a-240d-40a2-b7e8-957bdf78eb03,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"json, authentication, websocket, rest-api, headers, http",https://stackoverflow.com/questions/1669324,user_952590,25-07-2024,1489,low,intermediate
300eed94-19bb-46bd-9538-6fe24bfc695e,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","semaphore, async, executor, race-condition, lock, coroutine",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,23-06-2024,518,medium,intermediate
9482c227-0776-46bf-bb9f-187c6004b22f,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"await, race-condition, threading, task, deadlock, semaphore",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,06-10-2021,4812,high,beginner
2d330121-29be-4af7-aa74-c4b2ef8817a3,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"nan, groupby, vectorization",https://github.com/pandas/pandas/issues/8446,contributor_6648,23-02-2023,344,medium,intermediate
2220ff68-392f-4923-97c5-6464d2c6f8cd,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"deadlock, async, threading, await",https://stackoverflow.com/questions/2140194,user_718011,04-07-2019,314,medium,advanced
e59cfb01-341a-49c3-9892-dbfd7c62af7d,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"rest, template, request",https://docs.flask.org/en/stable/@app/route.html,Official Docs,16-03-2022,2996,high,beginner
1f4c34ed-fe19-40fc-a148-f7f64d7096ef,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"loc, nan, dtype, numpy, iloc, array",https://stackoverflow.com/questions/6438436,user_522340,23-12-2023,33,low,advanced
1780de86-7d17-4722-8dc1-4ebe79c4c52f,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"stdout, shutil, os, stdin",https://github.com/cpython/cpython/issues/2707,contributor_7877,29-05-2018,487,medium,intermediate
94585900-20d6-4af3-ba35-de071695e35d,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"pathlib, tempfile, stdin, process, pipe, glob",https://stackoverflow.com/questions/5213115,user_959314,10-02-2019,2107,high,beginner
1a6aba4c-7581-4467-985b-8fcf88d0d395,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"response, fastapi, flask",https://stackoverflow.com/questions/8106470,user_441071,29-06-2023,1764,low,advanced
aff533d3-368f-4e33-a857-9eaee89fdf17,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"subprocess, stdout, process",https://stackoverflow.com/questions/5727085,user_644210,12-05-2020,646,high,advanced
37b125f0-860a-4c82-9d39-5cd9900580ba,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"async, task, await",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,13-06-2019,4835,low,advanced
51f93e99-00ce-4fbb-a134-a8162759f8c0,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"asyncio, task, lock, threading",https://github.com/cpython/cpython/issues/5591,contributor_1630,20-06-2023,360,high,intermediate
5d9070ab-89d6-4a09-9651-03e2867e2f5e,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"vectorization, broadcasting, array, pandas, nan",https://github.com/pandas/pandas/issues/4449,contributor_726,04-03-2024,488,medium,intermediate
f64a3471-e379-4276-b09f-2d38bdc7fd49,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"pivot, nan, dataframe, groupby, reshape",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,29-11-2020,797,high,advanced
15994367-e764-48e1-9ab1-e705064fb4db,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"os, env-variable, pathlib, stderr, process",https://github.com/cpython/cpython/issues/8586,contributor_7711,23-02-2023,446,medium,advanced
acf54ac1-a885-44c2-9654-9be9b9cc3f6a,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"relationship, postgresql, migration, connection-pool",https://github.com/alembic/alembic/issues/7344,contributor_3601,24-09-2024,231,high,intermediate
0c04f5b2-70d7-449b-9765-369567507f8b,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","alembic, sqlite, relationship, postgresql, orm",https://stackoverflow.com/questions/5977931,user_238275,17-08-2019,669,medium,beginner
634a1bd6-ade2-421a-bb64-afd7bc6c8295,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"http, requests, json, retry, oauth",https://stackoverflow.com/questions/1604451,user_885136,18-07-2023,618,high,beginner
16c0e347-e666-4a3d-8b3d-2830eb4dc337,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"flask, django, pydantic, rest, response",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,10-01-2019,2390,high,intermediate
1ec00635-1f97-49ec-a87c-a3fca3e48823,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","gather, threading, coroutine",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,29-09-2024,496,medium,beginner
3ec29d23-034c-4373-b23a-8c77ae8fb0bf,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","transaction, alembic, foreign-key, connection-pool",https://stackoverflow.com/questions/5977931,user_238275,28-08-2018,644,high,advanced
40d9bc83-2a6c-48a6-ac07-f4eca89676f8,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"blueprint, pydantic, fastapi, response",https://github.com/flask/flask/issues/2141,contributor_5020,26-02-2023,136,low,beginner
88a93267-cde5-4c42-92f2-56389b5c0f9e,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"response, blueprint, fastapi, django",https://stackoverflow.com/questions/8106470,user_441071,13-06-2021,1751,medium,beginner
4497af6c-a02c-4dbd-9e4d-fe9d5d0e06ce,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","array, nan, dtype",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,03-08-2019,4515,high,advanced
f576d553-989b-4097-a3cd-7c2278fb2669,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"connection-pool, migration, foreign-key, orm, postgresql, transaction",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,21-09-2022,2058,medium,beginner
96c37d08-22ff-41ed-8825-fd0eefaf6360,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"middleware, fastapi, pydantic, flask",https://stackoverflow.com/questions/8106470,user_441071,05-06-2022,1797,low,intermediate
02f50f29-89f9-4957-a7df-8b6f4dccc50b,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"stdin, stderr, glob, process",https://docs.os.org/en/stable/os/environ.html,Official Docs,21-08-2022,2224,high,intermediate
b2400fc3-76f6-4704-adcf-5fba52c063c0,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"glob, file-io, tempfile, subprocess, shutil, process",https://stackoverflow.com/questions/5727085,user_644210,11-10-2021,633,medium,beginner
bad8970c-0c2b-4d2c-9829-dbe0ce0438ad,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","pipe, file-io, process, tempfile, env-variable, stdin",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,31-01-2018,414,high,intermediate
a5a7f873-62f1-474f-b938-463fbf945ef4,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"coroutine, semaphore, gather, lock, await",https://stackoverflow.com/questions/2229110,user_573750,18-04-2021,2306,high,beginner
38799911-32c3-4bd7-9baf-d138bd538322,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"pathlib, stdin, subprocess",https://stackoverflow.com/questions/5394880,user_179430,22-02-2019,567,high,advanced
9b7820a6-3923-4081-ad29-f537ea12ac74,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"rate-limiting, headers, timeout, rest-api, aiohttp, websocket",https://github.com/requests/requests/issues/3605,contributor_1152,31-12-2022,391,high,advanced
cc1e4b66-c778-4bab-9c65-1700db66e4b5,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"template, fastapi, routing, orm",https://stackoverflow.com/questions/8930103,user_264801,05-08-2023,2206,high,beginner
5050fa50-175a-427a-ac81-db89b158ad0b,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"vectorization, iloc, merge, reshape, pivot",https://stackoverflow.com/questions/2321324,user_99814,05-04-2020,219,low,beginner
b6e7b06c-8709-4878-b7ba-bbcfbd9dc994,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"routing, dependency-injection, response, middleware, fastapi",https://docs.flask.org/en/stable/@app/route.html,Official Docs,11-05-2023,3001,low,beginner
e6220e3e-9c10-4655-addd-d90e1fc87570,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"dtype, nan, iloc, vectorization, merge, numpy",https://github.com/pandas/pandas/issues/3264,contributor_6628,18-04-2019,35,medium,intermediate
8e092a24-0501-4720-8714-fe2799756f1f,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"semaphore, race-condition, task, gather, executor",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,25-09-2018,4161,high,beginner
20c43b14-ce57-4bd3-a92a-f54eeae50530,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"os, subprocess, process, tempfile",https://github.com/cpython/cpython/issues/2707,contributor_7877,19-08-2018,440,low,intermediate
63400391-8b82-433c-9a8c-3a7c699ab454,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rest-api, timeout, httpx, requests, aiohttp, rate-limiting",https://stackoverflow.com/questions/1669324,user_952590,22-05-2021,1503,medium,beginner
2c6a55c4-451a-4638-acbd-83c4326ded0f,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","groupby, iloc, vectorization, pandas",https://stackoverflow.com/questions/5446912,user_563306,06-11-2019,2241,low,intermediate
a92277aa-9ee9-4fdd-937e-9da8f7b73208,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"gather, executor, await, task",https://stackoverflow.com/questions/2229110,user_573750,28-04-2022,2298,medium,beginner
b37d3a2a-e6b8-40f9-9c72-2409eecf91d7,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"sqlalchemy, sqlite, relationship, orm, connection-pool, query",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,20-02-2020,300,high,intermediate
3b0b9cba-3b53-44d1-ae1c-e6d79efad2b5,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"event-loop, deadlock, race-condition, executor, threading",https://stackoverflow.com/questions/2140194,user_718011,28-03-2020,275,high,advanced
5cad7d1e-18f7-4c02-b505-90726720c9e3,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","alembic, sqlalchemy, sqlite",https://stackoverflow.com/questions/1247595,user_107793,01-07-2024,395,low,advanced
cca621c4-c5d7-4df2-a068-a41513162c4c,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"pivot, dataframe, reshape, dtype, numpy, loc",https://stackoverflow.com/questions/6438436,user_522340,06-08-2018,1,medium,beginner
7b7327c5-f2dd-4db2-9167-a553a562351d,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"merge, reshape, loc, numpy, nan, broadcasting",https://stackoverflow.com/questions/4860684,user_627024,01-02-2024,1393,high,intermediate
9b4c1039-94bb-4919-bf34-d07b2a54439b,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"threading, task, gather",https://github.com/cpython/cpython/issues/4111,contributor_7884,22-11-2020,38,medium,advanced
fa5d7323-c258-4c91-a861-96104f03d838,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"flask, rest, template, routing, request, blueprint",https://stackoverflow.com/questions/8106470,user_441071,25-05-2024,1769,medium,intermediate
66e556fa-a0a1-464f-a6f4-20b4e129c9ec,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"task, lock, threading, await, semaphore, executor",https://stackoverflow.com/questions/3195773,user_714318,29-04-2020,1102,low,intermediate
cb1f3f90-f0b3-48c8-8c4f-d5492e1055dc,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"stderr, pipe, os, shutil",https://stackoverflow.com/questions/5727085,user_644210,03-06-2020,668,high,beginner
d7faab7f-3280-4954-8e0b-21e2f24e1d62,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"transaction, sqlite, migration",https://stackoverflow.com/questions/7358113,user_12260,29-12-2020,241,medium,intermediate
8130c8d2-8b73-4e7c-bc25-1128faee5996,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"pipe, tempfile, shutil, stdout, os",https://stackoverflow.com/questions/5727085,user_644210,26-01-2024,665,high,beginner
c622b562-7ddf-4c84-8539-dc014e9da1e4,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"numpy, vectorization, reshape, iloc, pandas",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,21-01-2021,1316,medium,intermediate
6b4b17e8-6386-4055-9bb6-a1e72a6934b3,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"query, connection-pool, transaction, sqlite, relationship",https://stackoverflow.com/questions/7358113,user_12260,24-03-2023,240,high,intermediate
ce3726a9-66bb-4ac7-8923-73f8f7ccb96e,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"coroutine, asyncio, event-loop, deadlock, gather, semaphore",https://stackoverflow.com/questions/3646552,user_469469,04-11-2018,1503,high,beginner
7c79f4f3-13a0-402e-986c-fbd6d7619809,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"rest-api, rate-limiting, httpx, json, aiohttp, headers",https://stackoverflow.com/questions/3592974,user_980733,19-09-2023,1658,medium,beginner
a0def889-3002-42c3-85b5-191496039f7b,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"template, dependency-injection, django, orm, routing, flask",https://stackoverflow.com/questions/7754864,user_773587,30-04-2019,396,medium,advanced
9d62678e-54a7-4427-8bda-6ba66d1a94bd,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"authentication, rate-limiting, json, aiohttp, timeout, httpx",https://github.com/requests/requests/issues/3605,contributor_1152,09-02-2019,395,low,beginner
098d9d47-d2a7-4b5c-b1c3-2f055d13b7b2,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"pandas, dataframe, numpy, pivot",https://stackoverflow.com/questions/6438436,user_522340,28-05-2019,27,medium,intermediate
4b519eb6-677c-4193-bc40-c1be1b86a910,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"postgresql, sqlite, connection-pool, query, migration",https://stackoverflow.com/questions/9436429,user_974047,10-07-2021,2383,low,intermediate
dc68a09a-aaa3-4ed1-ac86-12e06b73f18f,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","pipe, env-variable, shutil, stderr, stdout, file-io",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,08-10-2018,416,high,beginner
1c76a9e1-6357-4989-9050-0ac76e20ebdd,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"deadlock, async, asyncio, semaphore",https://stackoverflow.com/questions/2229110,user_573750,23-05-2020,2316,high,advanced
18fb5e13-2c9f-4cb2-852c-bd04fe14e877,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"stderr, subprocess, env-variable, tempfile",https://stackoverflow.com/questions/2737893,user_994539,18-02-2023,2260,low,intermediate
7563d01c-c6f6-4f81-9aae-69fc929169d6,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"template, orm, flask",https://stackoverflow.com/questions/8106470,user_441071,10-11-2023,1752,high,beginner
461d03c6-f343-4cf4-9959-4662492ed0a4,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"orm, blueprint, routing",https://stackoverflow.com/questions/8106470,user_441071,26-12-2021,1759,high,beginner
ad009653-07d6-464d-826b-01eb2aad1e14,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","dtype, loc, groupby, numpy, pandas",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,14-05-2022,1861,high,intermediate
61699cf2-99c3-4112-a9a6-9bdeb818ccbb,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"fastapi, rest, dependency-injection",https://stackoverflow.com/questions/7754864,user_773587,07-06-2019,437,high,intermediate
08cd2ee4-f668-403f-b9e7-3c8133ff801a,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"request, rest, pydantic, response",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,27-04-2023,315,high,advanced
611979f2-0e88-4f37-a674-cffa45ec9fa9,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"reshape, dtype, merge",https://stackoverflow.com/questions/6438436,user_522340,12-02-2020,41,medium,advanced
9919ba82-cd91-4f29-a759-451e37ad806e,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"gather, await, semaphore, task, lock, executor",https://github.com/cpython/cpython/issues/4111,contributor_7884,11-02-2023,55,medium,advanced
7a3f54c9-8888-4592-9b59-34ffbec73e28,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"broadcasting, loc, groupby, merge, dataframe, numpy",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,29-12-2022,830,high,beginner
c48262e5-f9f4-42cf-8e05-69d1e9c32bff,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"sqlalchemy, sqlite, migration, alembic",https://stackoverflow.com/questions/7358113,user_12260,11-09-2020,277,medium,advanced
7132e6d4-daa1-49a8-a578-b6c3ec35f4f5,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"stdout, stdin, pathlib, subprocess, pipe",https://stackoverflow.com/questions/5727085,user_644210,07-04-2020,672,high,intermediate
0c0f3342-d1ce-4103-aaed-fff670c5a44b,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"flask, template, rest, middleware, response, django",https://github.com/flask/flask/issues/2141,contributor_5020,11-01-2018,144,high,intermediate
93294c46-0f28-43c1-bc24-1345643af66d,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"alembic, transaction, connection-pool",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,25-07-2023,3038,high,intermediate
64ed976a-8230-4fe3-8d85-62940fe6a52a,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"dataframe, merge, loc, iloc",https://stackoverflow.com/questions/6438436,user_522340,18-06-2022,3,medium,intermediate
f2db3151-c16b-4474-9148-0397479201a3,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","alembic, postgresql, session, orm, relationship",https://stackoverflow.com/questions/5977931,user_238275,24-08-2018,637,high,advanced
95d57332-3e25-4350-adf7-3c73505abffe,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"tempfile, stdout, shutil, stdin",https://stackoverflow.com/questions/2737893,user_994539,07-12-2021,2285,medium,intermediate
475f871a-72d4-4a99-b3ff-9663e1e20435,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"orm, dependency-injection, django, response",https://github.com/django/django/issues/8618,contributor_8921,13-12-2018,21,low,advanced
c92835d9-c9bc-4a4f-823c-2517e8e951f0,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"threading, await, executor, asyncio, task",https://stackoverflow.com/questions/3195773,user_714318,03-05-2020,1097,medium,intermediate
fdaffda1-58f8-440d-9abd-51b417b245c6,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"file-io, stdin, stdout, shutil",https://stackoverflow.com/questions/5213115,user_959314,28-07-2018,2080,high,beginner
e495844e-5b0c-484b-9a93-674b1a02692a,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"rest, dependency-injection, orm, flask",https://github.com/django/django/issues/8618,contributor_8921,11-07-2018,24,high,advanced
f82d3dc9-3acc-4264-bc08-f09e7d80d76c,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","aiohttp, retry, authentication, requests, headers",https://stackoverflow.com/questions/7907400,user_851204,15-11-2023,1397,high,beginner
10a70b2d-e915-4b8d-9b28-45f77f671cd6,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"iloc, array, merge",https://github.com/pandas/pandas/issues/3264,contributor_6628,24-04-2022,12,medium,advanced
2d7e50cb-ce4e-4400-bd85-e8cb3668ffb4,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","deadlock, task, threading, async, lock, asyncio",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,13-07-2020,533,medium,advanced
eb306a79-4405-4450-946c-70d60054e426,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"timeout, aiohttp, websocket",https://stackoverflow.com/questions/8896868,user_243238,05-07-2023,1558,high,beginner
c3696374-a7e8-4813-8abd-4e3e92a06328,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"array, nan, pivot, groupby, broadcasting, numpy",https://github.com/pandas/pandas/issues/3264,contributor_6628,06-08-2022,5,high,beginner
9a9867e3-7841-4f74-921c-69f152c660d8,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","iloc, broadcasting, array, dtype, pivot",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,01-04-2024,4519,medium,beginner
66fe7fc2-a6c6-4a8d-8015-a38c8356d8b3,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"middleware, response, flask, fastapi, routing",https://stackoverflow.com/questions/8106470,user_441071,09-02-2019,1765,high,beginner
b3d02ee4-32c4-45ba-8147-4cd66c2e6779,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"iloc, reshape, nan",https://stackoverflow.com/questions/6229731,user_428373,10-03-2022,833,high,intermediate
0f5b7309-553b-49f5-9649-5ac0a00e7389,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"pathlib, glob, pipe, shutil, tempfile",https://stackoverflow.com/questions/5213115,user_959314,13-10-2023,2058,low,intermediate
8729e38d-dbd3-4ed6-afee-5ec16dbdd981,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","pivot, pandas, array",https://stackoverflow.com/questions/5446912,user_563306,13-05-2018,2259,high,intermediate
46ab343a-daff-4056-bf11-e34b0e3f061f,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"blueprint, flask, middleware",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,02-11-2022,287,high,beginner
4e5c2fbe-0ce6-41d5-955c-d0e76ee0c007,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"relationship, sqlite, connection-pool, session, alembic, postgresql",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,29-08-2018,2085,high,beginner
34bc285c-db76-49ba-940f-dac72b6c6f55,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"sqlite, connection-pool, session, query",https://github.com/alembic/alembic/issues/7344,contributor_3601,25-07-2023,249,medium,intermediate
63fa51b9-c2a3-467a-9f80-f5a0d9654bba,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"event-loop, semaphore, threading, executor, lock",https://github.com/cpython/cpython/issues/4111,contributor_7884,07-03-2023,9,high,beginner
6bd3d061-afe5-4e77-a969-85efec648232,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"stderr, shutil, process",https://stackoverflow.com/questions/2737893,user_994539,05-08-2024,2288,low,beginner
21090ed8-e00c-4abe-93a0-aa64bb237c96,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","threading, lock, await, task, coroutine",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,21-10-2020,492,high,intermediate
7d5d281a-6a3e-428c-afdc-27659a924795,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","session, query, relationship, postgresql, transaction, sqlalchemy",https://stackoverflow.com/questions/5977931,user_238275,28-02-2021,663,medium,intermediate
f413e23b-fdda-4934-a22d-53b2d605837a,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rest-api, httpx, oauth, retry, timeout, json",https://stackoverflow.com/questions/1669324,user_952590,01-08-2018,1527,high,intermediate
7d6f396d-a683-4bb7-bb29-c75b42258c45,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"middleware, pydantic, request, dependency-injection, blueprint",https://github.com/django/django/issues/8618,contributor_8921,05-03-2021,1,medium,intermediate
0af717e5-b0df-4461-8fea-97161c9af3f1,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","nan, dataframe, pivot, pandas, array, merge",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,08-11-2021,1900,low,beginner
98328fad-c1a2-4ecd-be0b-e60f3ba9a619,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"pydantic, rest, request, dependency-injection, blueprint",https://stackoverflow.com/questions/8106470,user_441071,05-05-2024,1755,medium,beginner
3b6f1cd9-3469-4a29-af56-e991ff2d0e97,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"alembic, transaction, session, sqlalchemy, migration",https://stackoverflow.com/questions/9436429,user_974047,09-02-2024,2422,high,intermediate
bdefb5c3-d430-4b02-bd23-d34656620fff,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"subprocess, os, env-variable, pathlib, tempfile, glob",https://stackoverflow.com/questions/5394880,user_179430,22-01-2023,573,high,beginner
314706bf-4156-4262-bed2-8936fb9f4c58,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"django, pydantic, dependency-injection",https://github.com/django/django/issues/8618,contributor_8921,03-03-2020,1,high,intermediate
09fffb2a-8355-40db-90db-cb827a48d187,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"httpx, aiohttp, requests",https://stackoverflow.com/questions/1669324,user_952590,04-08-2020,1502,high,intermediate
ace783e4-5631-4521-a55c-0a55ab94b82a,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"rest-api, httpx, oauth, rate-limiting, requests",https://github.com/requests/requests/issues/3605,contributor_1152,02-10-2022,340,high,beginner
25a1f393-ad92-44aa-b7c4-e01fce040aad,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"relationship, foreign-key, sqlite, alembic, transaction, connection-pool",https://stackoverflow.com/questions/9436429,user_974047,29-05-2020,2400,high,beginner
c9d69902-0962-4a09-b3ab-f5f9a964472b,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"glob, stdout, file-io, subprocess, stdin, pipe",https://github.com/cpython/cpython/issues/2707,contributor_7877,01-07-2021,470,low,advanced
bc3aabc0-2e74-4fbe-b408-9abc89aad8a0,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"django, response, pydantic, template, flask",https://docs.flask.org/en/stable/@app/route.html,Official Docs,24-02-2019,2988,high,intermediate
60b38591-4152-4b38-a0ca-bffc53400bbf,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"await, race-condition, coroutine, async, asyncio",https://stackoverflow.com/questions/3195773,user_714318,20-10-2023,1117,high,advanced
43cdb84c-cb08-4378-bc79-7c5f6a0545a2,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"sqlalchemy, session, foreign-key",https://stackoverflow.com/questions/7358113,user_12260,12-07-2021,274,high,intermediate
d87f0023-0bcd-4239-b6be-457a2d1dc7f1,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"task, asyncio, gather, async, event-loop, coroutine",https://github.com/cpython/cpython/issues/5591,contributor_1630,26-12-2023,338,medium,intermediate
65546b72-44ef-4b6c-9569-63db4c865849,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"dataframe, pivot, pandas",https://github.com/pandas/pandas/issues/3264,contributor_6628,10-08-2019,42,low,advanced
bbe9225e-81be-402b-a3b1-7bd0e8033872,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"migration, sqlite, orm, transaction, relationship, sqlalchemy",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,18-02-2018,3011,high,beginner
04aaf556-4fb2-4ddb-9da3-7751f5246b8e,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"task, event-loop, await, race-condition, asyncio",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,15-06-2020,4864,medium,intermediate
7357df0c-433c-43af-85c3-23b3272f2f47,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"orm, response, flask, template, middleware, routing",https://stackoverflow.com/questions/8106470,user_441071,22-01-2018,1796,medium,beginner
45bfdfa7-8b89-49ae-81a5-1d83bf0d2098,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"stderr, shutil, subprocess, pathlib, pipe, os",https://stackoverflow.com/questions/5394880,user_179430,01-12-2024,538,medium,advanced
78a40e0a-6f78-4e9d-89d9-79c49ffac98a,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"semaphore, task, threading",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,26-05-2020,4825,high,intermediate
f1573f39-4762-4e6d-a638-900cdd9874be,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"pivot, broadcasting, iloc",https://stackoverflow.com/questions/4860684,user_627024,25-10-2022,1381,high,advanced
7db09454-1d13-4ead-8acf-050a6a0204e4,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"fastapi, blueprint, request, django, rest",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,19-03-2023,321,medium,advanced
ffed51be-2c1c-46a3-b26e-ddec6c52f3f6,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"array, broadcasting, nan, pivot",https://stackoverflow.com/questions/6229731,user_428373,05-05-2019,850,low,advanced
8511bb58-973f-4396-ba27-b7c8321d364c,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"deadlock, semaphore, executor, async",https://stackoverflow.com/questions/3195773,user_714318,26-05-2024,1078,low,intermediate
3f79a80c-ceaf-4dbb-bde7-ecf3560863c9,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","reshape, dataframe, broadcasting, dtype, pivot",https://stackoverflow.com/questions/5446912,user_563306,20-10-2024,2261,high,intermediate
6791cb23-f811-487d-81f7-cf44f6ef746a,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"pydantic, response, blueprint, orm, django",https://stackoverflow.com/questions/8077999,user_202401,25-05-2023,1853,medium,intermediate
446e1ef3-c6ea-43cb-a460-2220d90b0d76,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"rest-api, aiohttp, authentication, timeout",https://stackoverflow.com/questions/8896868,user_243238,08-04-2019,1566,high,advanced
28ba3412-f27c-41fd-b788-56e21d223142,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"reshape, array, loc, pandas, nan, dtype",https://stackoverflow.com/questions/2321324,user_99814,22-12-2020,220,low,intermediate
1c390b34-3ce0-4697-96ee-3f6f7d1984db,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"http, aiohttp, timeout, rate-limiting",https://stackoverflow.com/questions/8896868,user_243238,26-04-2019,1586,high,intermediate
dda118ad-7023-4673-a522-48b314224093,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"semaphore, coroutine, lock, asyncio",https://stackoverflow.com/questions/2375453,user_449589,21-05-2019,2432,medium,advanced
e7a46b3c-ac82-421d-80de-dff515ae64de,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","requests, rate-limiting, websocket, rest-api",https://stackoverflow.com/questions/7907400,user_851204,25-11-2019,1343,low,advanced
5dd859da-9b08-4a8e-8cbb-ae082e81ab30,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"orm, template, rest",https://github.com/django/django/issues/8618,contributor_8921,13-10-2020,17,high,advanced
fd4693a1-6bf0-4739-b549-fcf006cd8829,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"requests, authentication, httpx, rest-api, timeout",https://github.com/requests/requests/issues/4019,contributor_4599,18-12-2024,282,low,beginner
cf8b5954-a8bd-410c-bceb-ede7926cb4ff,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","postgresql, alembic, query, sqlite, session",https://stackoverflow.com/questions/5977931,user_238275,30-12-2024,627,medium,beginner
29246401-885b-40c1-8fa0-aeb8e6f23df7,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"stdin, tempfile, process",https://stackoverflow.com/questions/2737893,user_994539,10-09-2018,2260,medium,advanced
383da64b-ca49-40f1-947e-5b2e33862467,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","websocket, oauth, requests",https://stackoverflow.com/questions/7907400,user_851204,26-04-2020,1357,high,advanced
a76253f7-f18c-413d-9687-c553b8590970,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"retry, rate-limiting, requests",https://stackoverflow.com/questions/3592974,user_980733,10-08-2024,1676,low,beginner
2dd047d6-4bcc-455f-9262-5d2406b02de9,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"response, request, pydantic, middleware, dependency-injection",https://github.com/django/django/issues/3243,contributor_6988,02-04-2023,70,medium,advanced
fc419228-9073-4927-ad57-4f6932b3b5d4,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"array, iloc, broadcasting, numpy, dataframe, reshape",https://github.com/pandas/pandas/issues/3264,contributor_6628,19-07-2018,2,high,advanced
d0724283-d79a-4b24-b369-9bc2eaca1f52,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"migration, session, postgresql, sqlalchemy",https://stackoverflow.com/questions/9436429,user_974047,03-01-2018,2393,high,advanced
18ba3f12-9f8e-40d1-b196-7092581f88b3,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"response, flask, orm, pydantic, routing, fastapi",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,17-08-2018,2425,high,beginner
e79e0353-ef07-46ad-b07e-d2a37fff27fc,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"deadlock, race-condition, gather, coroutine",https://stackoverflow.com/questions/3195773,user_714318,28-06-2018,1083,high,beginner
d84bdecb-ef67-4a96-9ec2-c761820433e1,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"template, blueprint, middleware",https://stackoverflow.com/questions/8106470,user_441071,11-08-2020,1802,high,intermediate
52cf6626-153f-4034-9933-a1a3039b963f,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"middleware, fastapi, response",https://github.com/django/django/issues/8618,contributor_8921,18-03-2021,5,low,intermediate
54b2033b-7f8b-4a29-89dd-62fb617ea541,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"alembic, transaction, session, sqlite, sqlalchemy",https://stackoverflow.com/questions/9436429,user_974047,20-01-2024,2386,high,beginner
a5b9937e-3118-4866-a934-3fb134df1538,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"nan, groupby, pivot, pandas, loc, dtype",https://github.com/pandas/pandas/issues/3264,contributor_6628,20-02-2021,1,low,beginner
23f3ec6b-60a2-4991-a77c-14f2e24cd069,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"dtype, merge, dataframe",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,02-06-2022,824,medium,advanced
8326d809-38a7-4f8f-b26e-f0f4da889871,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"flask, request, routing, template, rest, dependency-injection",https://github.com/flask/flask/issues/2141,contributor_5020,01-09-2023,145,medium,intermediate
f94fe265-bb6d-4237-968c-19bb891b37af,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"django, rest, template, request, blueprint",https://github.com/flask/flask/issues/2141,contributor_5020,14-07-2024,187,medium,beginner
2064dc8f-c507-4e59-93ab-c932ac1bd517,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"deadlock, semaphore, asyncio, threading",https://stackoverflow.com/questions/2375453,user_449589,07-07-2020,2422,medium,beginner
bcb00ac7-d64b-44cf-a0f6-4b4e42f70b1d,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"task, event-loop, await, deadlock, async",https://stackoverflow.com/questions/2140194,user_718011,03-06-2024,295,high,intermediate
9187e694-1a89-49de-80d6-62e37db4f0a3,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"migration, foreign-key, orm, relationship",https://stackoverflow.com/questions/7358113,user_12260,17-06-2023,222,low,intermediate
21eead2b-1b23-4a88-bc72-9c09d2863337,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"env-variable, glob, stdout, stdin, tempfile",https://github.com/cpython/cpython/issues/7712,contributor_8802,16-02-2020,385,low,beginner
9d32051f-b4c2-4363-91d1-2b923e3b9d34,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"env-variable, pipe, stdin",https://stackoverflow.com/questions/5394880,user_179430,06-03-2018,530,high,beginner
8a9401c8-aae5-4895-9f21-7ca4f1a33a8c,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","pydantic, dependency-injection, template, orm",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,18-01-2023,2866,medium,advanced
31015da2-9239-47d5-8fc2-2e1d5265e162,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"executor, task, await, semaphore, gather, async",https://stackoverflow.com/questions/3646552,user_469469,12-07-2023,1544,low,beginner
cf380039-7796-453d-b939-b017f5c83414,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"executor, gather, async, semaphore",https://github.com/cpython/cpython/issues/5591,contributor_1630,13-05-2024,316,medium,beginner
66a2d577-7280-4f81-8ca8-941f2a7f8c56,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"dtype, dataframe, pivot, reshape",https://github.com/pandas/pandas/issues/3264,contributor_6628,17-04-2022,12,high,intermediate
ad6e24e5-9519-47fe-bb1a-56d21f8b8e20,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","flask, response, pydantic",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,05-01-2022,2867,medium,beginner
5b9973dd-9a5b-40a1-b133-16ca1107923b,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"template, django, request, response, routing, middleware",https://stackoverflow.com/questions/7754864,user_773587,13-08-2024,396,medium,beginner
429551ed-94fc-42c0-a1fb-a94d63e4a6d2,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"vectorization, dataframe, loc",https://github.com/pandas/pandas/issues/4449,contributor_726,20-03-2020,497,high,advanced
ed2880c3-63c6-402b-80f4-47a7db2d4a31,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"tempfile, stdin, file-io, pipe, process, shutil",https://github.com/cpython/cpython/issues/2707,contributor_7877,30-05-2023,451,high,advanced
0faa2a30-4a58-491e-805e-6ed2e50ae711,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"pivot, array, loc",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,23-11-2020,1345,high,intermediate
ec13a5b3-8751-4a9b-aba7-f04087b33257,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"routing, middleware, template, blueprint, pydantic",https://stackoverflow.com/questions/8930103,user_264801,22-04-2023,2218,high,intermediate
1b083587-ec99-495c-9aa1-3763bc51454a,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","subprocess, stdin, file-io, pipe, env-variable, stderr",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,03-06-2024,439,high,beginner
957c3d9c-d2cc-49b3-8ecd-2ce887376b1f,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"retry, aiohttp, websocket, requests, headers, rest-api",https://stackoverflow.com/questions/3592974,user_980733,18-03-2024,1687,medium,advanced
1de3b330-f83b-4086-8d81-813e35ae7601,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"shutil, env-variable, subprocess",https://stackoverflow.com/questions/2737893,user_994539,31-07-2018,2293,medium,intermediate
24d9de5d-9406-49b0-9851-35d70a207e21,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"numpy, array, dtype, merge",https://stackoverflow.com/questions/6438436,user_522340,12-07-2023,39,medium,advanced
ef607481-fe65-4985-bbfa-d184a61e4deb,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"middleware, response, rest",https://docs.flask.org/en/stable/@app/route.html,Official Docs,11-09-2024,3020,low,intermediate
233e4b55-3909-4867-9e15-4d9633dffde7,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"async, await, lock, coroutine",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,23-07-2019,4126,high,intermediate
3eca92dd-a76b-4584-8b39-4f5554234ff5,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","headers, requests, aiohttp",https://stackoverflow.com/questions/7907400,user_851204,13-10-2020,1370,high,intermediate
9c2389a0-8eb1-4b66-8f9f-e5d9706727f3,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"alembic, relationship, foreign-key, transaction, connection-pool",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,31-01-2021,2064,medium,advanced
8a792c16-1b89-4fd4-bca7-3b04b43404a6,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","migration, transaction, alembic, session, relationship, orm",https://stackoverflow.com/questions/5977931,user_238275,17-06-2024,616,high,advanced
24dd9eec-42b1-43da-b024-5fe8c4046c38,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"coroutine, deadlock, async, event-loop, race-condition, gather",https://github.com/cpython/cpython/issues/5591,contributor_1630,18-12-2022,338,low,beginner
b89a0a0e-d608-4e9c-85f6-e3ad4a7bb77c,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"session, postgresql, relationship, transaction, sqlalchemy",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,26-03-2022,3010,high,intermediate
f804f050-03dc-495a-a7e4-67ca4844ff70,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"rest, orm, blueprint",https://docs.flask.org/en/stable/@app/route.html,Official Docs,04-12-2019,2988,medium,advanced
7afeb46e-ebd5-4a11-8a8c-b2d053a4af33,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"headers, timeout, rate-limiting, http, oauth",https://stackoverflow.com/questions/1669324,user_952590,23-09-2019,1504,high,advanced
2667407a-b204-4d5e-926b-29dd99ebedea,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"query, postgresql, migration, sqlite, foreign-key, sqlalchemy",https://stackoverflow.com/questions/7358113,user_12260,03-08-2018,258,high,beginner
5219ea63-67ea-4388-a5fc-181c7e535e14,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"json, requests, aiohttp, timeout, retry",https://github.com/httpx/httpx/issues/8949,contributor_1420,14-06-2024,469,low,beginner
79fab260-2663-46f0-949c-cc49953ef9ec,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"foreign-key, sqlalchemy, query, sqlite, migration",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,26-03-2019,2031,high,beginner
cad72ad6-522a-4b97-bed2-9f26e92fb0d1,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"pandas, merge, vectorization, dataframe, array, reshape",https://stackoverflow.com/questions/6229731,user_428373,16-08-2018,850,medium,beginner
1e4fba8a-c68b-4617-a365-00641f9b89a7,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"blueprint, response, request, dependency-injection, rest, flask",https://stackoverflow.com/questions/8106470,user_441071,30-11-2022,1791,low,intermediate
e26da5c0-c346-4ddf-aeef-c304e3b9e882,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"dependency-injection, flask, response, rest, pydantic, middleware",https://docs.flask.org/en/stable/@app/route.html,Official Docs,25-08-2024,3012,medium,advanced
c922a2cb-e78e-422c-bf85-681c622f0a49,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"numpy, groupby, dtype",https://stackoverflow.com/questions/6229731,user_428373,03-10-2018,822,medium,beginner
f4a32c46-d27e-483c-a73b-5fd9f231f78a,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"iloc, dtype, pivot, broadcasting",https://stackoverflow.com/questions/6229731,user_428373,17-09-2018,845,medium,advanced
e6dc0db7-7679-40bb-b0f5-d2414a1eae72,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"threading, coroutine, event-loop, deadlock, executor",https://stackoverflow.com/questions/3195773,user_714318,13-05-2021,1097,high,intermediate
be30b671-e872-4533-9d69-e5be79f903ec,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"await, executor, async, coroutine, task",https://github.com/cpython/cpython/issues/5591,contributor_1630,20-08-2021,344,high,advanced
47650045-f5ad-4a75-84d5-c2473380729d,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"dtype, broadcasting, pandas, array",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,24-09-2022,788,high,beginner
d68cdc0e-e1c2-415c-ae35-79751a57fd16,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"env-variable, stdout, glob",https://stackoverflow.com/questions/5394880,user_179430,23-08-2018,537,medium,intermediate
2345961c-833c-4c09-937a-aa898e7454cd,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"request, middleware, pydantic",https://stackoverflow.com/questions/8930103,user_264801,30-05-2024,2206,medium,beginner
f862b51c-0489-4d22-a21b-1ba830dd5dec,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","foreign-key, sqlite, query, relationship, orm, transaction",https://stackoverflow.com/questions/5977931,user_238275,17-10-2024,637,medium,intermediate
10297186-ec55-48d4-a92d-669c24022ea2,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"connection-pool, postgresql, query, alembic",https://stackoverflow.com/questions/7358113,user_12260,19-05-2022,250,medium,intermediate
2f5663d3-fb1a-4101-886d-cb2147df6602,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"pandas, dtype, iloc, nan, loc, dataframe",https://stackoverflow.com/questions/2321324,user_99814,15-08-2023,266,high,intermediate
cebe5a9d-0466-41a3-9c05-90298525e0c1,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"query, foreign-key, sqlite, transaction",https://stackoverflow.com/questions/9436429,user_974047,04-04-2018,2393,medium,beginner
0f7cad67-3f2d-4874-af16-f20846a0a189,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"http, oauth, requests, aiohttp, httpx",https://stackoverflow.com/questions/8896868,user_243238,06-08-2020,1585,medium,beginner
2885d037-cd7a-49b0-a15f-8ada6a7c6fbc,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","middleware, request, orm, template",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,01-05-2023,2844,medium,intermediate
2cf88f9b-3be8-4a46-8aba-537c2ee243ce,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"env-variable, pathlib, shutil",https://docs.os.org/en/stable/os/environ.html,Official Docs,06-01-2019,2232,medium,beginner
4f9abcad-603a-4213-aae5-68979f9e38d0,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"lock, async, semaphore, gather, coroutine, threading",https://stackoverflow.com/questions/3646552,user_469469,10-11-2018,1551,medium,beginner
91ccffe1-4c3c-45fd-b57b-bc03585a4d15,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"middleware, django, template, rest, request",https://docs.flask.org/en/stable/@app/route.html,Official Docs,02-08-2021,3024,medium,intermediate
55bf85ed-6515-498d-b094-abdef69858c8,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"fastapi, pydantic, dependency-injection, orm",https://docs.flask.org/en/stable/@app/route.html,Official Docs,27-09-2023,3017,medium,intermediate
f49ea47c-1507-4873-a846-f85d29bb8e41,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"middleware, flask, request",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,12-11-2019,2395,high,intermediate
e054d6f7-7d51-40a9-b4d0-504bd152894c,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"dependency-injection, orm, flask, template",https://stackoverflow.com/questions/1527021,user_911393,20-10-2019,971,medium,advanced
3a7deab8-f378-40fa-8781-585a9b73fc3b,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"oauth, websocket, headers",https://stackoverflow.com/questions/1669324,user_952590,07-09-2021,1525,medium,beginner
e85b0df2-889e-443a-a6dc-0b564e0dbb0b,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"groupby, dataframe, merge",https://stackoverflow.com/questions/2321324,user_99814,24-03-2018,237,low,intermediate
45819d80-554a-456e-857a-8b86b157f743,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"query, transaction, relationship",https://stackoverflow.com/questions/9436429,user_974047,26-06-2019,2413,medium,beginner
18818645-b503-4f99-9960-108d10ace2e1,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"pathlib, pipe, stderr, file-io, stdout, os",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,05-08-2024,3216,low,intermediate
a5a298d3-8f06-492c-a5a7-fe079b73e42a,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"async, task, await, semaphore",https://stackoverflow.com/questions/2229110,user_573750,25-11-2021,2306,medium,advanced
1b8d9360-2a34-4c73-a849-42a144b47105,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"flask, template, request",https://stackoverflow.com/questions/8930103,user_264801,17-04-2021,2201,medium,advanced
edc6116c-1a7e-473b-a0df-f201696d874e,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"oauth, rate-limiting, timeout, websocket, requests, httpx",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,23-07-2022,77,medium,advanced
49ab22a3-4388-4d2a-957d-4872e823acbc,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"groupby, vectorization, reshape, dtype",https://github.com/pandas/pandas/issues/4449,contributor_726,22-01-2018,496,low,intermediate
cd921ae4-d41a-4548-a81b-9996ed33673e,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"response, django, rest",https://github.com/flask/flask/issues/2141,contributor_5020,27-12-2024,172,medium,advanced
93f9b3fb-ff7b-4bd1-9de9-23d2b4f34f47,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"requests, retry, rest-api, http, aiohttp, authentication",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,16-08-2023,63,medium,beginner
ceea941e-3b2b-4bea-ae5a-a94dd70d8faf,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","broadcasting, pivot, iloc, numpy, loc, reshape",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,25-12-2024,1896,high,intermediate
fe3f03ee-ef63-4f61-8299-98b579721f2c,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"race-condition, lock, await, executor, task, gather",https://stackoverflow.com/questions/2140194,user_718011,01-10-2022,288,low,advanced
892d79a0-ae6c-43e6-823d-49e009cc52e8,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"asyncio, lock, deadlock, gather, task",https://github.com/cpython/cpython/issues/6647,contributor_4097,19-12-2020,274,medium,intermediate
2085409b-ca37-4801-8edb-5ea7462bcc98,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"foreign-key, sqlite, migration, sqlalchemy, alembic",https://stackoverflow.com/questions/7358113,user_12260,25-08-2020,274,high,intermediate
1ed5e31b-091b-4a44-81f3-1db7f95fe42c,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"iloc, pandas, reshape, array",https://github.com/pandas/pandas/issues/8446,contributor_6648,16-10-2018,356,high,intermediate
fa3de3e4-fd89-4ef0-8428-1b9b138f323c,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"template, blueprint, orm, fastapi, rest, flask",https://github.com/django/django/issues/8618,contributor_8921,23-09-2020,23,low,intermediate
4c857a6d-05fe-4f86-a164-3ea60f8c79bd,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"stdout, shutil, glob, stderr, process, env-variable",https://stackoverflow.com/questions/5213115,user_959314,20-05-2024,2108,high,intermediate
6ac4cd0b-7a27-454f-94da-d76d99c05e64,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","glob, subprocess, stdout, os, stderr, pathlib",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,19-01-2022,434,high,beginner
139417e1-9870-4cc9-9f2c-7f811c20ec44,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","deadlock, coroutine, gather, asyncio, threading",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,07-12-2022,482,high,intermediate
9ef1296b-c35e-4751-b535-44b5352637c4,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"asyncio, event-loop, coroutine, semaphore",https://github.com/cpython/cpython/issues/5591,contributor_1630,14-05-2024,317,high,intermediate
d505e4ce-af5f-4b63-b30a-048688f85a57,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"deadlock, asyncio, race-condition, async, threading, coroutine",https://stackoverflow.com/questions/3646552,user_469469,22-12-2019,1534,low,beginner
103149b2-06b3-4038-92a0-79cf3092832a,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"process, pathlib, env-variable, shutil",https://stackoverflow.com/questions/2737893,user_994539,21-04-2022,2278,medium,beginner
3a9a8268-9e23-46ff-ab6d-6aef83f30e37,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"file-io, glob, pipe, pathlib",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,14-01-2023,3210,low,intermediate
ced6d73b-1f4a-428f-bc55-bc8cdc5884df,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"broadcasting, pandas, array",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,04-01-2021,1317,medium,advanced
6e096eb0-8eaf-4738-948d-749bb5860a7b,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"numpy, merge, dtype",https://stackoverflow.com/questions/4860684,user_627024,28-09-2018,1423,medium,advanced
17366ac4-e609-4112-a483-ea449e841090,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"pivot, groupby, array, dataframe, merge",https://stackoverflow.com/questions/4860684,user_627024,12-11-2022,1420,low,advanced
fe53c406-d099-417d-afd9-8c3059efdee7,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"shutil, stderr, env-variable, subprocess, file-io",https://github.com/cpython/cpython/issues/7712,contributor_8802,05-01-2021,442,high,intermediate
bfd8e501-ac8f-46a0-8de3-f9df49e85ff5,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"await, coroutine, deadlock, event-loop, task, race-condition",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,09-03-2024,4838,high,advanced
bb2d3bde-2e75-4cf2-9910-7b8eab230165,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"authentication, websocket, rest-api, headers",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,29-11-2022,74,medium,advanced
131a74e0-8237-4008-8fac-1c3a28835198,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"transaction, migration, alembic",https://github.com/alembic/alembic/issues/7344,contributor_3601,25-04-2023,222,medium,intermediate
e746f31d-e0f8-40f2-b79f-c350a228019e,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"sqlalchemy, alembic, foreign-key, migration, query, connection-pool",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,22-01-2023,311,low,intermediate
04ec9286-9911-4652-92f5-fc366ae6ec49,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"gather, event-loop, deadlock",https://stackoverflow.com/questions/2375453,user_449589,18-07-2024,2445,high,advanced
e41748e2-b5d2-4b12-8a19-3a3e3cb33ddb,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"async, race-condition, task, gather, await, coroutine",https://github.com/cpython/cpython/issues/6647,contributor_4097,14-06-2020,254,medium,intermediate
47cedec7-a19d-4c3c-aeef-91ddb65ac55b,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"aiohttp, rest-api, headers, timeout, httpx, json",https://stackoverflow.com/questions/3592974,user_980733,26-05-2021,1700,high,advanced
bd270098-64b4-4aa4-a263-5b127400e32b,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"await, async, gather, lock",https://stackoverflow.com/questions/3195773,user_714318,15-08-2022,1103,medium,advanced
bd16f02c-3d57-4825-8a13-76f46ba0c897,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"routing, orm, pydantic, dependency-injection, django, blueprint",https://github.com/flask/flask/issues/2141,contributor_5020,22-05-2021,169,high,intermediate
ea2ec08d-8dca-4f62-b309-defc7ec29aa8,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","json, websocket, retry, requests, authentication",https://stackoverflow.com/questions/7907400,user_851204,24-12-2018,1372,high,intermediate
b7d98b9b-8647-4f40-b856-e9c83e41f813,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"routing, flask, blueprint, orm, template, fastapi",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,29-08-2020,2437,low,intermediate
3007bcc5-793f-45fd-bc81-8a920a230068,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"middleware, rest, response",https://stackoverflow.com/questions/7754864,user_773587,30-07-2024,423,medium,advanced
8785e171-7c5c-4fc0-8315-265943a60620,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"sqlite, migration, foreign-key, transaction, session, alembic",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,17-02-2020,276,medium,advanced
bcf8ff32-3156-4c32-86d4-5cbee7f7dcff,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"dataframe, pandas, vectorization",https://stackoverflow.com/questions/6229731,user_428373,21-03-2018,812,low,beginner
61fed399-750c-416c-8fea-809b3303d23f,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"dependency-injection, django, request, pydantic",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,05-11-2019,2449,high,advanced
42c290f2-e157-444d-81bb-96677621b07a,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"pathlib, process, shutil, glob, file-io, stderr",https://stackoverflow.com/questions/5394880,user_179430,15-07-2021,546,low,advanced
060d6e36-4677-4ffa-a7ed-c1fb7288ca2f,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"routing, flask, request, dependency-injection, template, rest",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,25-06-2024,2422,high,beginner
b1df1ac1-fdcc-4f9b-821a-9e196187dde4,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"os, process, tempfile, stdout, pipe",https://github.com/cpython/cpython/issues/7712,contributor_8802,10-04-2019,409,medium,intermediate
97672db3-472e-4e79-a265-065f0fd88d9a,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"process, stdout, stdin, env-variable, pipe, pathlib",https://stackoverflow.com/questions/2737893,user_994539,27-12-2024,2273,medium,beginner
ab841654-7f00-4774-861e-56ed24c8027d,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"connection-pool, sqlalchemy, alembic, relationship",https://stackoverflow.com/questions/7358113,user_12260,28-09-2022,252,medium,advanced
b7c67a36-01a9-421c-bf30-f234a34b5766,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"await, event-loop, threading, lock",https://stackoverflow.com/questions/3195773,user_714318,07-05-2021,1093,low,beginner
a92a1bb3-0b37-4914-83b4-0d16f5d2a97b,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"httpx, rest-api, requests, authentication, timeout, headers",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,11-09-2024,83,medium,beginner
6f0793fc-468c-4673-9a81-1fef696157b1,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"env-variable, stdin, os",https://stackoverflow.com/questions/5394880,user_179430,19-10-2021,549,high,intermediate
3aa085ce-8dd6-4f09-a50f-f8178b6c9ea6,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"blueprint, fastapi, middleware",https://stackoverflow.com/questions/1527021,user_911393,19-09-2018,951,low,beginner
54961e66-94b1-4149-87ac-4b1aa624dc41,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"pivot, iloc, reshape, groupby, merge",https://stackoverflow.com/questions/2321324,user_99814,26-06-2020,242,high,advanced
0d7c5c67-c9cb-48d9-bc4a-21cef8cfdeaf,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"orm, template, middleware",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,15-02-2021,321,medium,beginner
09750392-acb8-4d2c-bd75-b33d21ecda06,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","migration, sqlite, sqlalchemy",https://stackoverflow.com/questions/5977931,user_238275,22-04-2022,643,low,intermediate
61b5cba1-ebdf-4291-abc9-346f550b7e03,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"flask, routing, dependency-injection",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,30-01-2018,327,medium,advanced
8b8d1eb7-e653-4468-8342-1d980df2fb7c,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"foreign-key, sqlalchemy, migration, sqlite, postgresql",https://stackoverflow.com/questions/9436429,user_974047,16-12-2023,2402,high,beginner
1cf0f1cb-a229-4397-b12a-5673ea4a367f,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"threading, coroutine, async",https://stackoverflow.com/questions/2375453,user_449589,31-10-2018,2434,medium,intermediate
8abe2990-666e-402a-9893-2b5e64d73e79,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"merge, broadcasting, dtype, numpy, pivot, dataframe",https://stackoverflow.com/questions/2321324,user_99814,19-05-2021,255,high,beginner
69b653f5-88b2-4c72-b9af-6f6ec96d138b,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"aiohttp, rate-limiting, retry, rest-api, oauth, timeout",https://github.com/httpx/httpx/issues/8949,contributor_1420,23-01-2022,472,medium,intermediate
d8703af0-be43-48fa-9741-90973cf8028a,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","dtype, iloc, pivot, dataframe, loc",https://stackoverflow.com/questions/5446912,user_563306,09-07-2018,2291,low,advanced
b50697ae-7fea-4a77-88bd-3dc7b77ec773,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"event-loop, deadlock, await, asyncio",https://github.com/cpython/cpython/issues/4111,contributor_7884,26-10-2019,28,low,intermediate
71a24618-ad24-47da-8ec0-b1b84c55e380,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"foreign-key, alembic, sqlite, orm",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,01-09-2021,275,medium,advanced
29300bb5-0e46-427b-abe9-4407a8cd8d57,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"authentication, httpx, requests, rate-limiting, headers",https://stackoverflow.com/questions/1669324,user_952590,30-11-2021,1475,low,beginner
4d0986b1-a2bb-4045-9249-87b5f26a05f7,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"routing, pydantic, dependency-injection",https://stackoverflow.com/questions/8077999,user_202401,14-02-2021,1847,high,intermediate
f2c6abfe-735a-4896-98a4-7c7457e52474,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"migration, session, query, foreign-key, sqlalchemy",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,18-06-2018,3028,high,advanced
64e76e20-0cbf-4c07-ba35-e1ac6a1fdedb,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"oauth, requests, retry, headers, rest-api",https://github.com/requests/requests/issues/4019,contributor_4599,23-12-2022,270,high,intermediate
c2696633-5bf4-4a7e-9f3a-f3760b8470e0,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"httpx, json, rate-limiting, timeout",https://github.com/httpx/httpx/issues/8949,contributor_1420,27-10-2021,485,medium,beginner
7f1b0972-6c6a-4a4c-8bdc-519b59e7ff76,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"query, orm, sqlite, relationship, migration",https://github.com/alembic/alembic/issues/7344,contributor_3601,18-08-2023,233,medium,advanced
0e336493-b495-4788-8619-59ed1c5ca1e1,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","gather, race-condition, asyncio, deadlock",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,14-01-2021,511,high,intermediate
76aadb21-cbc8-4136-a78f-0bded6f10679,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"stderr, pathlib, shutil, file-io, env-variable",https://github.com/cpython/cpython/issues/7712,contributor_8802,20-08-2024,432,medium,beginner
6d7bf2e6-e1d1-4f01-ad71-d68fa031e45a,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"middleware, template, rest, django, flask, pydantic",https://docs.flask.org/en/stable/@app/route.html,Official Docs,26-03-2018,3036,high,beginner
339ee492-20c7-4f63-96fd-5271b24cc977,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"env-variable, pipe, os, process, stderr, shutil",https://github.com/cpython/cpython/issues/8586,contributor_7711,22-09-2023,414,medium,beginner
981a525d-48ac-4f01-9413-65ee2bdb2f1a,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"pydantic, routing, dependency-injection, response",https://docs.flask.org/en/stable/@app/route.html,Official Docs,12-08-2023,2995,high,beginner
e536dbf5-901a-41eb-8418-85776ab76ef0,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","relationship, foreign-key, connection-pool, sqlite, session",https://stackoverflow.com/questions/1247595,user_107793,21-01-2024,401,high,beginner
718f4a82-43bd-46d0-9b76-5f8bdc8e61a0,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"shutil, stdout, tempfile, pipe, subprocess",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,21-03-2022,3198,high,intermediate
52058554-411c-4ed6-8d67-4cc0e860e362,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"task, race-condition, coroutine, asyncio",https://github.com/cpython/cpython/issues/4111,contributor_7884,07-07-2020,45,medium,advanced
0bc30cf8-6684-461f-b560-530b63919629,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","shutil, stderr, file-io",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,10-09-2022,416,medium,intermediate
da146b0c-402f-4667-ac31-e4215b423f2d,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"reshape, groupby, array, vectorization",https://stackoverflow.com/questions/6438436,user_522340,14-07-2019,1,medium,intermediate
9becb431-7255-4777-a5e7-b65e56021a4c,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"numpy, broadcasting, loc, pivot, groupby",https://github.com/pandas/pandas/issues/3264,contributor_6628,18-08-2023,4,low,intermediate
73b119bf-0e48-4640-9411-748c031650f3,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","groupby, numpy, dtype",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,07-08-2022,1849,medium,beginner
94ea3126-46ab-4fd4-abbe-9fe975ec2947,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"rest-api, http, websocket, authentication, json",https://github.com/httpx/httpx/issues/8949,contributor_1420,20-07-2020,462,high,beginner
4168ffbc-49bd-4c3e-b86d-5509b590f546,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"await, gather, deadlock",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,01-12-2023,4863,high,beginner
23a5bcd3-c281-4479-8772-dc4cc6b7d302,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"threading, executor, async, deadlock",https://stackoverflow.com/questions/2140194,user_718011,06-11-2022,307,low,intermediate
f4cfe2d2-b9ab-4219-9607-5342ab8afc69,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"coroutine, task, async, await, executor",https://github.com/cpython/cpython/issues/6647,contributor_4097,25-03-2022,264,low,beginner
c34c0454-109b-4e15-bd7d-0b1a7df40f9b,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"http, timeout, httpx",https://github.com/requests/requests/issues/3605,contributor_1152,16-10-2020,360,high,intermediate
c299e4e5-9ca5-4d8b-bce1-f51c421c7410,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"dependency-injection, flask, template",https://stackoverflow.com/questions/8106470,user_441071,17-04-2018,1783,high,beginner
e6c0fc9f-8351-49f9-a150-c875c756416f,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"reshape, dataframe, iloc, nan",https://stackoverflow.com/questions/6438436,user_522340,21-03-2018,12,low,beginner
5dec7d56-e83b-400f-9714-4fb804f33969,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"os, process, tempfile, stderr",https://github.com/cpython/cpython/issues/7712,contributor_8802,26-09-2018,440,high,intermediate
6d195762-3a16-48c4-9af8-9c438c94e2d1,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"array, vectorization, pivot, iloc",https://github.com/pandas/pandas/issues/8446,contributor_6648,24-08-2022,311,medium,advanced
e3e42765-9aaa-4e13-a86a-0dcde8aa047b,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"stderr, file-io, pipe, subprocess, os, pathlib",https://docs.os.org/en/stable/os/environ.html,Official Docs,28-03-2018,2244,high,beginner
6b85932f-8883-47dd-8c71-81d5ed2d2785,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"glob, process, tempfile, subprocess, stderr, pipe",https://stackoverflow.com/questions/2737893,user_994539,02-03-2020,2262,low,advanced
0833662c-5fe4-43aa-8604-5f41f303eaa8,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","merge, groupby, numpy, pandas",https://stackoverflow.com/questions/5446912,user_563306,20-12-2021,2237,high,beginner
a9f58aa6-7314-475f-8734-17c0add000d8,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"gather, executor, lock, threading",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,19-10-2020,4142,low,advanced
bd04811b-428e-490b-9a82-8e43d4f36db3,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"async, await, coroutine, asyncio, threading",https://stackoverflow.com/questions/2229110,user_573750,18-03-2018,2299,medium,advanced
55107fda-4298-4f79-a65e-3d0428e424f0,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"http, requests, httpx, retry, timeout",https://stackoverflow.com/questions/1669324,user_952590,10-03-2020,1510,high,advanced
d54d494c-faea-402f-8626-4b996e8929f9,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"aiohttp, httpx, headers, retry, rest-api",https://stackoverflow.com/questions/1604451,user_885136,16-10-2020,604,low,advanced
b1b8d36f-2d80-440c-9a33-d428b2cff0d9,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"subprocess, os, env-variable, tempfile",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,13-07-2021,3173,medium,advanced
99723715-1dc8-4465-9b94-d5895aa35d73,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","reshape, pandas, loc",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,29-09-2018,4503,high,advanced
ce692790-e421-4d5e-b922-ba5fcf1cefdb,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"headers, oauth, authentication, retry, requests, httpx",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,18-08-2019,4211,high,intermediate
57c8596b-3096-468e-b4ae-7f99137405ac,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","broadcasting, pandas, dtype, reshape, nan",https://stackoverflow.com/questions/5446912,user_563306,23-12-2018,2291,high,intermediate
60f2caee-0ef3-4aeb-a0a5-78a46ec9c9f3,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"migration, foreign-key, sqlite, transaction, postgresql",https://github.com/alembic/alembic/issues/7344,contributor_3601,30-01-2019,229,high,advanced
182ebafa-bfa5-4706-963e-6a5a596e13d6,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"blueprint, fastapi, request",https://github.com/django/django/issues/3243,contributor_6988,26-12-2023,78,high,intermediate
44d1ce57-7910-45f0-a696-53102f278453,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"os, stdin, tempfile",https://github.com/cpython/cpython/issues/7712,contributor_8802,19-01-2022,409,low,intermediate
c4c4d1a0-4af2-4dfd-b43a-76c75e99a490,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"glob, stdout, env-variable",https://stackoverflow.com/questions/5727085,user_644210,27-02-2024,669,high,beginner
4d2530c8-9dcf-4d3c-9317-d5c58affa08e,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"httpx, rate-limiting, authentication, http, websocket, oauth",https://github.com/requests/requests/issues/4019,contributor_4599,20-05-2019,265,low,beginner
cfffc6f1-3e83-4c26-b36b-db55e9637e20,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"stdout, subprocess, env-variable, stdin, pipe",https://stackoverflow.com/questions/5213115,user_959314,30-04-2019,2092,high,beginner
1742b820-913a-463c-8e07-5f735bd5d73a,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"rest-api, rate-limiting, authentication, headers, websocket, retry",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,24-04-2019,4198,low,beginner
56b662d8-d215-4858-9974-569b0e5f2e0a,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"lock, executor, async, threading",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,08-12-2020,4866,high,beginner
909c8e12-b998-4997-94e3-c9e9c82b9ae0,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","dataframe, numpy, groupby, reshape, merge, pandas",https://stackoverflow.com/questions/5446912,user_563306,30-08-2020,2237,high,beginner
65d5f2bc-e2b8-4d00-83ac-de478bcaf74a,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"file-io, pathlib, glob, shutil",https://github.com/cpython/cpython/issues/7712,contributor_8802,24-01-2021,411,medium,beginner
0a5d64b3-e197-473c-a2c7-87e7af343e28,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"session, foreign-key, sqlalchemy, sqlite, migration",https://github.com/alembic/alembic/issues/7344,contributor_3601,16-12-2018,206,high,intermediate
5fa886c8-f7de-40d6-94ac-a9e0487824c4,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"flask, request, django, blueprint, routing, template",https://stackoverflow.com/questions/8106470,user_441071,15-03-2023,1764,high,intermediate
0b60cad1-1f2b-4bd9-8a26-0f2839fe0f18,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"race-condition, gather, async, lock",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,05-12-2024,4854,medium,intermediate
4a6d5b60-42f0-4193-98b9-9229ef036fe9,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"rate-limiting, rest-api, headers, authentication",https://github.com/requests/requests/issues/4019,contributor_4599,06-10-2021,264,high,beginner
e7ed50fe-2e33-422a-81b5-e42e3208c8d5,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"foreign-key, connection-pool, postgresql",https://github.com/alembic/alembic/issues/7344,contributor_3601,01-11-2020,213,high,beginner
6169199e-51b6-4da1-8df3-c791534c2902,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"numpy, broadcasting, vectorization",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,26-07-2024,802,medium,intermediate
81686058-048a-4813-8fd0-4c8bb2f457df,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"await, coroutine, lock",https://stackoverflow.com/questions/2229110,user_573750,20-11-2019,2304,high,beginner
88edb8c2-7a56-4492-9e42-d7e5ad0de109,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"reshape, iloc, merge",https://github.com/pandas/pandas/issues/8446,contributor_6648,21-02-2023,343,medium,advanced
c1da9964-64a4-4808-a4b2-3d53beffca20,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"rest, middleware, pydantic, routing",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,22-11-2023,2396,high,advanced
d2bae488-6c82-4909-b811-dd53cc74fab1,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"flask, rest, django, middleware",https://docs.flask.org/en/stable/@app/route.html,Official Docs,12-10-2024,2990,medium,intermediate
d7a3f6d3-bef7-4338-882d-56ec7bc6d2d4,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"deadlock, race-condition, executor, async, semaphore, lock",https://stackoverflow.com/questions/2140194,user_718011,24-05-2021,304,low,advanced
6ef818d5-00da-43ae-b634-3b19ad168393,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"deadlock, event-loop, race-condition, task",https://github.com/cpython/cpython/issues/6647,contributor_4097,25-09-2018,235,low,beginner
2090c025-3156-442c-a83f-55f360a32153,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","subprocess, stdin, tempfile, shutil, stderr",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,25-06-2019,461,high,advanced
03a57d61-ced9-4f79-937b-eef90a591ef1,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","response, flask, dependency-injection, routing",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,14-08-2020,2896,medium,intermediate
d135c0f2-fbef-432a-b144-cc34e81b7fa9,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"executor, async, coroutine",https://github.com/cpython/cpython/issues/6647,contributor_4097,04-08-2018,237,medium,beginner
281ce140-ae5c-484b-af37-fe68cad2823d,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"async, gather, coroutine, event-loop, deadlock, task",https://stackoverflow.com/questions/3646552,user_469469,18-03-2022,1520,medium,beginner
c2b8e915-a781-4795-b06c-271f07806622,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"gather, await, task",https://stackoverflow.com/questions/2375453,user_449589,04-03-2020,2464,high,advanced
2bab6571-2f50-423d-ab5a-9ed6ffaf5a22,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"tempfile, glob, stdin, stdout, stderr",https://github.com/cpython/cpython/issues/2707,contributor_7877,14-12-2021,491,medium,intermediate
6429143d-2d1e-4d8d-aee8-421803e572be,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"response, template, pydantic, blueprint",https://stackoverflow.com/questions/7754864,user_773587,05-05-2023,402,medium,intermediate
d33be8e0-408f-4009-b7de-8daa94a5887e,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"groupby, array, dtype",https://stackoverflow.com/questions/6438436,user_522340,23-09-2022,1,medium,beginner
7aee96b9-0310-41f4-a062-4edd06569754,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"executor, await, coroutine, threading, asyncio",https://stackoverflow.com/questions/2229110,user_573750,19-06-2020,2294,high,advanced
73132763-ea45-4ee1-a211-8ea6c6a7a26f,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"numpy, groupby, reshape, dtype",https://github.com/pandas/pandas/issues/3264,contributor_6628,28-01-2023,1,medium,beginner
28e3cb60-cd68-44bd-8ece-fe3460ae34e5,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"race-condition, event-loop, semaphore",https://stackoverflow.com/questions/2140194,user_718011,18-02-2023,268,medium,advanced
d426c73e-7967-485a-9779-70e97b483e50,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","stdout, env-variable, shutil, pipe, stdin, glob",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,02-09-2024,459,high,intermediate
0c73a029-6045-4303-8b57-ca95f347b819,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"shutil, tempfile, process, pipe, pathlib",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,26-10-2022,3224,medium,beginner
5a8bee98-24a2-45ac-861a-8e7a0a0ed380,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"request, flask, pydantic, routing, response, dependency-injection",https://github.com/flask/flask/issues/2141,contributor_5020,13-03-2024,183,medium,intermediate
ac351aef-4522-4280-ae7d-c219a6542338,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"iloc, broadcasting, dtype, groupby",https://github.com/pandas/pandas/issues/4449,contributor_726,30-10-2022,478,high,beginner
9ddb9e1c-91c5-4fb0-80e8-37a6a580e8ea,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","iloc, array, nan",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,23-08-2023,4514,high,intermediate
7721e542-7b90-4ac4-aa44-a9b82006d7ed,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"stderr, shutil, stdout, pathlib, os",https://github.com/cpython/cpython/issues/8586,contributor_7711,06-04-2023,422,high,advanced
9ea18b3f-fc50-4496-a9b7-c95154ca15d6,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"await, task, executor, asyncio, race-condition, gather",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,13-12-2021,4119,medium,beginner
a1c367d6-1b2c-490f-8551-1d2445e5d80d,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"dependency-injection, middleware, django, blueprint, flask, pydantic",https://stackoverflow.com/questions/1527021,user_911393,03-05-2023,959,low,advanced
b4887999-3f83-4943-a9a0-ae02f95f7497,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"pipe, pathlib, os",https://stackoverflow.com/questions/2737893,user_994539,23-08-2024,2261,medium,beginner
33036785-f3bc-4359-a99f-3e5be89db8c6,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","sqlite, postgresql, sqlalchemy",https://stackoverflow.com/questions/5977931,user_238275,03-05-2024,629,high,advanced
86377054-1cc8-4ec7-b31c-880db432b24e,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"blueprint, pydantic, request, orm, response",https://github.com/flask/flask/issues/2141,contributor_5020,30-01-2018,159,medium,advanced
f84f17ec-b275-469c-a2c5-ec62c0922c8c,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","postgresql, foreign-key, query, session",https://stackoverflow.com/questions/5977931,user_238275,17-02-2022,651,low,intermediate
c3b46f9f-714b-471b-ac4b-298aebe7e7bc,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"pydantic, template, routing, orm, rest, request",https://github.com/django/django/issues/3243,contributor_6988,07-02-2019,56,medium,advanced
a95df8e8-5e0e-42c3-bb28-991435317f56,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"semaphore, race-condition, gather, threading",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,23-10-2019,4851,medium,intermediate
90b9562f-969c-46e8-b31d-6bf745948352,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"race-condition, gather, coroutine, task, executor",https://stackoverflow.com/questions/3195773,user_714318,09-06-2021,1104,high,intermediate
8dabb0b8-a176-48d7-a9c7-ee70dddd1fdc,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","blueprint, flask, request",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,15-06-2022,2892,high,advanced
47400399-4edb-4315-aa43-8f1533167f83,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"lock, executor, coroutine",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,20-05-2019,4132,medium,advanced
76ca63c4-e148-46f7-94a7-6df806c1d763,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"dtype, pivot, array, iloc, merge",https://stackoverflow.com/questions/6229731,user_428373,16-07-2023,810,high,intermediate
fd6df30d-59a2-47a3-9863-52e7fd6c71fb,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"pivot, iloc, loc",https://stackoverflow.com/questions/2321324,user_99814,26-12-2022,250,high,intermediate
76510d15-f206-40cb-9e50-bdd86ebdaa88,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"stderr, glob, process",https://stackoverflow.com/questions/5727085,user_644210,04-10-2018,616,high,intermediate
0fda8035-e68b-4b7e-9b51-9e47f3f4dec7,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"pathlib, process, shutil, file-io, stdin",https://stackoverflow.com/questions/5727085,user_644210,17-02-2019,636,medium,intermediate
47142c73-b11f-46fa-80a7-454dc56c736c,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","lock, executor, async, task, coroutine",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,21-04-2020,522,medium,advanced
6a93a63f-38a2-4b43-a798-7f572dfbfee5,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"headers, requests, json, authentication, http",https://stackoverflow.com/questions/1604451,user_885136,12-10-2023,626,medium,beginner
4fcc5a97-f6b0-4342-a1a5-2cc29c5051dc,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"shutil, subprocess, glob, os, tempfile, pathlib",https://stackoverflow.com/questions/2737893,user_994539,25-10-2022,2287,medium,intermediate
4f845d01-e877-46cc-b280-d50905a4cd0e,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"gather, executor, deadlock, event-loop, asyncio",https://github.com/cpython/cpython/issues/4111,contributor_7884,09-03-2021,9,medium,beginner
7662b01e-8d72-4b0b-814e-f996bb4a0548,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"transaction, alembic, foreign-key",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,30-08-2019,3039,low,beginner
f8cdfa80-9513-4687-b03f-7bc40f6c2069,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"connection-pool, orm, sqlite, alembic, postgresql",https://stackoverflow.com/questions/9436429,user_974047,10-12-2022,2393,low,beginner
f3c4fb3b-643b-4840-90c1-2bf069fa9ec7,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"routing, dependency-injection, fastapi, pydantic",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,08-04-2018,299,high,advanced
fe03e4e0-30dd-4cae-ae85-2f059e1a27d5,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"env-variable, subprocess, stderr, pipe, tempfile, stdin",https://stackoverflow.com/questions/2737893,user_994539,17-07-2021,2286,high,beginner
47931292-669c-4cba-add6-4b0295b6eeaa,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"pydantic, blueprint, flask, fastapi",https://stackoverflow.com/questions/8106470,user_441071,17-05-2024,1771,medium,intermediate
d74a0ded-899f-4597-a829-dc9dfce855f0,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"response, request, blueprint, fastapi, django, template",https://github.com/django/django/issues/8618,contributor_8921,25-07-2024,35,medium,advanced
bd786fa3-1e7c-46b1-bb02-3795e3db27dd,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"response, template, fastapi, routing",https://docs.flask.org/en/stable/@app/route.html,Official Docs,26-05-2019,3014,high,intermediate
e03d17a7-4255-48ef-b3ad-6b7ada74bca2,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"alembic, foreign-key, sqlalchemy, transaction, sqlite",https://github.com/alembic/alembic/issues/7344,contributor_3601,04-09-2021,210,medium,beginner
4703d317-9645-476b-b0b1-0d1748f96cdb,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"await, race-condition, deadlock, event-loop",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,01-06-2021,4809,medium,advanced
ad5c79a5-b21b-4fda-81f9-3ba54418d71a,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"os, subprocess, file-io, glob",https://stackoverflow.com/questions/5727085,user_644210,12-11-2022,625,medium,advanced
5e6afa46-5cd9-42f9-b6af-06e019e98c27,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"routing, orm, template, flask, blueprint, middleware",https://stackoverflow.com/questions/7754864,user_773587,01-01-2020,424,high,intermediate
a008678c-d821-4def-ac7f-28063cea7f0c,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"pipe, pathlib, shutil, stdout, stdin",https://stackoverflow.com/questions/5727085,user_644210,12-12-2023,669,high,advanced
cef9c19f-8426-4063-8d65-0ae1476cade1,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"authentication, oauth, json, timeout",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,21-06-2021,97,low,intermediate
3dbdf12c-d059-4061-bc4e-3f3b03e218a4,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"os, stdin, file-io, process",https://docs.os.org/en/stable/os/environ.html,Official Docs,21-06-2023,2219,high,beginner
e5b2b8ee-8538-4e68-b90e-9b2894de1381,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"tempfile, pipe, shutil, glob, stdin, env-variable",https://github.com/cpython/cpython/issues/8586,contributor_7711,24-03-2021,429,high,advanced
d4054dca-091c-4afc-a0b6-ca0bd8632214,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","session, postgresql, sqlite, relationship, query",https://stackoverflow.com/questions/5977931,user_238275,13-11-2019,653,medium,beginner
e3903c4a-5076-4848-a6fa-a6346d756e7b,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"routing, dependency-injection, middleware, rest",https://stackoverflow.com/questions/1527021,user_911393,17-12-2022,958,medium,intermediate
ff61c90e-6b59-4720-9d1a-36745a70ac08,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"glob, tempfile, pipe",https://stackoverflow.com/questions/5394880,user_179430,11-03-2020,544,high,beginner
1646aef2-05ff-4b96-b546-3bacda798a7d,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"relationship, orm, postgresql",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,29-12-2022,266,low,intermediate
dc1182e5-8c9c-4e76-9eb2-376910c15ad8,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"rate-limiting, websocket, authentication, oauth, timeout, rest-api",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,09-04-2021,62,low,intermediate
601723e5-890c-4ebc-9c2c-5bdaf0cf6bfa,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"sqlalchemy, query, alembic, postgresql, foreign-key",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,06-03-2021,3051,medium,advanced
0143ef56-afdf-4cfa-a35e-01f30dbd599e,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"orm, sqlite, foreign-key, alembic, session",https://stackoverflow.com/questions/9436429,user_974047,19-04-2019,2391,medium,intermediate
1370aad6-7513-4461-bc96-d3a9ac599a8c,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"alembic, orm, foreign-key, transaction, connection-pool, migration",https://github.com/alembic/alembic/issues/7344,contributor_3601,22-03-2018,204,high,advanced
0a1a0577-0a4f-4c05-8e68-3c10a285a109,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"http, requests, oauth, retry",https://stackoverflow.com/questions/8896868,user_243238,17-01-2021,1554,medium,beginner
8d43b047-f340-4063-850c-10fb3ce0428d,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"flask, pydantic, template",https://stackoverflow.com/questions/8106470,user_441071,28-03-2023,1775,high,advanced
2b586a68-0b44-49f7-91cb-8541de4b682d,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"retry, oauth, json, rate-limiting",https://github.com/requests/requests/issues/3605,contributor_1152,02-10-2022,356,medium,intermediate
57aac642-3e63-4030-be1b-4c959eb4a824,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"migration, sqlalchemy, relationship",https://stackoverflow.com/questions/9436429,user_974047,03-02-2023,2412,medium,intermediate
10799c1c-8c7e-4ac2-b699-485845fd50de,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"groupby, numpy, dataframe, nan, loc",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,09-01-2020,804,medium,advanced
97389611-1cd0-4aa2-b56c-15f8cf44d636,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"process, subprocess, stdin, glob",https://stackoverflow.com/questions/5727085,user_644210,04-07-2024,676,high,advanced
f0b28326-01f0-4c93-a611-910cb0d23cd2,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"dependency-injection, pydantic, blueprint, middleware, orm",https://stackoverflow.com/questions/8077999,user_202401,11-03-2024,1867,medium,advanced
70188618-f097-4cc9-91ad-a7733d0531fb,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"requests, websocket, authentication, rate-limiting, oauth, json",https://stackoverflow.com/questions/1669324,user_952590,14-06-2021,1504,low,advanced
f216e043-af85-4e07-a09e-6df0fdcae388,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"semaphore, coroutine, event-loop, executor, task, asyncio",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,28-03-2020,4818,medium,advanced
cda0ae59-c9b0-4d7c-9c49-1fcbdf9b2be8,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"template, response, middleware",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,07-12-2018,291,medium,intermediate
0c7cda54-dd7e-480c-81b7-91a6364eb7fb,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"sqlalchemy, relationship, foreign-key, query, alembic",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,07-07-2021,2049,medium,advanced
414b2724-b97f-46d4-b90f-0501c4c76160,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"vectorization, reshape, array, nan",https://github.com/pandas/pandas/issues/3264,contributor_6628,06-09-2022,17,low,intermediate
92e59781-bde4-4cf7-bb46-2af160e8bb11,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"pathlib, tempfile, shutil",https://docs.os.org/en/stable/os/environ.html,Official Docs,07-06-2023,2228,medium,intermediate
99b7ed07-d69e-4363-b4fb-93d6fb8e9e4c,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"migration, sqlite, foreign-key, alembic, session, query",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,03-02-2019,3023,high,advanced
59900996-3094-41b7-a4bd-4f2490ef43f0,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"tempfile, stdout, env-variable, pathlib",https://stackoverflow.com/questions/5394880,user_179430,16-12-2020,548,high,intermediate
2bb8faad-a3ed-411e-bd6a-2f7fad441514,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"httpx, websocket, oauth",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,02-10-2024,83,low,advanced
e85de13e-1ec5-4551-9d96-40bdd5179d98,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","fastapi, orm, template, rest, blueprint",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,11-09-2019,2837,medium,beginner
b7224d05-7bb0-463e-a1ca-357d9b4ba7e9,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"aiohttp, rate-limiting, authentication, headers, requests",https://stackoverflow.com/questions/1669324,user_952590,04-01-2018,1532,medium,beginner
c4899a6e-3e3b-44a9-8e48-1f7dd469e1dd,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"pydantic, response, dependency-injection",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,27-01-2019,2394,medium,intermediate
a675f774-2210-44e0-a1d2-b1bb12af4974,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"os, subprocess, glob, file-io, pathlib",https://github.com/cpython/cpython/issues/8586,contributor_7711,25-07-2019,416,high,advanced
cec444fb-7f1f-4a5f-9119-917294c4aa42,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"loc, pandas, numpy, merge",https://github.com/pandas/pandas/issues/8446,contributor_6648,31-03-2018,328,medium,intermediate
da390c79-c17e-4909-b836-d87dca03a80f,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"websocket, oauth, httpx, aiohttp",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,26-02-2019,55,high,intermediate
1498bbde-1f06-4925-9b79-b6068526ae40,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"httpx, authentication, http, rate-limiting",https://stackoverflow.com/questions/8896868,user_243238,15-08-2024,1552,low,advanced
c575b8e3-cb3a-4690-871f-94c40e969f7d,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"blueprint, template, fastapi, flask",https://github.com/django/django/issues/3243,contributor_6988,30-06-2020,78,medium,intermediate
ddeb70d4-7d80-4daa-b549-ddc7ea153f2d,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"sqlalchemy, connection-pool, session, query, alembic",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,06-02-2020,2045,medium,intermediate
59bd33a3-1e17-477e-82d9-31df0bb1026c,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","await, gather, async, coroutine, task, lock",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,03-12-2021,497,medium,advanced
b060690a-8ce6-4cbe-bb6c-893599b735e6,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","transaction, query, foreign-key, alembic, orm",https://stackoverflow.com/questions/1247595,user_107793,24-04-2023,403,high,intermediate
731d576e-b223-46e6-b609-0db74d5e5c4e,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","async, executor, gather, threading, asyncio, task",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,02-03-2022,527,high,beginner
c5e6a1ef-b0bf-44cc-8cb1-50deaf9a9c20,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"pathlib, stderr, file-io, pipe",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,18-08-2022,3229,low,advanced
455df171-2eb0-44ea-98d7-42f158a3ebc8,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"rate-limiting, requests, rest-api, json, oauth, authentication",https://stackoverflow.com/questions/3592974,user_980733,16-05-2019,1670,low,intermediate
4a214a3f-9bd8-45a0-a57f-bca545fed3de,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"pipe, os, stdout, subprocess, stdin",https://stackoverflow.com/questions/5727085,user_644210,06-07-2024,625,medium,beginner
25662505-da49-4c8e-abff-d834aa268a30,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","pydantic, orm, middleware, flask",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,21-06-2024,2877,high,advanced
29576394-5fc7-4a08-9abe-3ead1c0b8ce9,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","semaphore, lock, asyncio, event-loop",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,29-01-2022,499,high,beginner
c9ac3f35-39a7-426b-9a0e-12c32cee9606,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"pandas, pivot, loc, nan, numpy, vectorization",https://github.com/pandas/pandas/issues/8446,contributor_6648,04-09-2020,306,high,beginner
6dff8917-f605-4c95-a2a8-b79044b127c7,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"http, aiohttp, headers",https://stackoverflow.com/questions/3592974,user_980733,27-10-2020,1704,medium,advanced
d9769f33-aaa6-4f73-a14c-70cd5da9de12,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"json, httpx, authentication, oauth",https://github.com/requests/requests/issues/4019,contributor_4599,22-11-2023,239,low,intermediate
c8d9e799-0af8-4dc8-94d7-ccb9881793a4,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"headers, websocket, oauth, retry, rest-api",https://stackoverflow.com/questions/3592974,user_980733,11-09-2019,1701,high,advanced
a79b3495-b0df-4010-a8c2-a68b326d11e9,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"loc, groupby, dtype, nan, reshape, pivot",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,09-08-2020,840,medium,advanced
26445d92-1bde-4d0e-97fe-3fc858c959c0,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"dtype, groupby, reshape, broadcasting, vectorization",https://stackoverflow.com/questions/4860684,user_627024,30-06-2023,1389,high,advanced
2a079ef7-d245-47bc-a929-bc9678d7d3df,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"merge, loc, groupby, vectorization, iloc",https://github.com/pandas/pandas/issues/8446,contributor_6648,07-12-2023,308,medium,intermediate
298c71ac-3e40-41e3-bf39-337fa9306350,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"threading, asyncio, race-condition, gather, executor",https://stackoverflow.com/questions/2140194,user_718011,17-08-2024,284,medium,advanced
29bbcd8a-a977-44e0-991e-e078119d7356,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"sqlite, session, postgresql, alembic",https://stackoverflow.com/questions/9436429,user_974047,23-08-2024,2380,high,intermediate
7a23d587-6972-4a2d-aecd-07c681def55a,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"await, asyncio, semaphore, coroutine",https://stackoverflow.com/questions/3646552,user_469469,08-12-2022,1496,high,beginner
93ca9cc2-d8fe-49b6-8352-c572de8472ac,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"coroutine, gather, race-condition, lock, async, executor",https://stackoverflow.com/questions/2375453,user_449589,29-03-2020,2446,low,intermediate
fb024e4d-4a9f-48dd-b5ef-9d3fb286b2ce,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"env-variable, stdin, os, stdout, stderr",https://docs.os.org/en/stable/os/environ.html,Official Docs,24-11-2024,2207,medium,advanced
087941b2-a1f4-4c2e-b0d5-a7b6b5344591,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"fastapi, orm, rest, routing",https://stackoverflow.com/questions/8106470,user_441071,13-03-2022,1765,high,advanced
9c911cbb-8c8b-4fb1-b2b7-3653f7fd735c,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","event-loop, task, threading",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,08-10-2019,495,high,beginner
42d26a4b-5b8c-41d1-9109-e96eed682a27,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"task, race-condition, await, coroutine",https://github.com/cpython/cpython/issues/5591,contributor_1630,07-12-2018,362,medium,intermediate
41246a85-f999-41f4-8e0b-9cc95fdd1f71,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"tempfile, stderr, glob, pathlib, file-io",https://github.com/cpython/cpython/issues/8586,contributor_7711,29-04-2018,388,medium,intermediate
afbd07bc-543a-4807-8512-12a0c9f79aa3,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"glob, file-io, shutil, stderr",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,18-06-2020,3229,medium,beginner
84263a6b-4c5f-41c4-963b-0638be04667b,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","reshape, loc, merge, numpy",https://stackoverflow.com/questions/5446912,user_563306,19-04-2021,2262,medium,beginner
7b2dd68d-f182-41c0-afbd-3dfc3bcf7925,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"headers, aiohttp, authentication, websocket",https://stackoverflow.com/questions/1604451,user_885136,29-02-2020,635,medium,intermediate
d9509852-5f82-495f-a512-f3fff68cd440,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"lock, race-condition, await",https://github.com/cpython/cpython/issues/4111,contributor_7884,18-09-2018,55,low,intermediate
1a432f07-4363-4bb4-8641-eed995ef193c,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"env-variable, process, pathlib, file-io, stdin",https://stackoverflow.com/questions/2737893,user_994539,18-09-2019,2278,low,intermediate
ad8b7449-079a-41f5-86d4-c0c63abeb4d8,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","tempfile, file-io, pathlib, process, env-variable, subprocess",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,27-03-2024,435,low,beginner
d8bf5d99-d897-415f-b932-a8ba4d527d1c,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"json, timeout, oauth, aiohttp, rest-api",https://stackoverflow.com/questions/1604451,user_885136,26-04-2018,634,medium,advanced
d5c5e941-aeb1-404d-a13d-3a798300cf28,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","sqlite, connection-pool, orm, relationship",https://stackoverflow.com/questions/1247595,user_107793,04-07-2021,423,high,intermediate
0c200797-2510-46b4-9a3b-be2ab8ad0dd5,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"iloc, vectorization, reshape, merge, broadcasting, array",https://github.com/pandas/pandas/issues/3264,contributor_6628,19-02-2023,1,low,intermediate
9e8df60c-12e1-4813-8f09-dfc27a312c67,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"coroutine, lock, deadlock",https://github.com/cpython/cpython/issues/4111,contributor_7884,17-10-2018,22,high,advanced
5a10fbc3-dc8e-4cd1-b7a4-952418a65ad4,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","broadcasting, pandas, pivot, reshape",https://stackoverflow.com/questions/5446912,user_563306,06-03-2024,2231,high,advanced
47a2d21b-cbc4-4ca9-ad2b-4df40eb1c260,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"broadcasting, array, dtype, reshape",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,03-05-2022,790,low,beginner
86c5df99-2952-40a1-9180-f25ed7b6f862,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"gather, event-loop, await, async, coroutine",https://stackoverflow.com/questions/3646552,user_469469,28-07-2021,1510,low,beginner
58ab33cc-9272-4cc1-8f86-de101eabb950,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","array, broadcasting, loc, vectorization",https://stackoverflow.com/questions/5446912,user_563306,22-02-2024,2286,medium,intermediate
0bb3297f-260e-41e3-b3b6-2b02080f179c,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"request, response, blueprint, rest, orm, flask",https://stackoverflow.com/questions/8077999,user_202401,08-01-2020,1866,medium,beginner
22afa720-de0b-4747-b3ea-2c66e4338894,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"template, flask, pydantic",https://github.com/django/django/issues/8618,contributor_8921,31-12-2023,14,medium,beginner
f07585c3-fe6c-4eec-b3ec-862da8d60482,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"websocket, json, requests",https://stackoverflow.com/questions/8896868,user_243238,20-05-2021,1600,medium,advanced
34e5d3e4-58d2-4db9-8feb-149909e460c4,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"httpx, rate-limiting, retry",https://stackoverflow.com/questions/3592974,user_980733,30-06-2022,1648,medium,beginner
95f3bf70-841e-49af-854b-48bcfff64692,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"shutil, subprocess, pipe, os",https://stackoverflow.com/questions/5213115,user_959314,23-10-2024,2097,high,advanced
3f96e9cb-db54-4bb1-a847-322a38b22230,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"json, headers, rest-api, requests, httpx",https://stackoverflow.com/questions/8896868,user_243238,24-12-2022,1568,high,intermediate
3f2fbb75-7595-4a1f-8126-db757d005876,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"pathlib, process, pipe, env-variable, tempfile, stderr",https://docs.os.org/en/stable/os/environ.html,Official Docs,17-04-2018,2227,medium,beginner
aa0c9f8f-6338-4c57-9876-ea45f5efac1d,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"reshape, merge, nan, dtype, groupby",https://stackoverflow.com/questions/2321324,user_99814,28-03-2023,259,medium,beginner
a2f228c0-ee6e-4e89-8475-46fba4433bb9,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"gather, deadlock, semaphore, asyncio, await, coroutine",https://github.com/cpython/cpython/issues/6647,contributor_4097,09-11-2021,284,high,intermediate
0d62d5b3-41ec-4e07-bb98-68e3e00a99e7,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"pandas, broadcasting, pivot, loc, iloc, numpy",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,03-09-2020,1319,medium,advanced
95c5c3f7-e14f-4e38-930a-6d4119db0866,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"groupby, pandas, loc, dtype",https://stackoverflow.com/questions/2321324,user_99814,29-10-2020,263,low,advanced
1e0539c2-6d4b-4ad9-9873-5a591b3a4c1b,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"shutil, process, tempfile",https://stackoverflow.com/questions/2737893,user_994539,22-07-2023,2286,high,advanced
2ea631a8-ded5-4c8a-abb8-44c9946b4eb3,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"pivot, pandas, array, nan, reshape",https://stackoverflow.com/questions/4860684,user_627024,21-06-2020,1394,high,beginner
2ca5e7fc-715e-44cb-a230-f11b46389d20,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"orm, migration, foreign-key",https://stackoverflow.com/questions/7358113,user_12260,31-03-2024,255,high,advanced
3632dc6a-86ae-4d9f-97d8-8a05d2e12c0d,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"stderr, env-variable, pipe",https://stackoverflow.com/questions/5394880,user_179430,27-12-2021,534,medium,intermediate
93f300fe-5395-4eb2-b34c-29723fb08900,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"threading, coroutine, asyncio, deadlock, async, gather",https://stackoverflow.com/questions/3646552,user_469469,25-03-2018,1517,high,intermediate
1f05c4b3-59f5-40c5-b7de-edcd82e8ce5a,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"subprocess, tempfile, stdout",https://github.com/cpython/cpython/issues/8586,contributor_7711,31-12-2020,418,high,advanced
67df1921-0f03-4d78-bb59-21f31fb001ea,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"postgresql, connection-pool, migration, sqlalchemy",https://stackoverflow.com/questions/7358113,user_12260,15-10-2019,231,low,advanced
d05fe93a-9dcd-478b-902b-f7db46b2d7f8,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","async, deadlock, task, race-condition, asyncio",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,16-11-2024,496,high,intermediate
0f27b876-55de-4447-a40f-bdf0dec253c9,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"requests, aiohttp, json, timeout",https://stackoverflow.com/questions/3592974,user_980733,22-07-2022,1667,medium,advanced
47f0ff8c-f61c-4c3a-bd32-620d2c8566fe,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"broadcasting, dataframe, nan",https://github.com/pandas/pandas/issues/4449,contributor_726,19-08-2022,526,medium,intermediate
030f185b-c8d4-4f42-a30f-ad9597649467,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"migration, session, connection-pool, relationship, postgresql, alembic",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,16-02-2022,3035,medium,intermediate
282382b6-8282-48aa-ba92-cf6ba821ac15,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"orm, template, dependency-injection",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,26-01-2024,287,medium,intermediate
238490e3-fbff-43e5-b7e5-5e2bb544f877,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"aiohttp, requests, authentication, retry, oauth",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,01-03-2019,95,medium,advanced
9a380bfe-e6ea-497d-8113-5bddf1cbe09e,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"executor, event-loop, task, async, coroutine",https://stackoverflow.com/questions/2140194,user_718011,02-04-2022,270,low,intermediate
9300cd84-36c1-49fa-ba7a-264474932d10,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"relationship, transaction, sqlalchemy, orm, query",https://stackoverflow.com/questions/7358113,user_12260,26-11-2018,258,low,beginner
721a2b66-ae12-4d7a-b8f1-ba12bd3775b0,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"task, deadlock, async, coroutine, event-loop, threading",https://stackoverflow.com/questions/3646552,user_469469,23-03-2024,1502,high,beginner
13861343-8461-470a-a740-2b6d225d80c2,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"fastapi, response, flask",https://docs.flask.org/en/stable/@app/route.html,Official Docs,10-10-2024,2998,high,advanced
71e1c987-5b27-4ff2-886a-088965e8a6d8,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"threading, async, event-loop",https://stackoverflow.com/questions/2140194,user_718011,06-04-2019,314,low,advanced
caca9b78-a1e2-466a-b770-8b8f16b7d024,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"async, asyncio, race-condition",https://github.com/cpython/cpython/issues/5591,contributor_1630,05-04-2021,337,high,advanced
fac33366-b59c-4eea-bf05-24ce1a308bcb,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"semaphore, gather, asyncio, threading, race-condition",https://stackoverflow.com/questions/2375453,user_449589,30-01-2022,2471,high,beginner
e847c87e-e352-4e5f-b383-62bc7fe45416,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"postgresql, foreign-key, sqlite, transaction, connection-pool, relationship",https://stackoverflow.com/questions/7358113,user_12260,15-06-2023,252,medium,advanced
36a3439b-7f31-49b0-8e9c-6346be00e4ec,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","vectorization, pivot, dtype, iloc, nan",https://stackoverflow.com/questions/5446912,user_563306,15-05-2024,2269,low,beginner
f4a396da-886f-4f96-969d-5920cbeed74c,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"pipe, pathlib, shutil, os",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,02-12-2022,3200,high,advanced
cc552f4b-8382-4dfb-83c2-37f28c38a042,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"oauth, json, websocket, rate-limiting, authentication, retry",https://github.com/requests/requests/issues/4019,contributor_4599,17-07-2023,252,medium,advanced
ba3d1ef3-b32b-4eb0-be13-6a1c5418f99f,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"fastapi, response, request, routing, pydantic, blueprint",https://stackoverflow.com/questions/7754864,user_773587,13-08-2019,422,medium,advanced
e294c205-bb43-4802-84fb-ad1ffecdf401,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"async, gather, threading, race-condition, semaphore, lock",https://stackoverflow.com/questions/2140194,user_718011,29-09-2020,261,medium,beginner
006a29f0-a78b-4837-ba6c-332c536d8ed9,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"numpy, vectorization, loc, dtype, merge, pandas",https://stackoverflow.com/questions/6229731,user_428373,24-09-2018,853,high,beginner
2fe70f01-90ee-4bcb-8edd-e91e708e9120,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","event-loop, coroutine, race-condition, async",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,21-07-2019,494,low,intermediate
a9a19674-7148-44d1-8fed-124c13240e47,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"json, oauth, requests, timeout, retry, rest-api",https://github.com/requests/requests/issues/4019,contributor_4599,20-06-2024,239,high,advanced
357e640d-6453-4df9-9105-1a9fbae9374a,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"pandas, broadcasting, iloc, dataframe",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,20-08-2023,839,medium,advanced
b87dce59-e3b5-4790-b74a-7262291c9142,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"loc, array, vectorization, dtype",https://stackoverflow.com/questions/2321324,user_99814,18-07-2023,241,high,beginner
acf1dc2f-5eb9-4ffd-ad18-f7e6ddfe6f3d,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"dataframe, iloc, numpy, pandas",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,09-01-2022,843,high,intermediate
7e4303bf-d441-4cd1-8bc9-20085ea86ae1,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"deadlock, semaphore, threading",https://stackoverflow.com/questions/2375453,user_449589,07-04-2023,2469,low,intermediate
03ccea44-56f6-482a-a510-731165bb24bf,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"flask, request, dependency-injection, orm",https://github.com/flask/flask/issues/2141,contributor_5020,04-06-2024,178,medium,beginner
980aff58-5d00-48e2-94ff-71505d61e331,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"response, routing, middleware, flask, pydantic, rest",https://stackoverflow.com/questions/8077999,user_202401,15-04-2024,1844,high,intermediate
bb2562b4-7c63-40fb-82a4-7742438f8fb1,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"stdout, stderr, process, pathlib, glob",https://stackoverflow.com/questions/5727085,user_644210,27-01-2024,659,low,beginner
efa2f3fd-b837-406e-8f60-72e5fccf4fae,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","postgresql, sqlalchemy, foreign-key, transaction, migration, relationship",https://stackoverflow.com/questions/5977931,user_238275,09-01-2024,671,medium,intermediate
04443eff-569d-4e4f-86ba-5d348ed9f4fb,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"foreign-key, query, sqlite, sqlalchemy, orm, transaction",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,15-05-2019,2069,high,intermediate
04c924de-fba3-496f-81a5-1d8943ffb894,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"iloc, nan, array",https://stackoverflow.com/questions/4860684,user_627024,20-11-2018,1423,low,intermediate
b3d286b0-9a5e-40ab-9522-876c12fb0bf3,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"pydantic, response, orm, request, dependency-injection, routing",https://stackoverflow.com/questions/8106470,user_441071,28-09-2018,1766,medium,beginner
2dd0e1ed-8f8a-49f5-9044-a272b00a62f3,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"nan, iloc, broadcasting, reshape, vectorization, loc",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,19-02-2019,1314,low,beginner
22ab2a0c-1727-417c-b081-c406db97e024,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"headers, websocket, authentication",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,26-10-2019,4227,high,beginner
7666e514-00b8-4d04-be5c-1c817d021812,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"fastapi, middleware, request, template, rest",https://stackoverflow.com/questions/7754864,user_773587,29-08-2019,428,high,intermediate
7d8e5fc9-1ca1-4671-ae9e-81009fec0bb8,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"process, os, pipe, pathlib",https://stackoverflow.com/questions/5394880,user_179430,10-04-2022,534,medium,intermediate
05fc4fdf-b2aa-4725-b387-02de7d80ae95,stack_overflow,FastAPI/Flask/Django,fastapi,How to implement JWT authentication in FastAPI?,"```python
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
oauth2_scheme = OAuth2PasswordBearer(tokenUrl='token')
```
Create access tokens with `jwt.encode(payload, SECRET_KEY, algorithm='HS256')`. Verify with `jwt.decode(token, SECRET_KEY, algorithms=['HS256'])`. Store SECRET_KEY in environment variables, never in code.",Use python-jose for JWT and passlib for password hashing with OAuth2PasswordBearer.,"rest, django, request",https://stackoverflow.com/questions/7754864,user_773587,07-03-2020,408,high,beginner
d0fb3a65-bbed-4b3a-b8fc-e53e5b1193fd,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"subprocess, os, tempfile, stdin, glob, process",https://stackoverflow.com/questions/5213115,user_959314,15-05-2021,2052,medium,advanced
9d8ef251-283c-453b-b1ec-272d2fd64e2f,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"lock, async, deadlock",https://stackoverflow.com/questions/2229110,user_573750,08-11-2021,2337,medium,advanced
0a2290da-452b-4659-99e2-4a4aaf59dcbc,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"requests, httpx, websocket, rate-limiting",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,28-06-2023,4209,medium,beginner
b7805e5d-461d-48a3-85a7-e6bdc79c55a5,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"executor, await, semaphore, task",https://github.com/cpython/cpython/issues/6647,contributor_4097,06-07-2024,285,medium,advanced
63107430-d315-48a1-8856-6406fdca5c1b,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"loc, broadcasting, dtype, nan",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,14-08-2022,794,low,intermediate
2c6ac981-a3e1-4ed7-a6b7-40270f566e71,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"websocket, oauth, aiohttp, authentication, headers, retry",https://github.com/httpx/httpx/issues/8949,contributor_1420,24-12-2020,439,medium,intermediate
eee5503a-7e1b-4511-a80c-2512d1280dfc,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"glob, file-io, shutil, stdout",https://github.com/cpython/cpython/issues/7712,contributor_8802,25-08-2018,420,low,intermediate
172c30bb-470b-4502-8d0f-4f617d9f4021,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"pandas, reshape, vectorization, array, nan, broadcasting",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,14-11-2020,800,medium,beginner
abb238ed-0a28-4d96-9611-26fd2342ca15,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"nan, merge, groupby, broadcasting",https://stackoverflow.com/questions/6438436,user_522340,24-09-2019,6,medium,advanced
0d3e111a-c6d3-46ca-9f9c-3e9b0e4f8afb,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"django, middleware, flask, template, pydantic, rest",https://stackoverflow.com/questions/8930103,user_264801,26-09-2018,2200,high,intermediate
4df53127-d34e-4836-8bbf-f6679084b714,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"query, sqlalchemy, connection-pool",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,19-09-2020,257,low,advanced
766483a2-d627-4b91-a616-dd4d3cfdc656,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"race-condition, deadlock, gather, asyncio, event-loop",https://github.com/cpython/cpython/issues/5591,contributor_1630,07-05-2019,319,medium,beginner
ec45a005-e5fb-417c-afaa-f74d59552ec6,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"lock, coroutine, async, event-loop, threading",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,11-03-2021,4139,high,advanced
30d1253a-bd21-4e94-809a-6b0fc4aa5aac,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","pipe, file-io, os, stdin, process, stdout",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,12-12-2018,431,high,intermediate
d1949a96-c9db-4ac9-9718-19a9afc56981,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"subprocess, glob, process, stderr, shutil, env-variable",https://github.com/cpython/cpython/issues/2707,contributor_7877,27-05-2018,439,high,intermediate
1d8542ab-318d-4d06-816b-dbf491935ebe,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"subprocess, env-variable, pathlib",https://github.com/cpython/cpython/issues/7712,contributor_8802,23-07-2022,415,high,intermediate
b2fc5023-2e48-404e-8c12-123548fc0373,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"asyncio, semaphore, threading, task, race-condition, gather",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,29-03-2023,4136,low,beginner
71741ba9-0799-476f-ac94-f53e8f912073,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"httpx, requests, websocket, rest-api, http, retry",https://stackoverflow.com/questions/1669324,user_952590,25-06-2022,1521,low,intermediate
9dd9ac98-82e7-4d15-b157-f7405e231153,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"process, subprocess, env-variable",https://stackoverflow.com/questions/5213115,user_959314,08-04-2022,2096,high,intermediate
46aaa0f5-da8d-4db1-a69c-99cabd92801c,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"dtype, nan, broadcasting, vectorization, array",https://stackoverflow.com/questions/4860684,user_627024,06-02-2021,1404,low,intermediate
da7164ee-6532-4124-ad14-c467a7306a90,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"aiohttp, websocket, headers, requests, httpx, oauth",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,26-07-2024,4183,high,advanced
3dc3d5ed-0f3f-4ec5-afe3-da7c5d5b0675,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rate-limiting, timeout, json, oauth",https://stackoverflow.com/questions/1669324,user_952590,07-01-2019,1474,medium,intermediate
3d142493-1f46-40df-aba4-fad1a20cabf7,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"race-condition, async, executor, asyncio",https://stackoverflow.com/questions/2140194,user_718011,05-07-2021,293,medium,intermediate
23fa46a8-9dab-4566-9934-f4638b7d42f8,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","iloc, numpy, nan, pivot, dtype, vectorization",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,14-11-2023,1900,high,beginner
cf383109-aac6-4e11-834c-589146856d47,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","merge, nan, pivot, dataframe, array",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,05-01-2020,1907,medium,beginner
c7f156ad-3100-4c6d-9418-081489637a85,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"loc, vectorization, pivot",https://stackoverflow.com/questions/2321324,user_99814,02-06-2019,257,high,intermediate
006dca6d-2032-416c-b983-191e6b66fb13,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","iloc, dtype, pivot, numpy",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,24-05-2020,1878,high,beginner
7e41dca6-9fd7-4103-8552-961b5278c34a,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"broadcasting, reshape, pivot, iloc",https://github.com/pandas/pandas/issues/3264,contributor_6628,11-12-2021,47,medium,advanced
f7b80187-a2d4-497e-a8ed-dd2ed0ade291,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"glob, stdin, tempfile",https://docs.os.org/en/stable/os/environ.html,Official Docs,25-05-2020,2211,high,intermediate
b621d7ac-5646-4e95-b752-cc4b61153390,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"threading, lock, gather, executor, asyncio",https://stackoverflow.com/questions/3646552,user_469469,19-08-2021,1542,high,beginner
8204956f-c0aa-44de-9d82-f36f07ffe643,stack_overflow,OS/Subprocess/File I/O,shutil,subprocess.run vs Popen: which should I use?,"`subprocess.run()` is a high-level wrapper that waits for completion — use for most cases. `subprocess.Popen()` gives full control: stream stdout/stderr in real-time, write to stdin, run processes concurrently. For capturing output: `subprocess.run(..., capture_output=True, text=True)`. Always use `shell=False` and pass args as a list to prevent shell injection.",Use subprocess.run() for simple cases; Popen for streaming output or interactive processes.,"tempfile, glob, env-variable, pipe, stdin",https://stackoverflow.com/questions/5727085,user_644210,04-03-2020,673,high,advanced
161933f8-36a8-48c3-ab16-904cc06e314d,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"transaction, sqlite, connection-pool, relationship, query, orm",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,16-01-2019,2077,medium,advanced
d0eb7b65-638b-4c47-b12e-5a87362ed04e,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"groupby, dtype, merge, nan",https://stackoverflow.com/questions/4860684,user_627024,27-02-2022,1407,low,intermediate
2eac6192-1e87-483e-aac7-847e68f1a627,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"orm, middleware, template, django",https://github.com/django/django/issues/8618,contributor_8921,31-07-2020,13,high,intermediate
3a7b0aab-8309-4397-bbba-c21a7df3e520,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"deadlock, semaphore, coroutine, executor, task",https://stackoverflow.com/questions/2140194,user_718011,05-07-2019,317,medium,advanced
d28af518-33c8-4eb6-8bfe-dafd753a5ae6,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"glob, stdout, shutil",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,16-12-2022,3216,low,beginner
74d11c46-c50c-44b4-8cf4-6a27e512a42c,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"numpy, vectorization, iloc",https://stackoverflow.com/questions/4860684,user_627024,19-08-2020,1394,low,intermediate
c246aa92-8043-46b0-a000-4d71d8bbcdb4,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"array, pivot, groupby, dataframe",https://github.com/pandas/pandas/issues/8446,contributor_6648,09-02-2024,330,high,advanced
b52ad89a-c580-4cb1-bd4a-d32a017d56c0,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"numpy, loc, vectorization, dtype, array",https://stackoverflow.com/questions/4860684,user_627024,28-03-2023,1420,high,beginner
b144f275-8dd1-4438-8cb3-d6bb02832107,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"session, relationship, sqlite, transaction, alembic",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,21-03-2022,285,high,beginner
efa695d4-b35c-4bfd-b0a7-338b7aacf2a2,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"query, relationship, connection-pool, orm",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,19-12-2023,3019,high,beginner
cb5d41d5-d752-4554-94b2-2f0534b7cc13,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"rest-api, headers, httpx, authentication, rate-limiting",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,26-02-2020,85,high,advanced
71540fda-9e64-4fbd-a7ca-01e121574e01,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"async, deadlock, threading, gather, await, race-condition",https://github.com/cpython/cpython/issues/5591,contributor_1630,04-07-2022,341,high,advanced
625d013b-8d4a-415c-8b42-f9679009269b,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"websocket, timeout, rate-limiting, http, authentication",https://github.com/httpx/httpx/issues/8949,contributor_1420,05-09-2024,457,high,intermediate
07fa91b3-6595-4ce2-80d0-71d1590a5a67,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"shutil, tempfile, subprocess, os, env-variable",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,19-05-2021,3232,medium,beginner
c8be90b4-cacb-4c99-a2f3-1b72290d9da1,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"blueprint, rest, dependency-injection, middleware, request",https://github.com/django/django/issues/3243,contributor_6988,31-05-2023,97,high,advanced
029108a5-53a9-482c-9382-2a05eceda026,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"headers, retry, requests, httpx, json",https://stackoverflow.com/questions/1604451,user_885136,21-02-2022,620,high,advanced
c04a4dad-06a4-45aa-a558-4a2480674340,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"alembic, orm, connection-pool, relationship, postgresql, transaction",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,25-05-2021,2040,medium,intermediate
5559f38e-0040-465a-b9de-e3b3f79fb548,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"requests, headers, retry, httpx",https://github.com/httpx/httpx/issues/8949,contributor_1420,31-01-2019,483,high,advanced
f9014d5b-ee99-4599-95c6-5be9b361e458,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"env-variable, process, stderr, pathlib, tempfile",https://stackoverflow.com/questions/5394880,user_179430,23-09-2018,525,high,advanced
0465694a-6bf9-48aa-9601-c9346c53fe6d,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","pandas, merge, nan, broadcasting, dataframe",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,24-10-2019,4531,medium,advanced
c50f985c-0734-4bd5-9524-eecee35d76c9,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"relationship, sqlite, foreign-key",https://stackoverflow.com/questions/9436429,user_974047,29-11-2021,2407,high,advanced
09f7988f-0057-4fd7-8c4c-a01996c4cbf9,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"rate-limiting, retry, httpx",https://stackoverflow.com/questions/1669324,user_952590,23-05-2023,1528,medium,intermediate
a1f174ec-d7d2-4371-872b-f0ddd4f7e498,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"deadlock, coroutine, threading, async, semaphore, gather",https://stackoverflow.com/questions/2375453,user_449589,21-01-2021,2468,high,beginner
e3fe41c1-d66d-42c8-acf2-8edaebd3fc8e,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"subprocess, tempfile, glob, stdin, pathlib, env-variable",https://stackoverflow.com/questions/2737893,user_994539,11-01-2023,2291,high,beginner
25eea788-55ab-48c2-9cac-146da9d69050,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"requests, websocket, retry, rest-api, oauth, json",https://stackoverflow.com/questions/3592974,user_980733,22-06-2023,1645,medium,beginner
22e4cded-af64-493a-a183-d66d3c1241e4,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","env-variable, stdin, stdout, file-io",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,27-04-2019,438,medium,beginner
dac5c811-9aaf-4bbf-8e19-13c621dc08b4,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"groupby, vectorization, broadcasting, pivot",https://stackoverflow.com/questions/2321324,user_99814,31-08-2022,275,high,beginner
ac892288-ba31-4e9b-bf5c-133736aaeda8,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"loc, pivot, dataframe",https://github.com/pandas/pandas/issues/4449,contributor_726,14-11-2021,482,medium,advanced
5f4b4a82-489a-443f-b0d6-d5350dd3ff31,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"rate-limiting, websocket, requests, aiohttp",https://github.com/requests/requests/issues/3605,contributor_1152,26-09-2021,345,high,advanced
8d72ebfc-b68b-4678-a7fd-e0e752b15ef0,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"relationship, alembic, postgresql, sqlite, orm",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,10-12-2020,3050,medium,intermediate
a965decc-237e-4901-8567-80b9dcaaef4e,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"routing, request, middleware, fastapi, pydantic, dependency-injection",https://github.com/django/django/issues/3243,contributor_6988,03-08-2024,86,medium,advanced
0d80bb59-870f-407a-afda-193ace40ba0e,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","routing, orm, middleware, django, pydantic",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,21-03-2024,2896,medium,beginner
2f66e1d9-7be7-4020-bb2d-b8b3e9eaeb63,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"postgresql, orm, connection-pool, relationship, query, sqlalchemy",https://stackoverflow.com/questions/9436429,user_974047,28-08-2023,2374,medium,intermediate
2ffd8892-4d55-4193-bbaa-f87d7bedacf5,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"threading, lock, asyncio, task, event-loop",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,10-08-2023,4847,medium,beginner
50cba774-4ce6-4404-9a0a-2294d99494fc,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","orm, routing, dependency-injection, middleware, rest",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,06-08-2024,2845,high,advanced
0a2bbac6-e752-4dfe-98ee-87861362be89,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","retry, websocket, oauth, authentication",https://stackoverflow.com/questions/7907400,user_851204,15-11-2021,1398,high,advanced
9a7df6e1-8f23-474a-812e-be3c3b31007a,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","stderr, env-variable, process, os",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,09-12-2024,439,medium,advanced
be4a87f3-aced-478f-8535-cd88f932316e,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"await, event-loop, coroutine, lock",https://stackoverflow.com/questions/2229110,user_573750,10-09-2022,2316,high,advanced
317ad2eb-0d17-4dda-8ed0-2bfc913cfbc0,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","executor, race-condition, task, event-loop, threading",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,22-09-2024,508,high,beginner
1cbd138e-25ee-4b03-b7b6-6f1071cba1c3,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","reshape, merge, iloc, pandas, dtype, nan",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,09-02-2018,1891,high,beginner
6ac658f3-89ad-4d69-941d-be828d65d6e1,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","rate-limiting, requests, http",https://stackoverflow.com/questions/7907400,user_851204,12-03-2022,1349,low,advanced
f644c190-9f7e-4e44-9392-4cc5512b4770,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"aiohttp, retry, oauth, json, headers, websocket",https://github.com/httpx/httpx/issues/8949,contributor_1420,27-06-2024,468,medium,beginner
34026b9b-531a-43c6-8ea0-f9cad8334dfa,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"os, file-io, stdin",https://stackoverflow.com/questions/5394880,user_179430,14-08-2024,531,high,beginner
ba2b0233-152a-4dae-919a-b3909900801a,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"subprocess, tempfile, stderr, process, pathlib, os",https://stackoverflow.com/questions/5213115,user_959314,03-05-2023,2082,low,beginner
8758ff68-729a-48e9-9f3c-e5f89a2819f6,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"reshape, numpy, dataframe, merge, groupby",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,23-07-2021,1323,high,intermediate
7d257eec-c7c8-47e9-a1be-a389a403246f,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"websocket, requests, oauth, authentication, rest-api",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,30-05-2018,4226,high,advanced
51594211-b89b-43c8-9e4b-b128285cd467,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","reshape, pandas, dataframe",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,06-02-2019,1872,high,beginner
4a622da2-9373-4007-85d5-9ad97d3491e4,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"template, fastapi, django",https://docs.flask.org/en/stable/@app/route.html,Official Docs,19-07-2022,3006,medium,intermediate
eb8fdfa3-4b1a-4393-b8e9-e3525c3cd093,github_issue,FastAPI/Flask/Django,django,FEAT: Django: add support for async ORM queries,"Problem: Django ORM is synchronous; using it in async views requires sync_to_async wrapper.

Fix/Discussion: Django 4.1+ added native async ORM support. Use `await Model.objects.filter().afirst()`, `async for obj in qs:`. For older versions: wrap with `sync_to_async`: `get_user = sync_to_async(User.objects.get)
user = await get_user(pk=1)`.",status:closed,"orm, pydantic, rest, routing, template",https://github.com/django/django/issues/8618,contributor_8921,09-02-2020,1,high,beginner
f6ce017a-2eeb-4f13-8440-030141f8c09b,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"threading, semaphore, gather, race-condition",https://stackoverflow.com/questions/2375453,user_449589,14-06-2022,2455,medium,beginner
ceab5fb0-8ce0-425d-8ff7-7d8c5b6b1938,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"httpx, oauth, headers, http, aiohttp, rest-api",https://github.com/requests/requests/issues/4019,contributor_4599,16-11-2019,236,high,beginner
904dd744-672e-4284-a122-ac444d2b8136,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"routing, middleware, template, blueprint, orm, rest",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,10-11-2018,327,medium,advanced
29bcb491-deef-4c22-bb92-5faedcd03573,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"pandas, nan, vectorization",https://github.com/pandas/pandas/issues/8446,contributor_6648,10-09-2020,363,high,beginner
44ab7b84-a41f-455a-9d8e-64caa1ad5f81,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"dtype, reshape, numpy",https://stackoverflow.com/questions/2321324,user_99814,24-05-2019,251,high,advanced
82526b4f-24c6-4a07-a214-9eccb9b5fa91,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","merge, groupby, pandas, dataframe, broadcasting",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,17-03-2022,1889,medium,beginner
727ab28a-70c0-4fe8-8c8a-6fa5f36a2e3e,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"semaphore, task, deadlock, event-loop, asyncio",https://stackoverflow.com/questions/3646552,user_469469,03-07-2023,1495,low,intermediate
9ac3164c-4d05-4220-b485-7c23ce0417a4,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"blueprint, pydantic, flask, response",https://stackoverflow.com/questions/1527021,user_911393,09-11-2024,918,low,advanced
ae3b1086-da53-44f6-b959-b78f705dda11,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"pipe, env-variable, tempfile",https://github.com/cpython/cpython/issues/8586,contributor_7711,05-12-2024,440,high,intermediate
05a6479f-2e8e-4fdd-9178-a6f2b57b70f1,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"timeout, oauth, retry",https://github.com/requests/requests/issues/4019,contributor_4599,20-07-2022,275,medium,advanced
21ac6555-c2b3-40e0-8b7b-97706e8c2e3a,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"pydantic, dependency-injection, orm, fastapi, django",https://github.com/flask/flask/issues/2141,contributor_5020,25-10-2019,141,medium,beginner
c8a6db61-6368-4231-b04a-28fe31638e97,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"headers, requests, websocket, rate-limiting",https://github.com/requests/requests/issues/4019,contributor_4599,13-10-2018,228,high,intermediate
c810202a-0d3b-4dba-acd5-135e1c706cf1,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"orm, transaction, query, foreign-key",https://stackoverflow.com/questions/7358113,user_12260,07-01-2020,256,low,beginner
eef5d852-5b41-4b36-8cf4-ede1ff28b224,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","loc, dtype, pandas, nan",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,08-04-2018,4523,high,beginner
a99f45eb-d38e-4715-a920-68f0f927ae94,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"stdout, file-io, stdin, pipe, glob",https://stackoverflow.com/questions/2737893,user_994539,31-12-2020,2254,medium,advanced
d2f079f0-0717-494e-b70b-97156f6d92bd,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"sqlalchemy, foreign-key, session, orm, transaction",https://stackoverflow.com/questions/7358113,user_12260,15-05-2020,278,medium,intermediate
a003b14a-d39b-4332-9d9c-1830595bb3e0,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"response, pydantic, template, django",https://stackoverflow.com/questions/8930103,user_264801,15-06-2024,2194,medium,advanced
e6b5413e-346a-48c0-80d4-d1e5ab497531,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"websocket, json, timeout, authentication",https://stackoverflow.com/questions/1669324,user_952590,25-04-2021,1503,low,intermediate
e82e7f8c-6263-4194-b7a6-c09a6bd86d6c,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","groupby, merge, loc, numpy, nan",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,02-06-2019,4488,medium,beginner
6345c90b-4432-445c-9644-4a549db54988,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"request, template, middleware, response, fastapi",https://stackoverflow.com/questions/8106470,user_441071,29-05-2023,1752,medium,advanced
7b2c720d-ddcb-451b-a6d8-eac513d9e8a4,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"gather, semaphore, event-loop, race-condition",https://github.com/cpython/cpython/issues/6647,contributor_4097,18-03-2018,268,medium,advanced
36e1f9fb-59a8-4f80-9fdf-4faaa2cfb7ad,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"headers, rate-limiting, aiohttp",https://github.com/requests/requests/issues/3605,contributor_1152,27-08-2023,366,high,intermediate
47e31298-9f38-493a-b625-d9d014c76ca6,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"iloc, vectorization, broadcasting, pivot, array, dataframe",https://github.com/pandas/pandas/issues/8446,contributor_6648,06-07-2019,319,medium,beginner
92bf3772-53ff-461a-a16d-f4e1b2215067,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"reshape, vectorization, groupby",https://github.com/pandas/pandas/issues/8446,contributor_6648,18-09-2022,333,high,beginner
ac797da4-5e01-4c13-a295-d2d020176a93,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"orm, dependency-injection, django, rest",https://stackoverflow.com/questions/8106470,user_441071,22-02-2021,1797,high,intermediate
af7435ad-fadb-4b2f-8083-c9137490d4c6,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"async, executor, asyncio, await",https://github.com/cpython/cpython/issues/5591,contributor_1630,16-08-2019,322,high,advanced
d454aad3-124a-4685-b817-c0bf5458a776,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"pivot, merge, pandas, iloc",https://github.com/pandas/pandas/issues/4449,contributor_726,16-02-2020,475,high,beginner
75371beb-9087-4f38-b964-e9bfedc32037,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"stdin, shutil, process",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,10-05-2024,3202,high,intermediate
1bda3b4c-b7d8-4683-bcc6-f6cce6a1e8ab,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"task, race-condition, asyncio, executor, event-loop, coroutine",https://stackoverflow.com/questions/2229110,user_573750,27-12-2018,2297,medium,beginner
fffab104-5045-40d8-9e9d-21e7e8359b5b,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"foreign-key, postgresql, sqlite",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,27-09-2019,2029,low,intermediate
3090a6dc-831f-4edb-b698-6dbf5d309e6b,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"rest, template, fastapi",https://stackoverflow.com/questions/1527021,user_911393,15-09-2021,947,high,beginner
981051b7-7e41-433c-95c7-015e294ea1f6,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"event-loop, semaphore, executor, async, task, deadlock",https://stackoverflow.com/questions/2375453,user_449589,22-10-2021,2425,high,advanced
b2283003-4340-4cee-abaf-efbc870ab37f,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"subprocess, os, file-io, process",https://stackoverflow.com/questions/5213115,user_959314,16-08-2024,2054,high,beginner
92a5ef98-11c0-4601-a4de-17dcd42293e8,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"routing, middleware, flask, response, request",https://stackoverflow.com/questions/8077999,user_202401,17-12-2021,1850,high,advanced
ad626ba5-8a11-4242-860e-492ce70f3fac,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"response, pydantic, blueprint, rest, fastapi, dependency-injection",https://github.com/flask/flask/issues/2141,contributor_5020,27-12-2018,143,high,advanced
9a605cde-011a-42b4-8906-8ade3b4b995d,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"orm, flask, routing, request, blueprint",https://stackoverflow.com/questions/1527021,user_911393,10-06-2019,959,high,advanced
228d2dfd-e94e-4c0a-9148-2a471b566650,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","fastapi, orm, django, routing",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,14-06-2018,2885,low,beginner
87fabd08-7f90-47e7-9921-ec25dc7c916d,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"transaction, alembic, connection-pool, sqlite, session, sqlalchemy",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,04-11-2021,266,high,beginner
66a980de-8797-4025-9884-d80b56aa19d3,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","file-io, env-variable, tempfile, os",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,04-01-2019,457,medium,advanced
2b1e5c0a-10e6-4d94-b9e6-30559f70ce4d,github_issue,NumPy/Pandas,pandas,PERF: groupby().apply() extremely slow on large DataFrames,"Problem: groupby().apply() with a custom function is 100x slower than expected on 10M row DataFrames.

Fix/Discussion: groupby().apply() serializes each group and has high overhead. Fix: vectorize with numpy, use groupby().transform() for same-shape output, or groupby().agg() with named aggregations. For complex logic, consider Polars or Dask. Numba's @jit can accelerate custom group functions.",status:closed,"dataframe, array, broadcasting, iloc, groupby, dtype",https://github.com/pandas/pandas/issues/8446,contributor_6648,23-06-2019,308,high,intermediate
c98fcf5d-8bbf-48f6-be25-78d2cde6f4d5,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"pipe, process, file-io, subprocess",https://stackoverflow.com/questions/5213115,user_959314,05-10-2019,2100,low,advanced
eede7887-3dca-4d3b-93b6-54dd355d8a2f,github_issue,FastAPI/Flask/Django,fastapi,BUG: FastAPI dependency_overrides not working in pytest,"Problem: Dependency overrides set in conftest are not applied during test execution.

Fix/Discussion: Set overrides on the app object before TestClient is created. Use `app.dependency_overrides[dep] = mock_dep` in a pytest fixture with function scope. Clear overrides after test: `app.dependency_overrides = {}`. Ensure TestClient is created after overrides are set.",status:closed,"dependency-injection, request, response",https://github.com/fastapi/fastapi/issues/8479,contributor_1994,14-03-2024,292,high,intermediate
723e4263-412a-4f6d-b275-3c93cd7c13d4,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"orm, alembic, query, connection-pool",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,04-08-2022,2031,medium,intermediate
3245181a-2687-4a1e-80c1-d4668c2ab2aa,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"process, tempfile, pipe, file-io, pathlib, subprocess",https://stackoverflow.com/questions/5213115,user_959314,16-06-2020,2051,high,intermediate
f9cce29f-d372-441c-be84-cfd2bd0e16b1,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","alembic, transaction, orm, relationship, foreign-key",https://stackoverflow.com/questions/1247595,user_107793,10-01-2020,407,low,beginner
e1ff8d17-44a1-41d5-8c95-bbfe2a112f0e,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"asyncio, threading, event-loop, coroutine, gather, executor",https://github.com/cpython/cpython/issues/4111,contributor_7884,02-03-2021,47,high,intermediate
78c377f1-6e09-4e4b-8e3b-8caedbee9fe9,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"semaphore, gather, event-loop",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,05-07-2019,4820,high,intermediate
2b8204c3-dfa1-4607-bcea-1fcade87e6ce,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"loc, groupby, numpy, dataframe, nan, pivot",https://stackoverflow.com/questions/6438436,user_522340,04-10-2020,24,high,intermediate
4a50a16a-ae7f-4d18-91d0-0b0e3e9d860e,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"gather, coroutine, threading, await, event-loop, deadlock",https://github.com/cpython/cpython/issues/6647,contributor_4097,04-05-2021,248,medium,advanced
836e82c0-9496-4dbe-9641-cb775459b1ab,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"orm, foreign-key, session, alembic, sqlalchemy",https://stackoverflow.com/questions/9436429,user_974047,12-11-2022,2391,high,advanced
98d2598f-3db1-4cba-b312-dd1581805172,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"pydantic, dependency-injection, orm, rest",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,11-06-2020,2399,high,advanced
d29437d2-fe3c-489d-8623-1f14a8e4ddb9,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"timeout, rest-api, json",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,10-09-2023,4200,high,beginner
13ab219f-96f4-4990-98a9-daaa6b77e73a,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"retry, oauth, httpx, websocket, rate-limiting",https://stackoverflow.com/questions/1669324,user_952590,29-12-2018,1528,medium,beginner
d1105c92-b541-4a20-9ff1-c4149cd83e39,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"array, vectorization, dataframe, dtype, iloc",https://stackoverflow.com/questions/2321324,user_99814,17-08-2020,269,medium,advanced
792d8836-4b23-40ce-a75e-863aa2b63e4d,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"process, subprocess, stdout, file-io, env-variable, tempfile",https://github.com/cpython/cpython/issues/2707,contributor_7877,11-01-2024,445,medium,beginner
2ba4a4ea-64d7-421b-bd2e-644f3924a6f8,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","iloc, groupby, array",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,30-10-2022,1899,medium,intermediate
3531fb57-7942-439a-9999-b07e9cb26212,stack_overflow,Requests/HTTP/APIs,retry,How to handle rate limiting with the requests library?,"```python
from tenacity import retry, wait_exponential, stop_after_attempt
@retry(wait=wait_exponential(min=1, max=60), stop=stop_after_attempt(5))
def call_api(url):
    r = requests.get(url)
    r.raise_for_status()
    return r.json()
```
Check `Retry-After` header in 429 responses. For async: use `aiohttp` with tenacity.",Implement exponential backoff with the tenacity or backoff library.,"rest-api, http, aiohttp, json, oauth, timeout",https://stackoverflow.com/questions/1604451,user_885136,26-12-2019,610,high,advanced
e841a792-bc27-4e7c-9cf6-0ff136b816f0,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"fastapi, rest, django",https://stackoverflow.com/questions/8930103,user_264801,19-06-2022,2208,high,advanced
557e7580-e3b0-48fc-b40a-13e4b869a944,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"pandas, reshape, iloc, array",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,28-09-2021,1308,medium,beginner
23bed06a-87c7-450b-bd26-992e292e3020,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"websocket, rate-limiting, httpx",https://stackoverflow.com/questions/8896868,user_243238,28-03-2020,1576,high,intermediate
63f56e34-91d4-4018-8358-2c3c6c5b736f,documentation,FastAPI/Flask/Django,FastAPI,FastAPI — Path Operations,"The `@app.get` function in FastAPI registers a GET endpoint at the specified path. It accepts `path, response_model` as a parameter and returns Response. Common use cases include building REST API endpoints that return JSON data. Note that use response_model to enforce output schema validation.","@app.get(path, response_model) -> Response","pydantic, request, rest, django",https://docs.fastapi.org/en/stable/@app/get.html,Official Docs,22-09-2023,2877,medium,beginner
4ac0fc89-8c96-4a5c-8ea2-2084d6de21af,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"await, threading, coroutine, event-loop",https://stackoverflow.com/questions/3646552,user_469469,20-02-2018,1537,high,advanced
56f2d3b6-2b6c-4091-8235-549360e83ed7,stack_overflow,SQLAlchemy/Databases,sqlalchemy,SQLAlchemy: how to avoid DetachedInstanceError?,DetachedInstanceError occurs when accessing a relationship after the session is closed. Solutions: (1) Use `joinedload()` or `subqueryload()` to eagerly load relationships. (2) Keep session open while accessing objects. (3) Use `expire_on_commit=False` on sessionmaker. (4) Convert to dict/DTO before closing session.,"Access lazy-loaded relationships within the session scope, or use eager loading.","connection-pool, sqlalchemy, session, alembic",https://stackoverflow.com/questions/1247595,user_107793,10-04-2022,393,medium,beginner
fca72146-1ef6-48bc-a430-f22f8a7af6ac,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"template, middleware, response, django, orm, request",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,14-10-2018,2439,high,advanced
2dc52c2a-be21-4f8a-bca6-1de8196aa1d1,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"postgresql, migration, session, connection-pool, sqlite",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,22-06-2019,3067,medium,beginner
87131d3a-91d2-499a-a090-e9b73ea524e7,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"iloc, pandas, loc, array, vectorization",https://stackoverflow.com/questions/4860684,user_627024,05-06-2018,1369,high,beginner
566664e9-b6e4-4f52-9003-2d7eb258fc6f,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"json, authentication, requests",https://stackoverflow.com/questions/8896868,user_243238,13-11-2024,1580,medium,advanced
b6e48d6b-370f-43ac-948c-8ebac1d9aa1b,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"merge, numpy, nan, array, dtype, vectorization",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,20-11-2024,843,high,beginner
233606b6-454a-4885-b711-57c9ca449045,documentation,OS/Subprocess/File I/O,os,os Environment Variables — official reference,"Official documentation for os Environment Variables. The method signature is `os.environ(key)`. provides a mapping of the current environment variables. Raises `KeyError` when key is accessed with [] notation and is not set. See also: dotenv, os.getenv, os.putenv.",os.environ(key),"file-io, os, env-variable",https://docs.os.org/en/stable/os/environ.html,Official Docs,16-09-2023,2205,low,beginner
39359f6c-efc0-4e8a-b9a8-80d93fe83cb3,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"django, pydantic, rest, fastapi",https://stackoverflow.com/questions/8106470,user_441071,29-06-2018,1794,low,beginner
a634a331-d1f3-4555-9850-e48f80e89d8d,documentation,NumPy/Pandas,Pandas,Pandas Merging DataFrames — official reference,"Official documentation for Pandas Merging DataFrames. The method signature is `pd.merge(left, right, on, how='inner')`. merges two DataFrames using SQL-style joins. Raises `MergeError` when merge keys produce duplicate columns. See also: df.join, df.concat.","pd.merge(left, right, on, how='inner')","broadcasting, iloc, vectorization, reshape, pivot, dataframe",https://docs.pandas.org/en/stable/pd/merge.html,Official Docs,01-01-2022,4539,low,intermediate
429f6dab-2f29-4d09-88a3-ca3281fff799,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"deadlock, semaphore, executor",https://github.com/cpython/cpython/issues/5591,contributor_1630,13-09-2023,351,high,intermediate
78b499b2-5eb8-48c2-a199-ef1f9b9905a7,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","query, orm, transaction, connection-pool, postgresql",https://stackoverflow.com/questions/5977931,user_238275,20-11-2022,666,medium,advanced
dd7444e0-acf9-481f-9ce1-f803bc1656a8,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"stdout, env-variable, subprocess, os, file-io, pathlib",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,29-12-2020,3207,low,beginner
c9a336a1-dc73-4205-b5d7-075720957a7a,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","sqlalchemy, relationship, orm",https://stackoverflow.com/questions/5977931,user_238275,20-10-2023,635,high,advanced
5f099ac7-133e-4cfa-af34-1696e4cce8e8,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"authentication, retry, json, oauth, timeout, websocket",https://github.com/requests/requests/issues/4019,contributor_4599,28-10-2021,246,medium,beginner
f95eaa55-241b-4f85-8d51-ac753555165f,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"websocket, aiohttp, requests, timeout, httpx, oauth",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,11-07-2024,48,high,beginner
0cdbd8a9-f303-4a5d-8abc-9db55ae6815b,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"race-condition, semaphore, event-loop, gather, coroutine",https://stackoverflow.com/questions/2140194,user_718011,22-10-2023,284,high,advanced
f42c2e82-9826-4826-9df5-068153dc0f2d,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","gather, await, task",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,17-01-2023,538,high,intermediate
af19dc50-e4f6-413f-9d0a-b7e087090edb,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"pipe, subprocess, os, process",https://stackoverflow.com/questions/5213115,user_959314,01-12-2020,2059,low,beginner
5ca857fb-2faf-4269-897e-70128964d7b0,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"async, gather, race-condition, semaphore, threading, deadlock",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,16-11-2018,4855,medium,advanced
6ce431ac-0342-423b-9779-ff75c421c141,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"orm, relationship, alembic, postgresql, foreign-key",https://stackoverflow.com/questions/9436429,user_974047,14-05-2018,2419,low,beginner
3abfc9e6-2e2b-43ed-ad33-a5fcb2801668,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"sqlite, relationship, postgresql, session",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,10-02-2021,3044,medium,advanced
d766ad1a-7e1d-4c1f-8c07-9c585dbdb0a3,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","deadlock, gather, race-condition, task, async, event-loop",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,26-07-2018,521,low,advanced
a6da5a47-c3f9-4a9c-b475-eaf164cd2610,stack_overflow,Requests/HTTP/APIs,json,How to stream large HTTP responses with requests?,"```python
with requests.get(url, stream=True) as r:
    r.raise_for_status()
    with open('file', 'wb') as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
```
Always use as context manager with stream=True to ensure connection is released.",Use stream=True and iterate over response.iter_content() or iter_lines().,"http, oauth, httpx, authentication, retry",https://stackoverflow.com/questions/3592974,user_980733,27-08-2020,1674,high,beginner
00840e79-2c5e-4a15-87a9-1de0942d7d61,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"json, headers, oauth, authentication, httpx",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,07-01-2024,4185,high,intermediate
2f4bb21d-01b4-4805-9985-cd61ee6f59ab,github_issue,OS/Subprocess/File I/O,cpython,BUG: subprocess.Popen hangs when stdout and stderr buffers fill,"Problem: subprocess.Popen hangs indefinitely when child process produces large output.

Fix/Discussion: This is a classic deadlock: parent waits for child, child waits for parent to read buffer. Fix: use `subprocess.run(..., capture_output=True)` which handles this correctly. Or: `stdout, stderr = proc.communicate()`. Never use `proc.stdout.read()` and `proc.wait()` separately.",status:closed,"process, stdin, pipe, file-io, glob, stdout",https://github.com/cpython/cpython/issues/8586,contributor_7711,29-05-2022,428,high,beginner
b3cb0b93-fc93-4d21-83d5-8e0ec0497fa8,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"headers, retry, oauth, http, rate-limiting, requests",https://github.com/requests/requests/issues/3605,contributor_1152,29-05-2023,340,high,intermediate
ff7bbe5a-16c9-4f74-8c60-cc5eb97116ed,github_issue,Asyncio/Threading,cpython,PERF: concurrent.futures.ProcessPoolExecutor slow startup on Windows,"Problem: ProcessPoolExecutor takes 3-5 seconds to start on Windows due to process spawning overhead.

Fix/Discussion: Windows uses 'spawn' start method (vs 'fork' on Linux). Mitigations: (1) Reuse executor across calls — don't create/destroy in loops. (2) Use 'forkserver' or 'fork' on Linux/macOS. (3) For short tasks, ThreadPoolExecutor may be faster. (4) Use `initializer` param to pre-load modules.",status:closed,"asyncio, async, deadlock, semaphore",https://github.com/cpython/cpython/issues/6647,contributor_4097,01-11-2024,242,high,advanced
8c4e6d20-8e9d-41f9-94c0-2f7c147be8a8,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"event-loop, await, async, race-condition",https://github.com/cpython/cpython/issues/4111,contributor_7884,07-07-2023,2,high,beginner
bf82f751-5ed3-4c34-a345-761456266f8f,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"orm, foreign-key, connection-pool, sqlalchemy, session, query",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,20-08-2023,2062,low,intermediate
4cd03b7f-1099-4dc5-9bf6-c981f72ec5ab,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"os, subprocess, process, tempfile, stdout, stderr",https://github.com/cpython/cpython/issues/2707,contributor_7877,03-06-2021,490,high,intermediate
b94838d7-54f3-4da5-a6e4-1598e4831d49,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"pipe, stderr, os, stdout, subprocess",https://github.com/cpython/cpython/issues/7712,contributor_8802,19-12-2022,404,low,advanced
d07c998f-ab06-40d2-ae17-14a1942b2419,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"retry, timeout, authentication",https://github.com/httpx/httpx/issues/8949,contributor_1420,26-04-2019,443,medium,advanced
a0ad8c98-43a2-455a-88a7-137b53fe1169,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"stdin, stderr, glob",https://github.com/cpython/cpython/issues/2707,contributor_7877,09-05-2019,489,medium,beginner
8eefd80f-a799-42e9-83d5-5ddb9304390a,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"vectorization, iloc, numpy, pandas, merge, dataframe",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,26-02-2021,1324,low,advanced
d3b3810b-209f-4f16-86e3-907c521ed59d,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","dtype, iloc, groupby, merge, dataframe, pandas",https://stackoverflow.com/questions/5446912,user_563306,28-10-2019,2267,medium,beginner
a3a5bfd1-662a-4d40-94ca-cf55cc2f6c46,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","deadlock, threading, semaphore, executor, asyncio",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,01-12-2024,494,high,intermediate
4724bb3e-e57a-4035-b191-76b3f9d6c8cc,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"aiohttp, headers, oauth, retry, rest-api",https://stackoverflow.com/questions/8896868,user_243238,25-08-2020,1549,high,advanced
5faf0623-cc3a-44a4-a65f-d4e5605b8449,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"broadcasting, iloc, groupby",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,29-08-2019,824,low,advanced
2a3b0f77-e2fe-4659-83f5-c8e2f15dd536,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"subprocess, process, stdout, stderr, pathlib",https://github.com/cpython/cpython/issues/7712,contributor_8802,18-08-2019,426,low,advanced
73521710-e0a4-45d6-8853-b06c6defe93b,documentation,NumPy/Pandas,NumPy,NumPy — Vectorization,The `np.vectorize` function in NumPy generalizes a scalar function to operate on arrays. It accepts `pyfunc` as a parameter and returns vectorized function. Common use cases include applying Python functions element-wise without explicit loops. Note that np.vectorize is a convenience wrapper; it does not improve performance like true ufuncs.,np.vectorize(pyfunc) -> vectorized function,"iloc, groupby, merge",https://docs.numpy.org/en/stable/np/vectorize.html,Official Docs,24-11-2023,1344,medium,intermediate
ac6dfe68-4c43-4cca-9048-2cac9a0e8db0,documentation,OS/Subprocess/File I/O,subprocess,subprocess — Process Execution,"The `subprocess.run` function in subprocess runs a subprocess and waits for it to complete. It accepts `args, capture_output=False, timeout=None` as a parameter and returns CompletedProcess. Common use cases include executing shell commands, scripts, or external programs from Python. Note that use shell=False (default) to avoid shell injection vulnerabilities.","subprocess.run(args, capture_output=False, timeout=None) -> CompletedProcess","file-io, subprocess, shutil, glob",https://docs.subprocess.org/en/stable/subprocess/run.html,Official Docs,22-06-2023,430,medium,advanced
38bad728-08fa-472c-a8bd-d1eca28e24f4,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"await, coroutine, gather, executor, async",https://stackoverflow.com/questions/2140194,user_718011,20-04-2018,271,medium,intermediate
3579a87d-50be-49d6-a2c7-f0d037333198,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"groupby, numpy, loc",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,04-07-2022,826,high,beginner
c5bb15e6-335d-4670-bd64-e89a4af69516,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"await, asyncio, gather, executor, event-loop, coroutine",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,20-12-2021,4821,high,beginner
514ac93a-badf-4504-a8b2-8b0cd4c91bce,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"deadlock, asyncio, coroutine, async, semaphore, task",https://github.com/cpython/cpython/issues/4111,contributor_7884,19-10-2019,56,medium,intermediate
fe90125c-ef28-4bee-a275-19b11e119df5,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"oauth, retry, httpx, rest-api",https://stackoverflow.com/questions/8896868,user_243238,06-04-2019,1592,low,intermediate
2a15f2e8-7821-456c-93ba-04befefb3afd,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"rate-limiting, headers, timeout, requests, websocket, retry",https://github.com/requests/requests/issues/4019,contributor_4599,04-03-2023,226,low,beginner
86f10057-5c85-4142-8c44-1c6680427a03,github_issue,NumPy/Pandas,pandas,BUG: pd.read_csv() silently truncates large integers,"Problem: Integer columns with values > 2^53 are silently corrupted when read from CSV.

Fix/Discussion: Floating point cannot represent integers > 2^53 exactly. Fix: `pd.read_csv(f, dtype={'col': str})` then convert: `df['col'] = df['col'].astype('Int64')`. Use `dtype_backend='numpy_nullable'` in Pandas 2.0+ for better integer handling.",status:closed,"pivot, merge, pandas, array",https://github.com/pandas/pandas/issues/4449,contributor_726,24-05-2022,485,high,advanced
69febb33-6e65-4b9b-b26d-66f2d503e242,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","dataframe, vectorization, numpy",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,07-01-2022,1898,medium,beginner
d6bf59a0-4186-4116-a315-3902577daf4f,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"threading, coroutine, await, event-loop, race-condition",https://stackoverflow.com/questions/3646552,user_469469,25-07-2022,1497,medium,intermediate
bffe4867-8501-4f51-9d65-8f14bde89181,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"lock, async, threading, race-condition",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,24-12-2021,4832,high,intermediate
de641413-f885-400e-af4c-b95547dc666b,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"executor, race-condition, task, coroutine, lock",https://stackoverflow.com/questions/3195773,user_714318,16-11-2024,1118,medium,advanced
90a3a447-83ee-4b95-a4f2-2a21b110bb28,stack_overflow,Requests/HTTP/APIs,websocket,requests.exceptions.SSLError: certificate verify failed,"Never use `verify=False` in production — it disables SSL verification entirely. Solutions: (1) Update certifi: `pip install --upgrade certifi`. (2) Provide CA bundle: `requests.get(url, verify='/path/to/ca-bundle.crt')`. (3) For self-signed certs in dev: `verify=False` only, and never commit this. (4) Check system time — expired system clock causes SSL failures.","Your SSL certificate chain is incomplete or self-signed. Fix the cert, don't disable verification.","httpx, requests, headers",https://stackoverflow.com/questions/7907400,user_851204,07-01-2020,1360,high,advanced
f23e18c7-5647-4e70-8bdd-6b812828bf20,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"stderr, stdin, glob, pipe",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,10-05-2020,3202,high,intermediate
b520eb5c-8997-4223-930f-5fc1569064ba,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"oauth, websocket, retry",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,20-04-2023,86,medium,advanced
28876d7f-93cd-4f89-b308-4857e35f5e5d,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"migration, orm, alembic, foreign-key, sqlalchemy",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,03-03-2024,257,high,intermediate
5f7ab7ad-addc-4f9a-b2a7-ccbcd1b596b0,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"stdin, shutil, env-variable, stdout, os, stderr",https://stackoverflow.com/questions/5394880,user_179430,13-09-2020,546,high,advanced
7c736392-4cbb-43c1-8afe-9b973e814dd0,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"orm, pydantic, flask, django, request",https://stackoverflow.com/questions/1527021,user_911393,12-12-2021,971,medium,intermediate
cc765fc8-1b97-41fd-b50f-c48452547cdf,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"connection-pool, foreign-key, orm, sqlite, relationship",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,04-07-2024,3038,high,advanced
16be93a7-0eed-4b3a-bfce-a04348d77ce7,documentation,Asyncio/Threading,asyncio,How to use asyncio.create_task in asyncio,"`asyncio.asyncio.create_task` schedules a coroutine as a Task in the event loop. Example usage:
```python
task = asyncio.create_task(send_email(user))
await task
```
This is useful when fire-and-forget background tasks, concurrent task management. Performance tip: use TaskGroup (Python 3.11+) for structured concurrency.",asyncio.create_task,"race-condition, coroutine, executor, semaphore",https://docs.asyncio.org/en/stable/asyncio/create_task.html,Official Docs,30-08-2021,4166,medium,intermediate
0bdc768d-b7db-487e-89c3-580007317fdc,github_issue,Requests/HTTP/APIs,httpx,BUG: httpx: SSL certificate error on Windows despite valid cert,"Problem: httpx raises SSLCertVerificationError on Windows when system CA store has the cert.

Fix/Discussion: httpx uses its own CA bundle (certifi) by default, not the system store. Fix: `httpx.Client(verify=certifi.where())` — already default. For custom certs: `httpx.Client(verify='/path/to/ca-bundle.pem')`. Install `pip install truststore` and use `ssl.create_default_context(ssl.Purpose.SERVER_AUTH)` to use system store.",status:closed,"oauth, rate-limiting, aiohttp, authentication, websocket, json",https://github.com/httpx/httpx/issues/8949,contributor_1420,24-01-2019,470,low,intermediate
f67134c0-fab0-4666-ab8e-673034f1a287,github_issue,Asyncio/Threading,cpython,BUG: threading.Timer not cancellable after it fires,"Problem: Calling cancel() on a Timer that has already executed does not raise an error but has no effect.

Fix/Discussion: threading.Timer.cancel() only works before the timer fires. Store Timer reference and check `timer.finished.is_set()` to know if it's already run. For repeating timers, use a loop with `threading.Event` for clean cancellation: `stop_event = threading.Event(); stop_event.wait(interval)`.",status:closed,"await, semaphore, gather",https://github.com/cpython/cpython/issues/4111,contributor_7884,28-08-2023,41,medium,intermediate
3f0aa295-37dd-4d75-a3e5-8ce0242bcaf3,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","loc, array, numpy, iloc",https://stackoverflow.com/questions/5446912,user_563306,21-12-2019,2262,high,beginner
4154ee74-721b-42d3-9401-396f08581dba,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"pivot, vectorization, groupby, nan",https://stackoverflow.com/questions/4860684,user_627024,30-10-2022,1371,high,advanced
feb9f381-922f-4f1d-8bb3-e5f4e0643cd9,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"json, retry, httpx, rate-limiting, aiohttp",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,15-03-2020,4218,high,advanced
5c44ca8d-37af-4806-b046-746c9c8e5f19,stack_overflow,Asyncio/Threading,lock,Python threading: how to share data between threads safely?,"For simple counters: use `threading.Lock()` as context manager. For complex shared state: prefer `queue.Queue` (thread-safe by design). Avoid global variables without locks. `threading.local()` gives each thread its own data copy. For read-heavy workloads, `threading.RLock` allows re-entrant acquisition.",Use threading.Lock for mutual exclusion or queue.Queue for producer-consumer patterns.,"threading, asyncio, executor, event-loop",https://stackoverflow.com/questions/3195773,user_714318,16-05-2019,1083,medium,intermediate
612a12cb-a2cc-4433-b327-9456c8bdc88c,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"pivot, vectorization, loc, merge, nan, numpy",https://github.com/pandas/pandas/issues/3264,contributor_6628,12-03-2022,20,medium,advanced
9c37a358-94fd-4f8c-a94d-0179eed2c19a,github_issue,SQLAlchemy/Databases,alembic,BUG: Alembic autogenerate misses index changes,"Problem: Alembic --autogenerate does not detect changes to indexes or constraints on existing tables.

Fix/Discussion: Alembic autogenerate compares metadata to database state but has limitations. Workarounds: (1) Manually add `op.create_index()` to migration. (2) Use `include_schemas=True` in env.py. (3) Run `alembic check` to see detected changes. (4) Always review autogenerated migrations before applying.",status:open,"query, orm, sqlalchemy, alembic, connection-pool, transaction",https://github.com/alembic/alembic/issues/7344,contributor_3601,16-06-2019,212,high,beginner
f2965fdb-a74d-4a6f-9f9e-9134c1410297,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"nan, numpy, loc, iloc",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,24-07-2020,801,low,advanced
fa4e5a57-8601-4a38-89a8-303bbd154ae2,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"reshape, pivot, dtype, pandas, vectorization",https://stackoverflow.com/questions/6229731,user_428373,01-04-2020,815,high,intermediate
2778393c-25d7-481c-a411-cab50b19a34d,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"connection-pool, migration, query, relationship, alembic, orm",https://stackoverflow.com/questions/7358113,user_12260,16-01-2024,250,high,intermediate
b3de3667-b59d-4d83-b441-3b089e4333af,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"loc, merge, numpy",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,02-03-2020,817,high,advanced
fe85764a-6cba-40db-9b28-7ee6819e359b,stack_overflow,NumPy/Pandas,loc,How do I efficiently fill NaN values in a Pandas DataFrame?,"For large DataFrames, avoid looping. Use `df.fillna({'col': val})` to fill specific columns. `df.ffill()` propagates last valid observation forward. For time-series data, `df.interpolate()` provides smoother results. Always check `df.isna().sum()` before and after to verify.",Use df.fillna(value) or df.ffill()/df.bfill() for forward/backward fill.,"broadcasting, array, vectorization",https://stackoverflow.com/questions/6438436,user_522340,11-08-2024,30,medium,advanced
2fa87447-3398-4ceb-988f-053206331fd1,stack_overflow,FastAPI/Flask/Django,django,How to run background tasks in FastAPI?,"FastAPI's `BackgroundTasks`: add `background_tasks: BackgroundTasks` as a parameter, then `background_tasks.add_task(func, *args)`. Runs after response is sent. For heavy workloads (email, ML inference), use Celery with Redis/RabbitMQ broker. For async background work, `asyncio.create_task()` works within async endpoints.",Use BackgroundTasks for lightweight tasks or Celery for heavy/distributed work.,"response, rest, request",https://stackoverflow.com/questions/8077999,user_202401,27-03-2020,1858,high,advanced
a82dd512-c60e-4092-a178-996551fe7f4d,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"oauth, timeout, httpx, rate-limiting, authentication, headers",https://stackoverflow.com/questions/1669324,user_952590,17-12-2022,1531,high,intermediate
5d959279-21c2-475f-acfe-a4f210e80d3f,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","event-loop, race-condition, asyncio, semaphore",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,07-02-2019,530,medium,advanced
405cae83-1a46-4a3b-81d7-6f973da9767a,documentation,FastAPI/Flask/Django,Django,Django ORM Queries — official reference,"Official documentation for Django ORM Queries. The method signature is `QuerySet.filter(**kwargs)`. filters QuerySet rows matching given field lookups. Raises `FieldError` when an unknown field lookup is provided. See also: QuerySet.exclude, QuerySet.annotate, Q objects.",QuerySet.filter(**kwargs),"orm, dependency-injection, pydantic, django, response",https://docs.django.org/en/stable/QuerySet/filter.html,Official Docs,06-11-2023,2430,low,intermediate
dade8440-f7e1-43fb-9782-7d1602b28a52,github_issue,Requests/HTTP/APIs,requests,BUG: requests hangs indefinitely on slow server responses,"Problem: requests.get() hangs forever when server accepts connection but never sends response.

Fix/Discussion: Always set both connect and read timeouts: `requests.get(url, timeout=(3.05, 27))`. Tuple: (connect_timeout, read_timeout). Or single value for both. Mount a Session with default timeouts using a custom HTTPAdapter subclass. Never use `timeout=None` in production code.",status:closed,"http, requests, oauth, rest-api",https://github.com/requests/requests/issues/4019,contributor_4599,30-01-2023,243,low,advanced
04e651f5-157a-4140-a0ae-e0a2fd273774,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"orm, query, alembic, migration",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,12-03-2019,262,medium,intermediate
1cc6d168-4f6e-4a5b-a59e-6c5980c944d5,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"aiohttp, rest-api, json",https://github.com/requests/requests/issues/3605,contributor_1152,08-04-2019,351,high,advanced
4d24778b-d930-48e8-9481-a267b3789928,documentation,Asyncio/Threading,threading,threading Thread Synchronization — official reference,"Official documentation for threading Thread Synchronization. The method signature is `threading.Lock()`. creates a mutual-exclusion lock for thread-safe access. Raises `RuntimeError` when lock is released without being acquired. See also: threading.RLock, threading.Semaphore, threading.Event.",threading.Lock(),"await, threading, event-loop, task",https://docs.threading.org/en/stable/threading/Lock.html,Official Docs,07-04-2024,4853,medium,beginner
f9f4fbaa-d28e-44a6-bf42-73418a529192,stack_overflow,Asyncio/Threading,async,asyncio RuntimeError: This event loop is already running,"This error is common in Jupyter and FastAPI. Solutions: (1) In async context: just use `await coroutine()`. (2) In Jupyter: `import nest_asyncio; nest_asyncio.apply()`. (3) Run in thread: `asyncio.get_event_loop().run_in_executor(None, sync_func)`. (4) Use `asyncio.ensure_future()` to schedule from within async code.",You're calling asyncio.run() inside an already running event loop. Use await instead.,"deadlock, race-condition, semaphore, async, lock, coroutine",https://stackoverflow.com/questions/2229110,user_573750,16-12-2019,2335,high,intermediate
95b1457a-7718-494b-b241-8902a833b5ac,stack_overflow,NumPy/Pandas,nan,How do I reshape a wide DataFrame to long format?,"`pd.melt(df, id_vars=['id'], value_vars=['col1','col2'])` unpivots columns to rows. `df.stack()` moves column index to row index. For the reverse, use `df.pivot()` or `df.unstack()`. Always reset_index() after stack/unstack to get a clean DataFrame.",Use pd.melt() or df.stack() depending on your structure.,"iloc, reshape, loc, pivot, numpy, dataframe",https://stackoverflow.com/questions/6229731,user_428373,12-09-2022,812,medium,intermediate
0894eaca-f6ba-4328-8b39-85730f7d6811,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"event-loop, asyncio, lock, race-condition",https://github.com/cpython/cpython/issues/5591,contributor_1630,07-05-2022,345,high,intermediate
68db51c3-242d-430c-9cb4-2a4e7d30349d,github_issue,OS/Subprocess/File I/O,cpython,FEAT: pathlib: add support for reading/writing with encoding shorthand,"Problem: pathlib.Path.read_text() does not default to UTF-8, causing issues across platforms.

Fix/Discussion: Always pass encoding explicitly: `Path('file').read_text(encoding='utf-8')`. Python 3.10+ added `encoding='locale'` default change proposal. Best practice: always specify encoding in all file I/O operations for portability.",status:closed,"pipe, stderr, stdin, env-variable, pathlib",https://github.com/cpython/cpython/issues/2707,contributor_7877,11-09-2023,451,high,beginner
4cb043cf-274e-4581-86f2-686bc1a600ea,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"asyncio, semaphore, lock, race-condition, task",https://github.com/cpython/cpython/issues/5591,contributor_1630,24-07-2023,361,medium,advanced
5d72c359-3fb6-4282-b470-e017c7206ca2,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"glob, stdout, os",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,30-11-2019,3220,medium,advanced
b13bb9e1-b3a3-4f14-ac0f-7d0e6fbd5e01,github_issue,OS/Subprocess/File I/O,cpython,BUG: os.path.join ignores prefix when component starts with /,"Problem: os.path.join('base', '/absolute') returns '/absolute', ignoring 'base'.

Fix/Discussion: This is documented behavior: os.path.join discards previous components when it encounters an absolute path. Fix: use `pathlib.Path(base) / component.lstrip('/')`. Validate user-provided paths with `Path(path).resolve().is_relative_to(base_dir)` to prevent path traversal.",status:closed,"os, shutil, env-variable",https://github.com/cpython/cpython/issues/7712,contributor_8802,22-05-2021,426,high,intermediate
a1a2bd0b-3622-475f-b287-3f9f37b2e4b3,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"http, timeout, httpx, authentication, rate-limiting, rest-api",https://github.com/requests/requests/issues/3605,contributor_1152,11-04-2022,349,high,intermediate
919076bf-1143-4345-9a1f-a8059f2e30b5,stack_overflow,SQLAlchemy/Databases,connection-pool,How to handle database migrations with Alembic?,"Workflow: (1) Change SQLAlchemy models. (2) `alembic revision --autogenerate -m 'description'`. (3) Review generated migration script. (4) `alembic upgrade head` to apply. Always review autogenerated migrations — they miss some changes (indexes, constraints). Use `alembic downgrade -1` to rollback. Store migrations in version control.",Use alembic revision --autogenerate to create migrations from model changes.,"postgresql, connection-pool, sqlite, relationship",https://stackoverflow.com/questions/9436429,user_974047,25-09-2022,2373,high,beginner
feeecde4-c6a3-41d1-9964-145e0306883d,stack_overflow,Requests/HTTP/APIs,requests,How to upload a file with requests?,"```python
with open('file.pdf', 'rb') as f:
    r = requests.post(url, files={'file': ('file.pdf', f, 'application/pdf')})
```
For multiple files: pass a list of tuples. For multipart form data with fields: combine `files` and `data` parameters. Don't set Content-Type manually — requests sets it with boundary.",Use the files parameter with a file-like object or tuple.,"requests, oauth, timeout, json, aiohttp",https://stackoverflow.com/questions/8896868,user_243238,13-09-2024,1593,medium,intermediate
31869085-0150-4acf-99df-f50224d294b1,documentation,FastAPI/Flask/Django,Flask,How to use @app.route in Flask,"`Flask.@app.route` maps a URL rule to a view function. Example usage:
```python
@app.route('/users/<int:uid>')
def get_user(uid):
    return jsonify(user)
```
This is useful when defining HTTP endpoints in a Flask application. Performance tip: use Blueprints to organize large applications.",@app.route,"rest, template, fastapi, flask, response, dependency-injection",https://docs.flask.org/en/stable/@app/route.html,Official Docs,04-08-2023,3010,high,intermediate
cd631eaa-01f8-4062-a4af-10416a74ece7,stack_overflow,OS/Subprocess/File I/O,stdin,Python: how to safely write to a file atomically?,"```python
import tempfile, os
with tempfile.NamedTemporaryFile('w', delete=False, dir='.') as tmp:
    tmp.write(data)
    tmp.flush()
    os.fsync(tmp.fileno())
os.replace(tmp.name, target_path)
```
`os.replace()` is atomic on POSIX. This prevents partial writes from corrupting files.",Write to a temp file then rename — rename is atomic on POSIX systems.,"stderr, pipe, process, stdout, file-io",https://stackoverflow.com/questions/5394880,user_179430,20-12-2022,568,low,beginner
c09e40a7-e210-4e00-b709-02a71a81474a,stack_overflow,SQLAlchemy/Databases,query,SQLAlchemy bulk insert: what's the fastest way?,"`session.bulk_insert_mappings(Model, list_of_dicts)` skips ORM overhead. Even faster: `session.execute(insert(Model), data)`. Avoid `session.add()` in loops. For PostgreSQL, use `insert().on_conflict_do_nothing()` for upserts. Batch in chunks of 1000-5000 rows for optimal performance.","Use session.bulk_insert_mappings() or execute(insert(), list_of_dicts) for maximum speed.","postgresql, sqlalchemy, foreign-key, alembic, sqlite, orm",https://stackoverflow.com/questions/5977931,user_238275,23-06-2018,670,medium,beginner
f4c9d248-7e04-4026-8bc5-a73ecf8839cd,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"sqlite, relationship, migration, transaction",https://stackoverflow.com/questions/7358113,user_12260,14-05-2023,275,high,advanced
404aff84-5914-42cf-b231-adc9304dc57e,github_issue,Asyncio/Threading,cpython,BUG: asyncio task leaks when exception is not handled,"Problem: Unhandled exceptions in fire-and-forget asyncio tasks are silently ignored, causing task leaks.

Fix/Discussion: Always await tasks or add exception handlers. Use `task.add_done_callback()` to log exceptions. In Python 3.11+, use TaskGroup for structured concurrency — exceptions propagate automatically. Set `asyncio.get_event_loop().set_exception_handler()` for global unhandled task exception logging.",status:closed,"lock, semaphore, async",https://github.com/cpython/cpython/issues/5591,contributor_1630,20-12-2023,359,medium,advanced
933eb5a5-c9e0-4cde-9ac8-bcf0333e90e9,stack_overflow,Asyncio/Threading,coroutine,How to implement a thread pool in Python?,"```python
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(task, arg) for arg in args]
    results = [f.result() for f in futures]
```
For CPU-bound: use ProcessPoolExecutor instead. For async integration: `await loop.run_in_executor(executor, func, *args)`.",Use concurrent.futures.ThreadPoolExecutor for I/O-bound tasks.,"async, coroutine, lock, threading",https://stackoverflow.com/questions/3646552,user_469469,16-08-2019,1517,low,beginner
787e583a-49ef-4e75-a274-356cd6fee41d,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"sqlite, session, postgresql, orm, connection-pool, sqlalchemy",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,19-12-2019,308,medium,advanced
2c3d03ff-5c97-4e3a-8dc7-21560b6b413b,github_issue,NumPy/Pandas,pandas,BUG: SettingWithCopyWarning when modifying sliced DataFrame,"Problem: Modifying a slice of a DataFrame raises SettingWithCopyWarning and may not update original.

Fix/Discussion: Always use .loc or .copy() when slicing. Use `df.loc[mask, 'col'] = val` for assignment. Create explicit copies: `subset = df[mask].copy()`. In Pandas 2.0+, Copy-on-Write makes this behavior consistent — enable with `pd.options.mode.copy_on_write = True`.",status:closed,"dataframe, array, reshape",https://github.com/pandas/pandas/issues/3264,contributor_6628,07-09-2023,12,medium,beginner
658bb87a-695d-44bd-ae24-0113b6f57661,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"pipe, stdin, process, os",https://stackoverflow.com/questions/2737893,user_994539,05-07-2019,2281,high,intermediate
51c0c6d3-c8e0-4315-abeb-f1b91c4ee8a2,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"numpy, groupby, broadcasting, pandas, merge, loc",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,16-01-2023,824,high,beginner
fed54d13-d20f-40f6-9268-50d23ab3a222,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"race-condition, task, gather, async, executor",https://stackoverflow.com/questions/2375453,user_449589,10-09-2022,2449,medium,beginner
58d4d137-ebe8-4616-b276-00e4bdf30258,stack_overflow,NumPy/Pandas,array,Why is my Pandas merge creating duplicate rows?,Duplicate rows after merge usually mean the join key is not unique. Diagnose with `df.duplicated(subset=['key']).sum()`. Use `how='left'` carefully when right table has multiple matches. Set `validate='one_to_many'` or `'many_to_one'` to enforce cardinality. Consider deduplicating with `df.drop_duplicates(subset=['key'])` before merging.,Your merge key has duplicates in one or both DataFrames. Use validate='one_to_one' to catch this early.,"dataframe, dtype, vectorization, pandas",https://stackoverflow.com/questions/2321324,user_99814,24-09-2024,247,high,beginner
285270ed-4755-4cad-9d26-7591266f5c5a,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"retry, oauth, rate-limiting, websocket, rest-api, authentication",https://github.com/requests/requests/issues/3605,contributor_1152,18-01-2024,347,medium,advanced
158b45c2-54b9-4acf-b6e3-0fbbcd17e8fe,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"process, os, stderr, file-io, subprocess",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,24-12-2021,3223,high,intermediate
a606e766-68b6-489a-bc88-903e36ce0628,documentation,Requests/HTTP/APIs,requests,requests — HTTP Session Management,The `requests.Session` function in requests creates a persistent HTTP session with connection pooling. It accepts `` as a parameter and returns Session object. Common use cases include making multiple requests to the same host efficiently. Note that always close or use Session as context manager to release connections.,requests.Session() -> Session object,"retry, oauth, json",https://docs.requests.org/en/stable/requests/Session.html,Official Docs,04-04-2019,82,medium,advanced
57c49432-d2a8-495c-93ab-1e02b80129aa,stack_overflow,OS/Subprocess/File I/O,shutil,How to read a large file line by line in Python without loading it all into memory?,"```python
with open('large.txt', 'r') as f:
    for line in f:
        process(line.strip())
```
This reads one line at a time. For binary files: use `f.read(chunk_size)` in a loop. For CSV: use `pd.read_csv(file, chunksize=10000)`. Never use `f.readlines()` on large files.",Iterate over the file object directly — it yields lines lazily.,"shutil, env-variable, stdin, stdout, pipe",https://stackoverflow.com/questions/2737893,user_994539,03-10-2020,2282,medium,advanced
146f29e3-2884-4ad7-ab1f-c766dccfb757,stack_overflow,SQLAlchemy/Databases,session,How to implement database connection pooling with SQLAlchemy?,"`create_engine(url, pool_size=10, max_overflow=20, pool_timeout=30, pool_recycle=1800)`. Use `pool_pre_ping=True` to detect stale connections. For async: use `AsyncEngine` with `create_async_engine()`. Monitor with `engine.pool.status()`. NullPool disables pooling for scripts/serverless environments.",create_engine() has built-in pooling. Configure pool_size and max_overflow.,"sqlalchemy, foreign-key, sqlite",https://stackoverflow.com/questions/7358113,user_12260,04-12-2023,265,high,intermediate
a4426707-14ce-4bb7-9278-ccf7da35a8ab,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"rate-limiting, rest-api, http",https://github.com/requests/requests/issues/3605,contributor_1152,19-03-2021,379,high,intermediate
8a1295b3-7a92-4d54-be01-897718316dcf,github_issue,FastAPI/Flask/Django,flask,BUG: Flask session not persisting between requests in tests,"Problem: Session data set in one request is not available in the next request during testing.

Fix/Discussion: Use Flask test client's session_transaction() context manager: `with client.session_transaction() as sess:
    sess['user_id'] = 1`. Ensure SECRET_KEY is set. For testing: `app.config['TESTING'] = True; app.config['SECRET_KEY'] = 'test'`.",status:closed,"blueprint, rest, pydantic",https://github.com/flask/flask/issues/2141,contributor_5020,27-04-2020,168,high,intermediate
995c4d32-3600-49e9-8abe-0bdb3f315ea0,documentation,NumPy/Pandas,NumPy,NumPy — Linear Algebra,"The `np.einsum` function in NumPy evaluates Einstein summation convention on operands. It accepts `subscripts, *operands` as a parameter and returns ndarray. Common use cases include matrix multiplication, dot products, tensor contractions. Note that prefer np.einsum over loops for large arrays.","np.einsum(subscripts, *operands) -> ndarray","vectorization, reshape, pandas, numpy, dtype",https://docs.numpy.org/en/stable/np/einsum.html,Official Docs,22-12-2020,1861,medium,beginner
d76bfbaa-119f-40c1-bc0d-2624b3798042,stack_overflow,Asyncio/Threading,gather,How to run asyncio code from synchronous Python?,"`asyncio.run(main())` creates an event loop, runs the coroutine, closes the loop. Never call asyncio.run() from inside a running event loop (use await instead). In Jupyter notebooks (which have a running loop), use `await coroutine()` directly or `nest_asyncio.apply()`. For mixing sync/async, use `loop.run_until_complete()`.",Use asyncio.run() in Python 3.7+ to execute a coroutine from sync code.,"coroutine, lock, await",https://stackoverflow.com/questions/2140194,user_718011,15-08-2022,316,medium,advanced
19c3dd6b-d242-4d8d-86a9-cd4b3460434a,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"postgresql, transaction, sqlalchemy, session, connection-pool, relationship",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,08-08-2019,272,high,advanced
ee5aeeb0-3043-4a14-8d72-4f86a8a48a27,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"authentication, http, timeout",https://github.com/requests/requests/issues/3605,contributor_1152,22-06-2022,344,medium,intermediate
faf74b97-0215-4cf6-9c72-b905a0471e74,stack_overflow,NumPy/Pandas,numpy,NumPy broadcasting error: operands could not be broadcast with shapes,"NumPy broadcasts shapes right-to-left. Arrays (3,4) and (4,) are compatible. Arrays (3,4) and (3,) are not — reshape to (3,1). Use `arr.reshape(-1,1)` to add a dimension. Always print `a.shape, b.shape` before operations to debug. `np.expand_dims(arr, axis=1)` is cleaner than reshape for adding dimensions.",Shapes must be compatible: dimensions must match or one of them must be 1.,"reshape, pivot, groupby, vectorization, merge",https://stackoverflow.com/questions/4860684,user_627024,12-10-2022,1392,high,intermediate
a3b8cf7f-ba84-48ae-bbb2-2ae97b661159,documentation,SQLAlchemy/Databases,SQLAlchemy,How to use create_engine in SQLAlchemy,"`SQLAlchemy.create_engine` creates a database engine representing a connection pool. Example usage:
```python
engine = create_engine('postgresql://user:pass@host/db', echo=True)
```
This is useful when establishing the central database connection for an application. Performance tip: set pool_size and max_overflow based on expected concurrency.",create_engine,"transaction, alembic, relationship, orm, query",https://docs.sqlalchemy.org/en/stable/create_engine.html,Official Docs,15-05-2021,2072,medium,intermediate
0797f323-f7fd-4eca-bc17-29e57639c828,stack_overflow,NumPy/Pandas,dataframe,How to apply a function to each row in Pandas without using iterrows?,"`iterrows()` is slow because it creates a Series per row. Prefer `df.apply(func, axis=1)` for row-wise operations, or better yet, vectorize using NumPy: `np.where(condition, a, b)`. For complex logic, `df.assign()` with vectorized expressions is cleanest. Benchmark: vectorized > apply > itertuples > iterrows.","Use df.apply(func, axis=1) or vectorized NumPy operations for best performance.","array, vectorization, dtype, iloc, numpy, pivot",https://stackoverflow.com/questions/5446912,user_563306,02-06-2023,2249,high,intermediate
4173e4a7-04a1-4b59-bac1-5682e2b41397,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"retry, rest-api, headers",https://stackoverflow.com/questions/1669324,user_952590,31-03-2022,1496,medium,advanced
c2dbf47c-5874-4c95-b199-85943cb32840,documentation,Asyncio/Threading,asyncio,asyncio — Concurrent Coroutines,"The `asyncio.gather` function in asyncio runs multiple coroutines concurrently and collects results. It accepts `*coros, return_exceptions=False` as a parameter and returns list of results. Common use cases include parallel I/O operations such as multiple API calls. Note that set return_exceptions=True to prevent one failure from cancelling all tasks.","asyncio.gather(*coros, return_exceptions=False) -> list of results","gather, asyncio, task, race-condition, semaphore, threading",https://docs.asyncio.org/en/stable/asyncio/gather.html,Official Docs,13-03-2019,485,medium,beginner
429ad8e5-46cd-4fc7-bfda-fc112ac372a1,stack_overflow,Requests/HTTP/APIs,websocket,How to add retry logic to requests?,"```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
retry = Retry(total=3, backoff_factor=1, status_forcelist=[500,502,503,504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)
```",Mount an HTTPAdapter with urllib3 Retry on the Session.,"aiohttp, headers, websocket",https://stackoverflow.com/questions/1669324,user_952590,09-06-2024,1487,medium,advanced
b9d67217-ef6c-4b30-8ceb-135f64834014,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"relationship, connection-pool, postgresql",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,10-06-2022,3058,high,beginner
dd6814d3-91d3-43b8-aa1c-9926ec9b918b,documentation,OS/Subprocess/File I/O,pathlib,How to use Path.glob in pathlib,"`pathlib.Path.glob` yields all paths matching the given glob pattern. Example usage:
```python
py_files = list(Path('src').glob('**/*.py'))
```
This is useful when finding files recursively, batch file processing. Performance tip: iterate the generator lazily rather than converting to list for large directories.",Path.glob,"file-io, os, pathlib",https://docs.pathlib.org/en/stable/Path/glob.html,Official Docs,16-08-2024,3182,low,advanced
be54710f-1a45-42fa-9edb-f17ac5a3cf44,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"oauth, authentication, aiohttp, retry, rate-limiting, http",https://github.com/requests/requests/issues/3605,contributor_1152,08-10-2019,382,medium,intermediate
baf7083c-27e4-4c2f-9584-bd36f2b312e4,stack_overflow,FastAPI/Flask/Django,request,Django N+1 query problem: how to fix?,N+1 occurs when accessing related objects in a loop. Diagnose with `django-debug-toolbar` or `connection.queries`. Fix ForeignKey: `User.objects.select_related('profile').all()`. Fix M2M: `Post.objects.prefetch_related('tags').all()`. Use `only()` to fetch specific fields and reduce data transfer.,Use select_related() for ForeignKey and prefetch_related() for ManyToMany relationships.,"pydantic, routing, rest, middleware, flask, orm",https://stackoverflow.com/questions/8106470,user_441071,13-04-2022,1786,medium,advanced
fdd3d1c7-1b13-40d6-abf5-bfdcd5f4edab,documentation,SQLAlchemy/Databases,SQLAlchemy,SQLAlchemy — ORM Session Query,The `session.query` function in SQLAlchemy constructs a SELECT query against mapped entities. It accepts `*entities` as a parameter and returns Query object. Common use cases include retrieving ORM-mapped objects from the database. Note that prefer session.execute(select(...)) in SQLAlchemy 2.0+.,session.query(*entities) -> Query object,"foreign-key, alembic, sqlite, session",https://docs.sqlalchemy.org/en/stable/session/query.html,Official Docs,04-09-2020,3027,high,beginner
ed12241e-3861-43c3-b8f3-39e7f3edeb91,github_issue,Requests/HTTP/APIs,requests,PERF: requests connection not reused between calls — new TCP connection each time,"Problem: Each requests.get() call opens a new TCP connection, causing high latency.

Fix/Discussion: requests.get/post etc. create a new Session per call. Fix: use a persistent Session: `session = requests.Session()` and reuse it. Sessions pool connections via urllib3. For thread-safety: create one Session per thread. For async: use httpx.AsyncClient or aiohttp.ClientSession for async connection pooling.",status:closed,"timeout, websocket, json, requests, retry",https://github.com/requests/requests/issues/3605,contributor_1152,01-07-2020,369,high,intermediate
e3de5ae4-16fe-400c-a360-5f11f0aee558,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"await, coroutine, lock, executor, threading, semaphore",https://stackoverflow.com/questions/2375453,user_449589,18-06-2020,2452,high,advanced
99b78854-d151-4d3f-a1e1-d1e8e229817f,stack_overflow,Asyncio/Threading,asyncio,How to limit concurrency with asyncio?,"```python
sem = asyncio.Semaphore(10)
async def limited(url):
    async with sem:
        return await fetch(url)
results = await asyncio.gather(*[limited(u) for u in urls])
```
This prevents overwhelming APIs or databases with too many simultaneous connections.",Use asyncio.Semaphore to cap the number of concurrent coroutines.,"threading, semaphore, event-loop, executor",https://stackoverflow.com/questions/2375453,user_449589,22-01-2022,2416,high,intermediate
1ec71ab7-6dda-4d62-acb4-22f596db2ef4,github_issue,SQLAlchemy/Databases,sqlalchemy,BUG: SQLAlchemy connection pool exhaustion under load,"Problem: Application hangs under concurrent load — all connections are checked out and pool is exhausted.

Fix/Discussion: Increase `pool_size` and `max_overflow`. Ensure sessions are always closed: use `contextmanager` or `with Session() as session:`. Set `pool_timeout` to fail fast. Enable `pool_pre_ping=True`. Monitor with `engine.pool.checkedout()`. In async: use `AsyncSession` with `async_scoped_session`.",status:closed,"relationship, orm, session",https://github.com/sqlalchemy/sqlalchemy/issues/106,contributor_5078,17-02-2021,308,high,beginner
712adcf7-9e3e-4b7b-86c4-3b19905a29af,stack_overflow,FastAPI/Flask/Django,flask,How do I handle CORS in FastAPI?,"```python
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_methods=['*'], allow_headers=['*'])
```
In production, replace `'*'` with your actual frontend domain. For credentials (cookies), set `allow_credentials=True` and specify exact origins.",Add CORSMiddleware from starlette to your FastAPI app.,"blueprint, routing, request, dependency-injection",https://stackoverflow.com/questions/1527021,user_911393,23-09-2019,961,medium,advanced
70cde696-bc47-4301-9fd1-bf65739ff0a9,stack_overflow,OS/Subprocess/File I/O,env-variable,How to watch a directory for file changes in Python?,"```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
handler = FileSystemEventHandler()
observer = Observer()
observer.schedule(handler, path='.', recursive=True)
observer.start()
```
For simple polling: `os.stat(file).st_mtime`. Linux-native: `inotify`. macOS-native: `FSEvents`.",Use the watchdog library for cross-platform directory monitoring.,"tempfile, env-variable, stdout, glob, os",https://stackoverflow.com/questions/5213115,user_959314,12-09-2020,2086,high,advanced
88c0659d-abe5-47fe-946f-4747eb34576f,documentation,NumPy/Pandas,Pandas,How to use df.groupby in Pandas,"`Pandas.df.groupby` groups DataFrame rows by column values. Example usage:
```python
df.groupby('category')['value'].mean()
```
This is useful when aggregation, transformation, filtering by group. Performance tip: avoid apply() on large DataFrames; prefer agg().",df.groupby,"vectorization, array, reshape, broadcasting, iloc, pandas",https://docs.pandas.org/en/stable/df/groupby.html,Official Docs,04-02-2020,799,low,beginner
3eb7c4cb-c16b-4642-b2cc-a1989eaf4d3a,stack_overflow,FastAPI/Flask/Django,django,Flask: how to return JSON responses properly?,"`return jsonify({'key': 'value'})` sets Content-Type to application/json. Flask 1.0+ automatically converts returned dicts to JSON responses. For custom status codes: `return jsonify(data), 201`. For errors: use `abort(404)` or return `({'error': 'Not found'}, 404)`.",Use jsonify() or return a dict directly (Flask 1.0+).,"django, response, rest, template",https://stackoverflow.com/questions/8930103,user_264801,02-10-2020,2197,high,advanced
2ab08505-1c66-4ef0-9274-159a3f9c8ebc,documentation,Requests/HTTP/APIs,httpx,How to use httpx.AsyncClient in httpx,"`httpx.httpx.AsyncClient` provides an async HTTP client for non-blocking requests. Example usage:
```python
async with httpx.AsyncClient() as client:
    r = await client.get(url)
    data = r.json()
```
This is useful when making concurrent HTTP requests in async applications. Performance tip: set timeout=httpx.Timeout(10.0) to prevent hanging requests.",httpx.AsyncClient,"retry, aiohttp, websocket, httpx, rest-api",https://docs.httpx.org/en/stable/httpx/AsyncClient.html,Official Docs,19-09-2024,4208,medium,beginner
d8a38a6e-d974-4a9e-86f3-722e322a5efd,github_issue,FastAPI/Flask/Django,django,PERF: Django template rendering bottleneck in production,"Problem: Template rendering takes 500ms+ for complex pages with many database queries.

Fix/Discussion: Primary cause is N+1 queries in template. Solutions: (1) Use select_related/prefetch_related. (2) Cache rendered templates with `cache` template tag. (3) Use `django-cachalot` for query caching. (4) Move heavy computation to views, pass pre-computed context. (5) Consider server-side caching with Redis.",status:closed,"template, blueprint, django",https://github.com/django/django/issues/3243,contributor_6988,26-10-2019,79,high,beginner
